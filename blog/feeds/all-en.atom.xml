<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>datapythonista blog</title><link href="https://datapythonista.github.io/blog/" rel="alternate"></link><link href="https://datapythonista.github.io/blog/feeds/all-en.atom.xml" rel="self"></link><id>https://datapythonista.github.io/blog/</id><updated>2019-12-01T00:00:00+00:00</updated><subtitle>about me</subtitle><entry><title>Successful delivery of data projects</title><link href="https://datapythonista.github.io/blog/successful-delivery-of-data-projects.html" rel="alternate"></link><published>2019-12-01T00:00:00+00:00</published><updated>2019-12-01T00:00:00+00:00</updated><author><name>Marc Garcia</name></author><id>tag:datapythonista.github.io,2019-12-01:/blog/successful-delivery-of-data-projects.html</id><summary type="html">&lt;h1&gt;Successful delivery of data projects&lt;/h1&gt;
&lt;p&gt;&lt;img alt="" src="/static/img/blog/data_projects/tower_bridge.jpeg"&gt;&lt;/p&gt;
&lt;p&gt;This week we organized a round table with people involved in the management
of data projects. Mostly data science.&lt;/p&gt;
&lt;p&gt;The idea came after the &lt;a href="https://pydata.org/london2019/schedule/presentation/61/executives-at-pydata/"&gt;Executives at PyData&lt;/a&gt;
session organized earlier this year. And discussions with few people on the
challenges when trying to deliver data …&lt;/p&gt;</summary><content type="html">&lt;h1&gt;Successful delivery of data projects&lt;/h1&gt;
&lt;p&gt;&lt;img alt="" src="/static/img/blog/data_projects/tower_bridge.jpeg"&gt;&lt;/p&gt;
&lt;p&gt;This week we organized a round table with people involved in the management
of data projects. Mostly data science.&lt;/p&gt;
&lt;p&gt;The idea came after the &lt;a href="https://pydata.org/london2019/schedule/presentation/61/executives-at-pydata/"&gt;Executives at PyData&lt;/a&gt;
session organized earlier this year. And discussions with few people on the
challenges when trying to deliver data projects.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://ianozsvald.com/"&gt;Ian Ozvald&lt;/a&gt;, founder of PyData London, and organizer
of the PyData session was present. He's also a trainer and consultant specialized
in the topic (one of his courses is coincidentially named &lt;em&gt;Successful data science projects&lt;/em&gt;),
so his participation was very appreciated. We also had &lt;a href="https://www.linkedin.com/in/mehmood-hassan7/"&gt;Mehmood Hassan&lt;/a&gt;
a recruiter from &lt;a href="https://www.interquestgroup.com/brands/ecom"&gt;ECOM&lt;/a&gt;, who kindly
offered to host the session in their offices, and feed us during the event. :)
Mehmood contributions were also valuable, bringing a recruiter's point of view
in different topics.&lt;/p&gt;
&lt;p&gt;The rest of attendees had different backgrounds, like lead data scientists,
project managers, and senior specialists in machine learning engineering.
They came from a diversity of industries, companies such as
&lt;a href="https://en.wikipedia.org/wiki/Lloyds_Bank"&gt;Lloyds Bank&lt;/a&gt;,
&lt;a href="https://en.wikipedia.org/wiki/Johnson_%26_Johnson"&gt;Johnson &amp;amp; Johnson&lt;/a&gt;,
&lt;a href="https://en.wikipedia.org/wiki/MercadoLibre"&gt;Mercado Libre&lt;/a&gt;,
&lt;a href="https://en.wikipedia.org/wiki/ITV_(TV_network)"&gt;ITV&lt;/a&gt; or
&lt;a href="https://en.wikipedia.org/wiki/J.P._Morgan_%26_Co."&gt;JP Morgan&lt;/a&gt;
among others.&lt;/p&gt;
&lt;p&gt;Next there is a summary of the discussions during the event. The topics were
proposed by the same attendees, before and during the event.&lt;/p&gt;
&lt;h2&gt;Data teams&lt;/h2&gt;
&lt;p&gt;The first topic that was discussed was about the teams. One of the first
challenges is the current terminology. Data science roles are very broad
and can mean a variety of things depending on the company. While some
progress has been made (new roles like machine learning engineer), this is
still a challenge today.&lt;/p&gt;
&lt;p&gt;There is a preference in many companies to try to hire people with an
unreasonable set of skills. From excellent software engineering skills,
to advanced knowledge of machine learning techniques, and great soft
skills. There is also a preference of companies to hire only senior
people, which makes things challenging in both sides (for candidates
and for companies).&lt;/p&gt;
&lt;p&gt;One of the companies was using a (probably) rare role, that was a team
of experts with the goal of advising and auditing practices in the
data projects. Deciding on the feasibility of projects being considered,
the recruitment, the skills needed. It was described as similar to
project management, but with very high technical knowledge.&lt;/p&gt;
&lt;p&gt;Having multiple skills in a team is also tricky. Projects that had only
data scientists doing everything (like productionizing) went wrong,
based on attendees experience. But there were different cases were
having separate teams (data scientists and devops for example) went
also wrong, because of the cultural gap. In some cases the development
ended up being more adversarial among them, than collaborative.&lt;/p&gt;
&lt;p&gt;Regarding the leadership of the projects, many options seem to be
happening. Data science teams that take ownership of the projects,
and lead the development. Meaning that other teams (data engineering,
devops) report to them. Other cases the software development team
owns the project, and data scientists report to them. There are also
cases where the leadership is shared between technical and business
managers.&lt;/p&gt;
&lt;p&gt;Participants have also shared accounts of spending quality time with
stakeholders not directly involved in the data work, like executives
or internal clients. Time spent on introducing concepts, plans, and 
getting feedback in an informal setting contributed to long term success,
i.e. made getting buy-in easier.&lt;/p&gt;
&lt;h2&gt;Organization&lt;/h2&gt;
&lt;p&gt;&lt;img alt="" src="/static/img/blog/data_projects/session1.jpeg"&gt;&lt;/p&gt;
&lt;p&gt;For organizing the teams, the preference was to use Agile techniques as
a reference, but everybody agreed that using the same techniques used
for software engineering wasn't useful. Kanban, Scrum... were adapted
and in some cases the organization was just slightly inspired by them.&lt;/p&gt;
&lt;p&gt;One of the variants was to use longer sprints than usual (assuming it's
usual to have two week sprints). The sprints were four weeks instead,
and they were divided in different stages. For example, the first
stage was analyzing the data and planning the next stages of the sprint.&lt;/p&gt;
&lt;p&gt;Another variant was to use Scrum managing the uncertainty of data projects
by making hypothesis and assumptions. The length of the tasks, the quality
of the data... are estimated or assumed, the sprint is planned for that,
and for every wrong assumption and extra work, new tasks are added to
the backlog. This was successful for one team, but required the people
in the team to be senior and experienced.&lt;/p&gt;
&lt;p&gt;The main goals by using these techniques, besides of course delivering
the expected results, were to have visibility of the development of
the project, and to estimate deadlines.&lt;/p&gt;
&lt;p&gt;Agile techniques are often based on trying things fast, and failing
early. This often does not apply to data science projects, since they
may have a big overhead to get started. For example accessibility to
the data (regulated institutions may need long processes of approval).&lt;/p&gt;
&lt;h2&gt;Technology&lt;/h2&gt;
&lt;p&gt;All companies were mainly using the PyData stack for the projects.
This is surely biased, given that the organization of the event, and
the promotion, came from people from the PyData community.&lt;/p&gt;
&lt;p&gt;The preference was to develop the projects in shared infrastructure,
and not in the workstations. As an example, 8 Gb of RAM can be quiet
good for a workstation, but clearly insufficient for many data projects.
&lt;a href="https://jupyter.org/"&gt;Jupyter&lt;/a&gt; was the main interface used, and as
said, having it on the servers and not locally (using Jupyter Hub)
as the preferred approach.&lt;/p&gt;
&lt;p&gt;Some of the mentioned tools were:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://pandas.pydata.org/"&gt;pandas&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://scikit-learn.org/stable/"&gt;scikit-learn&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pytorch.org/"&gt;PyTorch&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://fasttext.cc/"&gt;fastText&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And for productionizing, tools like Docker or Flask (creating
microservices) were named.&lt;/p&gt;
&lt;p&gt;There was mostly agreement on building "from scratch" the platform using
these tools, and not using data frameworks with GUI...
&lt;a href="https://docs.aws.amazon.com/sagemaker/latest/dg/whatis.html"&gt;SageMaker&lt;/a&gt;
was used in some cases.&lt;/p&gt;
&lt;p&gt;Persistence of models is mainly done with Python's pickles.&lt;/p&gt;
&lt;h2&gt;Open source&lt;/h2&gt;
&lt;p&gt;&lt;img alt="" src="/static/img/blog/data_projects/session2.jpeg"&gt;&lt;/p&gt;
&lt;p&gt;There was also a discussion on how companies see and get involved in
open source.&lt;/p&gt;
&lt;p&gt;There were different points of views regarding hiring of open source
contributors. People closer to the recruitment side thought that it's
a clear competitive advantage to contribute to open source. While
people closer to open source development didn't see any impact of their
contributions in their professional careers.&lt;/p&gt;
&lt;p&gt;There were also concerns on whether companies care about candidates
with good GitHub profiles, because they expect them to work longer
hours (since they are used to work for free), and be more motivated.&lt;/p&gt;
&lt;p&gt;There were no experiences on companies supporting open source by hiring
contributors to work on the projects as part of their job.&lt;/p&gt;
&lt;p&gt;The experiences on companies sponsoring events were very positive.
Most companies who host events, sponsor conferences seem to see
value when they have experience, and they keep recurring. Some
have seen the quality of applications to their companies increase
significantly, more than the quantity. And candidates usually
have a very positive attitude when interviewed by companies they
know because they sponsor events.&lt;/p&gt;
&lt;p&gt;On the recruitment side, it was also side about the poor experience
of many companies, who have unreasonable tests to asses candidates.
There was agreement that tests should have a reasonable duration,
let the candidate learn things (about the company and the role
besides technical things), and useful feedback by senior technical
people should be given after it's reviewed.&lt;/p&gt;
&lt;h2&gt;The future&lt;/h2&gt;
&lt;p&gt;Regarding the future of the data industry, everybody was optimistic
and thought that it will continue to grow, even with the difficulties
in delivering results. Companies seem to keep growing their awareness
of the value of the data they have.&lt;/p&gt;
&lt;p&gt;Some areas that people expect to grow are fairness in machine learning
and interpretability.&lt;/p&gt;
&lt;p&gt;For the future of our round tables, people found the session useful.
Besides sharing experiences, people found very useful to know that
other companies have many of the same problems, and that they didn't
take a wrong path, and are disconnected from the rest of the industry.&lt;/p&gt;
&lt;p&gt;We are likely to organize sessions like this in the future. Several
people also shown interest on having them online, since they were
not based in London.&lt;/p&gt;
&lt;p&gt;If you are managing data projects, and can be interested in future
session, feel free to get in touch. You have many ways to get in
touch with me at my &lt;a href="https://datapythonista.me"&gt;website&lt;/a&gt;.&lt;/p&gt;</content></entry><entry><title>An update on the pandas documentation</title><link href="https://datapythonista.github.io/blog/pandas-documentation-update.html" rel="alternate"></link><published>2019-11-28T00:00:00+00:00</published><updated>2019-11-28T00:00:00+00:00</updated><author><name>Marc Garcia</name></author><id>tag:datapythonista.github.io,2019-11-28:/blog/pandas-documentation-update.html</id><summary type="html">&lt;h1&gt;An update on the pandas documentation&lt;/h1&gt;
&lt;p&gt;&lt;img alt="" src="/static/img/blog/pandas_doc/panda_book.jpeg"&gt;&lt;/p&gt;
&lt;h2&gt;Some context&lt;/h2&gt;
&lt;p&gt;This post is mainly a technical post on what's the status of the pandas documentation.
But let me provide a bit of context on where this comes from.&lt;/p&gt;
&lt;p&gt;It's a personal opinion, but I think pandas is one of the clearest examples …&lt;/p&gt;</summary><content type="html">&lt;h1&gt;An update on the pandas documentation&lt;/h1&gt;
&lt;p&gt;&lt;img alt="" src="/static/img/blog/pandas_doc/panda_book.jpeg"&gt;&lt;/p&gt;
&lt;h2&gt;Some context&lt;/h2&gt;
&lt;p&gt;This post is mainly a technical post on what's the status of the pandas documentation.
But let me provide a bit of context on where this comes from.&lt;/p&gt;
&lt;p&gt;It's a personal opinion, but I think pandas is one of the clearest examples of how open
source is transforming the data world (together with some other projects like scikit-learn,
Jupyter, R...). Is likely that pandas contributed to the huge growth of
Python, a language that not many people knew about when pandas development started.&lt;/p&gt;
&lt;p&gt;And I think its documentation has been the clearest example of the paradox of open
source software. While pandas users were growing to the millions, and it was adopted in thousands
of companies (including the largest companies in the world), almost nobody spent any time
or money in its documentation (which requires a lot of work to be of high quality). It's surely not to blame the
very few people (3 or 4 at times) who were maintaining the project. They had enough dealing with thousands of
issues, updates in the many and fast changing dependencies, releasing new versions... While also
implementing new features and fixing bugs themselves. And even more considering that most of that
work was done as volunteers, in evenings after work or in weekends.&lt;/p&gt;
&lt;p&gt;More than 2 years ago I sent to the project my first pull request, fixing a single docstring
(one of the around 2,000 in the project). And decided to spend a significant amount of
my also volunteer time (after work and during weekends) in improving that part. That also
was one of the main reasons for starting the &lt;a href="https://python-sprints.github.io"&gt;Python sprints&lt;/a&gt;
group.&lt;/p&gt;
&lt;p&gt;More than two years later, not much changed (apparently). But if you care about my opinion,
I'm sure very soon pandas will have one of the best documentations of any open source project. This
post explains all the work done by hundreds of people in the last couple of years, and the work
that is still missing, and how we are going to approach it.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;If you work for a company that is making money using pandas, and that would be more productive
and make even more money if pandas documentation was better, please contact a pandas maintainer
including &lt;a href="mailto:garcia.marc@gmail.com"&gt;myself&lt;/a&gt; or &lt;a href="https://www.numfocus.org"&gt;NumFOCUS&lt;/a&gt;.
We are happy to discuss funding opportunities, including small grants or helping your company
hire people to work on pandas.&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;The problem with the docstrings&lt;/h2&gt;
&lt;p&gt;The pandas API is huge, and includes around 2,000 functions, methods, classes, attributes...
Each of them with a page in the documentation.
Given the very reduced number of developers pandas had, and the huge demand and urgency for a dataframe
library in Python, most of those API pages couldn't be created with high standards when the
features were implemented. See for example the
&lt;a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.core.resample.Resampler.last.html"&gt;Resampler.last&lt;/a&gt;
page.&lt;/p&gt;
&lt;p&gt;It may not be obvious for people who haven't contributed to a project like pandas before,
but improving a docstring, and make it as useful for readers as possible, it's not 5 minutes
of work. Based on the work done by lots of contributors over the last year, I would estimate
it takes around 1 day of work of an experienced pandas user. You can see the docstring of
&lt;a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.core.resample.Resampler.bfill.html"&gt;Resampler.bfill&lt;/a&gt;
to see what I'd consider a good docstring.&lt;/p&gt;
&lt;p&gt;Considering this estimate of 1 day per docstring, and the around 2,000 docstrings, it's
easy to calculate that it'd take around 8 years for a single person working full time,
to have all them fixed. And that excludes the time of maintainers to review the changes,
provide feedback, merge...&lt;/p&gt;
&lt;h2&gt;The pandas documentation sprint&lt;/h2&gt;
&lt;p&gt;&lt;img alt="" src="/static/img/blog/pandas_doc/pandas_sprint.png"&gt;&lt;/p&gt;
&lt;p&gt;As it's obvious that a single person can't do much, one of the things that was tried
was to organize a &lt;a href="https://python-sprints.github.io/pandas/"&gt;worldwide pandas sprint&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The sprint was extremely successful in many ways. 30 local users groups participated,
from places as diverse as Korea, Hong Kong, India, Turkey, Kenya, Nigeria, Argentina
or Brazil, besides many cities in Europe and US. Difficult to say how many people
participated, but we estimate there where around 500 people helping make pandas
documentation for a whole Saturday.&lt;/p&gt;
&lt;p&gt;I think there are no words to describe how amazing that is. How many people offered
to organize sprints with their local groups. And how many people joined them in every
sprint. The organizers had to prepare the event for weeks, both for logistics but also
for the technical part of leading a lot of people in their first open source contributing.&lt;/p&gt;
&lt;p&gt;A big responsible for this success was &lt;a href="https://numfocus.org/"&gt;NumFOCUS&lt;/a&gt;. For several
years now NumFOCUS has done extraordinary efforts on building the PyData community.
Having a connected network of more than 150 user groups made it very easy to communicate
and reach all the people who could be interested.&lt;/p&gt;
&lt;p&gt;The feedback I received from the participants and organizers was very positive, and people
enjoyed the experience (which I personally think it's much more important than the
contributions made). And there were around 200 documentation pages that were fixed
because of the sprint (10% of the total).&lt;/p&gt;
&lt;p&gt;But not everything was so positive. The sprint also made evident that the problem of
fixing the documentation was not the number of contributors. The bottleneck happened
to be the maintainers. The sprint created a total disruption of the project for more than two
weeks. And this period wasn't longer because the maintainers were spending day and night
reviewing the pull requests from the sprint. In many cases it was the maintainers who
had to finish the work started during the sprint. Many pull requests contained great
work, but were discontinued, and they required important changes that had to be done
by the maintainers. The last PR from the sprint was merged almost a year later than
the sprint.&lt;/p&gt;
&lt;p&gt;More information about the sprint can be found in this
&lt;a href="https://numfocus.org/blog/worldwide-pandas-sprint"&gt;NumFOCUS write up&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;The validation script&lt;/h2&gt;
&lt;p&gt;We anticipated before the sprint, that reviewing the contributions would be a lot
of work. And we developed a script to automate part of it. The idea was to automatically
detect things like:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The documented parameters of a function need to match the actual parameters in the signature&lt;/li&gt;
&lt;li&gt;Conventions like starting sentences with a capital letter or finishing with a period&lt;/li&gt;
&lt;li&gt;Ensure that some sections we'd like to always have are present (like Examples)&lt;/li&gt;
&lt;li&gt;Formats that make Sphinx render the documentation incorrectly, like missing spaces before the
  colon between a parameter name and its type&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We managed to have several of these ready for the sprint. But to keep all the docstrings consistent
and rendering correctly, we needed many more. Many people spent a significant amount of time adding
new checks to the script, and we are currently able to automatically detect
&lt;a href="https://github.com/pandas-dev/pandas/blob/master/scripts/validate_docstrings.py#L63"&gt;more than 40 possible problems in docstrings&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Of course not everything can be validated, think of correct grammar, wrong, inaccurate or misleading
information, examples that are not clear... But validating almost every formatting issue automatically
will definitely save a lot of time of reviewers. Who will be able to focus on the things that
can't be automated.&lt;/p&gt;
&lt;p&gt;Some other projects had interest in using our validation script, so it's been recently moved to
&lt;a href="https://github.com/numpy/numpydoc"&gt;numpydoc&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="/static/img/blog/numpydoc_validation.png"&gt;&lt;/p&gt;
&lt;h2&gt;Continuous Integration&lt;/h2&gt;
&lt;p&gt;During the sprint, we provided clear instructions, and we had mentors in each of the 30 different
locations. So, everybody was probably aware that the validation script was one of the main things
they had to check. But regular contributors don't get this sort of induction. So, ideally we would
like to run the checks automatically in the CI, so contributors are aware of any problem in their
proposed changes. But there are some things to consider.&lt;/p&gt;
&lt;p&gt;With Travis, our main CI system, the errors ended up in a huge log, that only experienced
pandas developers are able to understand. See for example &lt;a href="https://travis-ci.org/pandas-dev/pandas/jobs/484898115"&gt;this job&lt;/a&gt;
and make sure you wait until it's fully loaded. :)&lt;/p&gt;
&lt;p&gt;Luckily, at the time our script was being implemented, Numba set up Azure Pipelines for their CI, and we
decided to use it to complement Travis. The main reason was that we required more computational
power for the huge test set of pandas, and the large number of builds. But, I think the clarity
on how the errors can be reported, is as convenient as the 30 concurrent jobs the Azure team
offered us. Compare this with the previous Travis log:&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://user-images.githubusercontent.com/10058240/47961709-1ca90800-e008-11e8-80d7-cccc2c2e5776.png"&gt;&lt;/p&gt;
&lt;p&gt;We were very ambitious, and somehow pioneers in what we were doing, and it wasn't
easy to get what we wanted. But The Azure team was extremely helpful, and the final
presentation of errors in docstrings, as well as the linting errors and others was
much clearer. And friendly for first time contributors.&lt;/p&gt;
&lt;p&gt;Azure pipelines was an improvement, but we still had some challenges. The integration
with GitHub wasn't great, and it required following two links and navigating a somehow
confusing interface to arrive to the page where the errors were being presented in a
better interface than TravisCI.&lt;/p&gt;
&lt;p&gt;Just few days ago we moved this docstring validation, among other things, to
&lt;a href="https://github.com/features/actions"&gt;GitHub Actions&lt;/a&gt;. So far the experience has been
great, and we keep the same advantages as with Pipelines, and also we have a better
integration of the CI with GitHub. And the configuration is also simpler and a bit
more intuitive than with Pipelines.&lt;/p&gt;
&lt;p&gt;We are still figuring out how to notify contributors with a human-readable message
about problems in the CI. Since only experienced contributors know how to find the
problems by themselves. And that's taking time from the reviewers, for a task that
could be easily automated. With GitHub Actions is very easy to write comments in
a pull request, so the only remaining challenge is to obtain all the failures in
all the jobs in a run. But hopefully that's not too complex and we can have it in
place soon.&lt;/p&gt;
&lt;p&gt;Another important thing that the continuos integration can do for us, is to let
us visualize the documentation before being merged. In many cases, small details
make the documentation render in an incorrect way. Like a bold style that doesn't
finish when it's expected to finish. Or a broken table that renders as plain text.&lt;/p&gt;
&lt;p&gt;This has been challenging until now, since CI systems don't do this automatically,
and it's tricky to implement manually. CircleCI provided this feature, but to
access the rendered documentation you had to know the url and replace the id of
your build on it. Maintainers could do that in a not very efficient way, but
first-time contributors couldn't guess.&lt;/p&gt;
&lt;p&gt;Implementing it manually has a main challenge. The CI is usually only able to
access passwords and keys when a pull request is merged. Otherwise a malicious
pull request could access the key and leak it. An option to overcome this limitation
would be to host in a server a GitHub application that receives a webhook when
a pull request is opened or updated, and its docs are built. After being triggered
it would fetch the docs, and publish them somewhere, using a key only accessible
in the server.&lt;/p&gt;
&lt;p&gt;Implementing that was in our backlog for a while. But there is another problem.
Where to host all these copies of the documentation. We use GitHub pages to
host the latest version of our docs. But since Git/GitHub track all the history
of changes, the repo would grow huge very quickly if we add all our docs (around
50Mb) for every pull request.&lt;/p&gt;
&lt;p&gt;The solution to this came easier than expected, since GitHub Actions is able to
access "secrets" from pull request builds. These secrets are private values added
to a repo, and can be used to store our hosting key. And &lt;a href="https://www.ovh.co.uk/"&gt;OVH&lt;/a&gt;
has recently sponsored a new pandas cloud hosting, were we can temporary store
all these versions of the docs. This is being implemented now, and with some
luck should be in production in just couple of days. GitHub Actions will also
make very simple to delete the docs for a PR once it is merged or closed.&lt;/p&gt;
&lt;h2&gt;Validating docstrings in the CI&lt;/h2&gt;
&lt;p&gt;Two key pieces to validate contributions to the pandas docstrings are in place:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A validation script with lots of checks&lt;/li&gt;
&lt;li&gt;A CI system friendly with first time contributors&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;But there is a last piece needed. If we activate the validation in the CI, we will
have 1,000 docstrings, or more, reporting errors in the CI for every PR. Basically,
we will be reported of every error in every docstring that needs to be fixed every
time the CI runs.&lt;/p&gt;
&lt;p&gt;Would be useful to be able to get the errors being introduced, so no more errors
are added, while we fix the ones we already have. But this is not feasible (would be
too complex and too slow).&lt;/p&gt;
&lt;p&gt;This leaves us in a unfortunate position, of only being able to validate what has
already been fixed. Which is extremely useful, as we can guarantee that things don't
get worse. But it doesn't solve our problem of improving the docstrings that need it yet.&lt;/p&gt;
&lt;p&gt;So, what can be done? I think it's useful to divide the docstring checks in two
different categories:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The pure formatting things (like having periods at the end of sentences)&lt;/li&gt;
&lt;li&gt;The ones that require knowledge of pandas and the object being documented
  (like adding examples of how to use an function, or adding an undocumented parameter)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The ones in the first category are somehow easy to fix. And many can be fixes at a time
(in a single pull request), working in one after the other, without stopping much to
understand things.&lt;/p&gt;
&lt;p&gt;Once all the errors of a kind have been fixed, we can start validating that specific
error in the CI. And we guarantee that no more errors of that kind will ever happen.&lt;/p&gt;
&lt;p&gt;And what is even better. Once all those formatting errors are fixed, we can start
working on the docstrings, one at a time. Where a person spends enough time understanding
the function being documented to become an expert. To a point where it can focus on
improving the content, writing a nice summary, useful examples, and document parameters
in an accurate way. And that person won't need to become an expert in reStructuredText
formatting, because the CI warn about any issue. And the person will be able to fix
any problem without requiring time from a maintainer.&lt;/p&gt;
&lt;p&gt;We already completely fixed several of the more than 40, and we validate that the errors are
not added again:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;GL03&lt;/strong&gt;: Use of double blank lines when one would be expected&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GL04&lt;/strong&gt;: Private classes mentioned in public docstrings&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GL05&lt;/strong&gt;: Tabs used instead of 4 spaces&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GL06&lt;/strong&gt;: An unknown section is found&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GL07&lt;/strong&gt;: Sections in the wrong order&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GL09&lt;/strong&gt;: Deprecation warning in the wrong position&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GL10&lt;/strong&gt;: Sphinx directives incorrectly formatted&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SS04&lt;/strong&gt;: Summary contains heading whitespaces&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SS05&lt;/strong&gt;: Summary staring with infinitive verb, not third-person&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PR03&lt;/strong&gt;: Parameters are in the wrong order (compared to the signature)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PR04&lt;/strong&gt;: Parameters without type&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PR05&lt;/strong&gt;: Parameter type finishing with a period (it shouldn't)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PR10&lt;/strong&gt;: Missing space before colon splitting parameter name and type&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;RT01&lt;/strong&gt;: No Returns section&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;RT04&lt;/strong&gt;: Returns description should start with a capital letter&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;RT05&lt;/strong&gt;: Returns description should finish with a period&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SA01&lt;/strong&gt;: No See Also section found&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SA02&lt;/strong&gt;: See Also description should finish with a period&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SA03&lt;/strong&gt;: See Also description should start with a capital letter&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SA05&lt;/strong&gt;: Unneeded prefix in See Also section object&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;EX04&lt;/strong&gt;: pandas or NumPy explicitly imported in the examples (we assume they are always imported)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Those validations have been added to the &lt;a href="https://github.com/pandas-dev/pandas/blob/master/ci/code_checks.sh#L289"&gt;code_checks.sh&lt;/a&gt;
script, which is responsible for many code quality checks (linting, typing, avoidance of unwanted patterns...).&lt;/p&gt;
&lt;p&gt;But there are still many errors that need to be fixed, including formatting errors.&lt;/p&gt;
&lt;p&gt;We are able to get the list of all the errors that we can automatically detect,
with the same script that analyzes a docstring, but without passing an object as a parameter::&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ ./scripts/validate_docstrings.py --format&lt;span class="o"&gt;=&lt;/span&gt;json &amp;gt; docstrings.json
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This will output a JSON file that can easily be loaded into pandas,
and see what needs to be fixed:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt;

&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pandas&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_json&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;docstrings.json&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;orient&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;index&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loc&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;errors&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
      &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;map&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;err_list&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;|&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;err&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;err&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;err_list&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
      &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;str&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_dummies&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;|&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;index&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sort_values&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
      &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;barh&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="" src="/static/img/blog/pandas_doc/pandas_docstring_errors.png"&gt;&lt;/p&gt;
&lt;p&gt;We can see how there are 18 different validations with docstrings that don't pass them.&lt;/p&gt;
&lt;p&gt;The list of all the validations and their error codes can be found in the same
&lt;a href="https://github.com/pandas-dev/pandas/blob/master/scripts/validate_docstrings.py#L77"&gt;validation script code&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We can see for example, how the error &lt;code&gt;GL08&lt;/code&gt;, happening more than 500 times, means that
the objects don't have a docstring at all. See for example
&lt;a href="http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.empty.html"&gt;Series.empty&lt;/a&gt;
Or the second most frequent error, &lt;code&gt;RT03&lt;/code&gt;
means that it is not documented what is being returned (the return type is present, but
there is no description on what's the returned object).&lt;/p&gt;
&lt;p&gt;In total we have 2,441 errors that we can detect automatically. That includes docstrings that
need to be fully created. And creating them requires a lot of time, since there is no documentation
of them, and analyzing the source code, experimenting... is required.&lt;/p&gt;
&lt;h2&gt;Where do we come from?&lt;/h2&gt;
&lt;p&gt;Analyzing the docstrings of past versions of pandas we can see that pandas 0.23 had
7,136 errors, with the current validations. pandas 0.23 was released on the 16th of
May of 2018, couple of month after the worldwide sprint with 500 people. Most of the
work of that sprint was already present in that version.&lt;/p&gt;
&lt;p&gt;This is the detail of errors at that time:&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="/static/img/blog/pandas_doc/pandas_docstring_errors_023.png"&gt;&lt;/p&gt;
&lt;p&gt;So, in 18 months we fixed two thirds of the errors. Assuming it takes the same amount
of time to fix every error, and that we continue at the same pace, in 9 months more we
should have all them fixed. This would amazing, but it's clearly false that all errors
require the same time, and it's obvious that we started by the easy ones. But we are
getting closer.&lt;/p&gt;
&lt;h2&gt;Parallelization, a game changer&lt;/h2&gt;
&lt;p&gt;Our work is every time more challenging and time consuming. Remember that we started with
small formatting changes like adding a period at the end of a sentence, and we are going 
to write full docstrings. So, we need to become smarter and more efficient on how we work on the
documentation. And the most important part is being able to work in parallel, since there is
not much a single person can do.&lt;/p&gt;
&lt;p&gt;Of the around 2,000 docstrings, around 1,400 still have errors (considering errors detected
by the script). Imagine that tomorrow we want to start working on all them. One of the main
problems would be to detect who works on what, and avoid duplicate work. Many people volunteered
in the past to help make the pandas documentation better, and there may be 1,400 people
out there who could be happy to help if they knew exactly what to do.&lt;/p&gt;
&lt;p&gt;How this is usually solved in open source is by creating issues. Then people assigned the
issue they want to work to themselves, and as people join the party, they check in the
list of unassigned issues what else need to be done.&lt;/p&gt;
&lt;p&gt;Unfortunately, a workflow as simple as this has been problematic in GitHub. While GitHub
provides a nice interface for issues, and implements the functionality of assignees, it's
limited to members of the organization (core developers). While this is useful for small
corporate projects, assignees is unused in pandas, and people have been assigning them
issues by mentioning their interest in a comment. Which it kind of works, but it doesn't
let people find unassigned issues in an easy way.&lt;/p&gt;
&lt;p&gt;Recently, we found a hack in pandas, that people is starting to use. With GitHub actions,
we are able to assign issues to people who adds a comment with the exact word `take.
While this is far from optimal, since most users won't be aware of this, it can be very
useful when organizing sprints or coordinated events, where we can communicate with
contributors. We can also write in the issue description about this new feature, so
creating a batch of issues automatically, that we expect people to assign to themselves
seems feasible.&lt;/p&gt;
&lt;p&gt;That's a game changer in parallelizing the work, since it makes the logistics much
simpler in coordinating the contributors. See more information about this new
workflow in this &lt;a href="https://datapythonista.github.io/blog/new-pandas-workflow.html"&gt;recent blog post&lt;/a&gt;
I wrote.&lt;/p&gt;
&lt;p&gt;But there are still some challenges:&lt;/p&gt;
&lt;p&gt;In many cases, pandas has templates for a docstring, that are reused in more
than one object. So different objects can use the same docstring, and it's not
easy to identify which. Creating issues automatically for each object can still
cause overlap in the work.&lt;/p&gt;
&lt;p&gt;While many things can be automated, the main bottleneck are still the reviews of
the changes. There are few people who has the knowledge and experience in pandas
to provide feedback on whether the changes to the documentation are reasonable.
And who has the permissions to merge changes into pandas. And almost all them
are volunteer, and need to take care of other obligations like full time jobs
and family.&lt;/p&gt;
&lt;h2&gt;The future&lt;/h2&gt;
&lt;p&gt;&lt;img alt="" src="/static/img/blog/pandas_doc/panda_babies.jpeg"&gt;&lt;/p&gt;
&lt;p&gt;Exciting times are coming for the pandas documentation. Not only the content, but
also a whole new theme is being implemented. So, soon the documentation will
look much better.&lt;/p&gt;
&lt;p&gt;The CI is getting closer to a level where we can automate as much as possible,
and be very efficient in coordinating the documentation efforts. As well as
let first-time contributors be quite autonomous, and progress independently on
their work until a maintainer can really add value.&lt;/p&gt;
&lt;p&gt;Not only the number of maintainers in the project has been growing significantly
in the last couple of years, but a new role of triaggers has been implemented,
which can be useful in this effor.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://numfocus.org/"&gt;NumFOCUS&lt;/a&gt; has recently awarded us a small development
grant to work on the documentation. And not only will help with the documentation
but hopefully will address a problem as big as it, diversity. A group of people
from groups underrepresented as pandas contributors will be helping with the
documentation, and organizing sprints in different locations to help and
encourage more people to contribute to it.&lt;/p&gt;
&lt;p&gt;Increasing the diversity of the background of the contributors, will not only
help with the quantity of the documentation pages, but also its quantity.
pandas should be useful for a wide variety of people. If the documentation is
made and reviewed by people from different backgrounds (academic backgrounds,
geography, gender...) it will be clearer and more useful to more people, and
will better accomplish its goal.&lt;/p&gt;
&lt;p&gt;The sprints are likely to be in Jakarta, Cairo and Berlin. If you can increase
the diversity of the pandas contributors and want to participate, feel free
to contact me for more details and updates.&lt;/p&gt;
&lt;p&gt;If you would like to organize a pandas documentation sprint for minorities in
a different location, please also get in touch. We are unlikely to be able to
provide funds, but we can help you with everything else.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;And if your company would benefit from a better pandas documentation, please
consider supporting the project. From funding to the project, to funding of
specific developments. And also you can consider hosting an event in your
office, letting your employees spend part of their time working on pandas,
providing in-kind donations, or anything you can think of. Please message
me or any other maintainer to discuss about opportunities.&lt;/strong&gt;&lt;/p&gt;</content><category term="pandas"></category></entry><entry><title>New pandas workflow</title><link href="https://datapythonista.github.io/blog/new-pandas-workflow.html" rel="alternate"></link><published>2019-11-17T00:00:00+00:00</published><updated>2019-11-17T00:00:00+00:00</updated><author><name>Marc Garcia</name></author><id>tag:datapythonista.github.io,2019-11-17:/blog/new-pandas-workflow.html</id><summary type="html">&lt;p&gt;Some exciting news. After some years of organizing &lt;a href="https://python-sprints.github.io/"&gt;sprints&lt;/a&gt;,
and maintaining open source, I've been thinking on a more efficient workflow for projects with
high volume of activity, like &lt;a href="https://pandas.pydata.org/"&gt;pandas&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;An exaggerated example would be that I want to create 1,600 issues in pandas. One for each
docstring of …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Some exciting news. After some years of organizing &lt;a href="https://python-sprints.github.io/"&gt;sprints&lt;/a&gt;,
and maintaining open source, I've been thinking on a more efficient workflow for projects with
high volume of activity, like &lt;a href="https://pandas.pydata.org/"&gt;pandas&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;An exaggerated example would be that I want to create 1,600 issues in pandas. One for each
docstring of the project, with the flaws that we are able to automatically detect. As a
side know, most of our validations to detect incorrect things in docstrings based on the
&lt;a href="https://numpydoc.readthedocs.io/en/latest/format.html"&gt;numpydoc standard&lt;/a&gt; are now available
in &lt;code&gt;numpydoc&lt;/code&gt; (in master). You can check the
&lt;a href="https://numpydoc.readthedocs.io/en/latest/validation.html"&gt;documentation&lt;/a&gt; to
see how to use it. And the &lt;a href="https://github.com/numpy/numpydoc/blob/master/numpydoc/validate.py#L35"&gt;source code&lt;/a&gt;
for the list of errors we validate.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="/static/img/blog/numpydoc_validation.png"&gt;&lt;/p&gt;
&lt;p&gt;Back to the example, &lt;a href="https://developer.github.com/v3/"&gt;GitHub API&lt;/a&gt; and our validations
scripts would make it very easy to create those 1,600 GitHub issues. We could create a
label &lt;code&gt;Docstring errors&lt;/code&gt; to identify them, and ask the community for help to fix
those. The community responded extremely well in the past when we ask them for help.
500 people joined our &lt;a href="https://numfocus.org/blog/worldwide-pandas-sprint"&gt;worldwide documentation sprint&lt;/a&gt;.
So, things seem feasible so far.&lt;/p&gt;
&lt;p&gt;There are just two main problems to make all this work:&lt;/p&gt;
&lt;p&gt;First, there is a small number of maintainers who would have to review, give feedback, and
merge the contributions. 1,600 pull requests is surely too much for a small group
of volunteers. We are surely in a much better position now, than when 500 people
contributed in a single day (it took months to deal with all the pull requests of the sprints).
We are around 12 active maintainers, compared to 4 at that time.
And we've been improving on making our workflow more efficient, with the
CI providing every time better feedback. More accurate, and presented in a better
way, so first time contributors can detect problems in their work without much
intervention from maintainers. &lt;a href="https://github.com/features/actions"&gt;GitHub Actions&lt;/a&gt;
will be key in making our workflow more efficient for code reviews (things like
contributors receiving automated emails when the CI detects something that needs to
be fixed in their work).&lt;/p&gt;
&lt;p&gt;Second, how could people know which of the 1,600 issues are available, and which
are already in the works by someone else? For small projects, GitHub has an option
&lt;code&gt;Assignees&lt;/code&gt; where members of a scrum team can assign to themselves what they are
working on. But this is not possible for a project the size of pandas, since only members
of the organization are able to self-assign issues. And even if we wanted to add
every possible contributor to the pandas GitHub organization, that would be a huge
amount of work for maintainers.&lt;/p&gt;
&lt;p&gt;The best solution should come from GitHub. Adding an option so project admins can
decide whether they want to allow any GitHub user to self-assign issues in their
projects. I've been discussing this with people at GitHub, and it is something it
may be added. But not immediately.&lt;/p&gt;
&lt;p&gt;The good news is that with the help of &lt;a href="https://github.com/features/actions"&gt;GitHub Actions&lt;/a&gt;
is now possible to achieve the same, in a slightly trickier way. We just added
to pandas an &lt;a href="https://github.com/pandas-dev/pandas/pull/29648"&gt;action to self-assign issues&lt;/a&gt;.
How it works is by just writing a comment with the keyword &lt;code&gt;take&lt;/code&gt; to an issue.
And few seconds later, the action will assign the issue to the commenter. This
is possible because few months ago GitHub added a feature to let
&lt;a href="https://github.blog/2019-06-25-assign-issues-to-issue-commenters/"&gt;assign issues to issue commenters&lt;/a&gt;.
It is not possible even for maintainers to assign an issue to an arbitrary user.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="/static/img/blog/github_actions_assign.png"&gt;&lt;/p&gt;
&lt;p&gt;With this simple but powerful change, now a much more efficient workflow should
be possible. The workflow could consist in:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;People interested in contributing to pandas start by &lt;a href="https://python-sprints.github.io/pandas/guide/pandas_setup.html"&gt;setting up the environment&lt;/a&gt;
  and learn &lt;a href="https://docs.google.com/presentation/d/1rOSYXZPyMe9KXnbVK_xbJzw_-ijxd6bIxndmvPU6L2o/edit?usp=sharing"&gt;how to make an open source contribution&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Then they check the list of &lt;a href="https://github.com/pandas-dev/pandas/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22+no%3Aassignee"&gt;unassigned good first issues&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Once they find one that they want to work on, they write a comment with the keyword &lt;code&gt;take&lt;/code&gt; on it&lt;/li&gt;
&lt;li&gt;The issue will disappear from the list of unassigned issues,
  other people won't waste time checking whether it's available or not&lt;/li&gt;
&lt;li&gt;If the person can't finally move forward (got busy, they are not interested anymore...)
  they can simply unassign themselves from the issue, and it will be in the list again&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This new workflow scales to the 1,600 issues or more. Before, potential contributors had
a list with all issues, assigned and not assigned. They had to check each individually for comments
claiming the issue, deal with ambiguity (do messages like "can I work on this?" mean you're working
on the issue?), and possibly have some discussion, before they could know if someone else is working in the issue.&lt;/p&gt;
&lt;p&gt;One obvious problem is if people self-assigning an issue, discontinuing work on it, but not
unassigning the issue. We will see how this works, but even in the worst case, unassigned
issues will still be easy to find if they exist. For the assigned ones, people can check them,
and know immediately who to ask to know if work is still going on, or progress was made.
And to ask if the original assignee is happy to hand over the issue to the new interested contributor.&lt;/p&gt;
&lt;p&gt;Implementing a bot that unassignes issues automatically after N days of inactivity could
also be an option.&lt;/p&gt;</content><category term="pandas"></category></entry><entry><title>Dataframe summit @ EuroSciPy write up</title><link href="https://datapythonista.github.io/blog/dataframe-summit-at-euroscipy.html" rel="alternate"></link><published>2019-09-11T00:00:00+01:00</published><updated>2019-09-11T00:00:00+01:00</updated><author><name>Marc Garcia</name></author><id>tag:datapythonista.github.io,2019-09-11:/blog/dataframe-summit-at-euroscipy.html</id><summary type="html">&lt;p&gt;Last week took place in Bilbao, Spain, &lt;a href="https://www.euroscipy.org/2019/"&gt;EuroSciPy 2019&lt;/a&gt;.
This year we introduced the &lt;a href="https://www.euroscipy.org/2019/maintainers.html"&gt;maintainers track&lt;/a&gt;
a room dedicated to discussions among maintainers. The idea is similar to the 
&lt;a href="https://en.wikipedia.org/wiki/Birds_of_a_feather_(computing)"&gt;birds of a feather&lt;/a&gt; or unconference
sessions of other conferences. But focussed on open source maintainers and contributors. And
we scheduled …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Last week took place in Bilbao, Spain, &lt;a href="https://www.euroscipy.org/2019/"&gt;EuroSciPy 2019&lt;/a&gt;.
This year we introduced the &lt;a href="https://www.euroscipy.org/2019/maintainers.html"&gt;maintainers track&lt;/a&gt;
a room dedicated to discussions among maintainers. The idea is similar to the 
&lt;a href="https://en.wikipedia.org/wiki/Birds_of_a_feather_(computing)"&gt;birds of a feather&lt;/a&gt; or unconference
sessions of other conferences. But focussed on open source maintainers and contributors. And
we scheduled most of the sessions in advanced, to attract the interested people to join the
conference. We also had a maintainers plenary session, in which 26 maintainers of popular
open source scientific projects participated (my guess is that around 50 maintainers attended
the conference).&lt;/p&gt;
&lt;h2&gt;Dataframe summit session&lt;/h2&gt;
&lt;p&gt;One of the sessions was a 2 hours discussion on Python dataframes. 16 people attended it, around
half of them were maintainers of dataframe open source libraries. There were also pandas users
and contributors, maintainers of other projects (PyPy, pytest) and people interested in being involved.
Also the developer of a proprietary dataframe library in Python, who could also add value to the discussion.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="/static/img/blog/dataframe_summit.jpeg"&gt;&lt;/p&gt;
&lt;p&gt;Those were the libraries represented:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/pandas-dev/pandas"&gt;pandas&lt;/a&gt;&lt;/strong&gt; Flexible and powerful data analysis / manipulation library for Python&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/dask/dask"&gt;Dask&lt;/a&gt;&lt;/strong&gt; Parallel computing with task scheduling&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/vaexio/vaex"&gt;Vaex&lt;/a&gt;&lt;/strong&gt; Out-of-Core DataFrames for Python&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/modin-project/modin"&gt;Modin&lt;/a&gt;&lt;/strong&gt; A dataframe framework that scales the pandas API with &lt;a href="https://github.com/ray-project/ray"&gt;Ray&lt;/a&gt; and &lt;a href="https://github.com/dask/dask"&gt;Dask&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/QuantStack/xframe"&gt;xframe&lt;/a&gt;&lt;/strong&gt; DataFrame library in C++&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We started by personal introductions, project introductions, and what people wanted to get out
of the session (many people already proposed topics before the event, and we defined an agenda with those).&lt;/p&gt;
&lt;h3&gt;Document the ecosystem&lt;/h3&gt;
&lt;p&gt;One of the first topics discussed was on how to let users know what is the best dataframe
tool for their job, and how the existing packages are different. The general consensus was
that the &lt;a href="https://pandas.pydata.org/pandas-docs/stable/ecosystem.html"&gt;pandas ecosystem&lt;/a&gt; page
is the best place for it. There are already plans to improve this page (and plans and work in progress to improve
the look and feel of the pandas website and documentation).&lt;/p&gt;
&lt;h3&gt;Apache Arrow&lt;/h3&gt;
&lt;p&gt;Another topic that was discussed early was &lt;strong&gt;&lt;a href="https://arrow.apache.org/"&gt;Apache Arrow&lt;/a&gt;&lt;/strong&gt;. Arrow's mission is to
provide a common memory representation for all dataframe libraries. So, libraries don't need to reinvent the
wheel, and transferring data among packages (e.g. pandas to R) can be done without transformations or even without
copying the memory.&lt;/p&gt;
&lt;p&gt;Vaex is already using Arrow, and pandas has plans in its &lt;a href="https://pandas.pydata.org/pandas-docs/stable/development/roadmap.html"&gt;roadmap&lt;/a&gt;
to move in that direction. People were in general happy with the idea, but there were some concerns
about decisions made in Arrow (mainly contributed by Sylvain, from xframe):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Apache arrow C++ API and implementation not following common C++ idioms&lt;/li&gt;
&lt;li&gt;Using a monorepo (including all bindings in the same repo as Arrow)&lt;/li&gt;
&lt;li&gt;Not a clear distinction between the specification and implementation (as in for instance project Jupyter)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Not only related to Arrow, but it was mentioned that would be useful to have
dataframes for streaming data. A library named &lt;a href="https://github.com/finos/perspective"&gt;Perspective&lt;/a&gt;
exists, which implements something similar, and has &lt;a href="https://github.com/timkpaine/perspective-python/"&gt;Python bindings&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;Interoperability&lt;/h3&gt;
&lt;p&gt;The next topic was about &lt;strong&gt;interoperability&lt;/strong&gt;. How dataframe libraries can interact among them, and
with the rest of the ecosystem. Examples can be:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Using the same plotting backends from different dataframe libraries&lt;/li&gt;
&lt;li&gt;Passing to &lt;a href="https://scikit-learn.org/stable/index.html"&gt;scikit-learn&lt;/a&gt; pandas-like dataframe objects&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There was consensus that defining a standard (and minimal) dataframe API would help. Dataframe libraries
could extend this smaller API and offer users a much bigger APIs (like pandas). But having a subset of
operations and methods would be very useful for third party libraries expecting dataframe objects.&lt;/p&gt;
&lt;p&gt;Devin from Modin is doing research at UC Berkeley on defining this API, and he's already got some
documentation he's happy to share. Modin is already implemented with this design, and while it's
one of the less mature participating projects (in Devin's words), it's user-facing layer could
potentially be reused by other projects reimplementing dataframes with a different backend. Devin
has shared the documentation for this &lt;a href="https://modin.readthedocs.io/en/latest/architecture.html#system-architecture"&gt;design&lt;/a&gt; and the &lt;a href="https://modin.readthedocs.io/en/latest/architecture.html#modin-dataframe-api"&gt;corresponding API&lt;/a&gt; on
the &lt;a href="https://modin.readthedocs.io"&gt;Modin documentation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;It was noted that could be useful to have a common test suite, if a standard dataframe API is defined.
There was agreement that the pandas test suite is not appropriate for other packages.&lt;/p&gt;
&lt;p&gt;NumPy did something similar in &lt;a href="https://numpy.org/neps/nep-0018-array-function-protocol.html"&gt;NEP-18&lt;/a&gt;,
which can be used as reference.&lt;/p&gt;
&lt;h3&gt;Public API improvements&lt;/h3&gt;
&lt;p&gt;At the end of the session, we discussed about possible improvements to the public pandas API.
Since several of the participants reimplemented the pandas API, was a good opportunity to see
places where they found inconsistencies, or where the API was making their lives difficult
when using other approaches.&lt;/p&gt;
&lt;p&gt;Indexing was the part of pandas that other maintainers were less happy about. The way &lt;code&gt;.loc&lt;/code&gt;
behaves was one of the comments. And being forced to have a default index, and not being able
to index by other columns were other comments.&lt;/p&gt;
&lt;h3&gt;Next steps&lt;/h3&gt;
&lt;p&gt;Couple of things were discussed to keep those discussions active, and keep coordinating on
shaping the dataframes of the future.&lt;/p&gt;
&lt;p&gt;The first was to start a workgroup, or a distribution list (or discourse). The &lt;code&gt;pandas-dev&lt;/code&gt;
list wasn't used by the participants (except the pandas maintainers), and it didn't seem
to be the appropriate place.&lt;/p&gt;
&lt;p&gt;Another idea would be to organize another bigger dataframe summit in the future. It was
proposed to be hosted somewhere in the Caribbean (ok, it was me who proposed that, and
everybody else laughed, but here I leave it again). :)&lt;/p&gt;</content><category term="pandas"></category></entry><entry><title>pandas: The two cultures</title><link href="https://datapythonista.github.io/blog/pandas-the-two-cultures.html" rel="alternate"></link><published>2019-07-22T23:26:00+01:00</published><updated>2019-07-22T23:26:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2019-07-22:/blog/pandas-the-two-cultures.html</id><summary type="html">&lt;p&gt;&lt;img alt="" src="/static/img/blog/two_cultures/leo_breiman.jpeg"&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.stat.berkeley.edu/~breiman/"&gt;Leo Breiman&lt;/a&gt; was a distinguished statistician at
UC Berkeley, known among other things for his major contributions to CART (decision trees),
and ensemble techniques, mainly bootstrap aggregation. Combining both, he was able to define
one of the most popular machine learning models even today (18 years after the publication
of …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img alt="" src="/static/img/blog/two_cultures/leo_breiman.jpeg"&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.stat.berkeley.edu/~breiman/"&gt;Leo Breiman&lt;/a&gt; was a distinguished statistician at
UC Berkeley, known among other things for his major contributions to CART (decision trees),
and ensemble techniques, mainly bootstrap aggregation. Combining both, he was able to define
one of the most popular machine learning models even today (18 years after the publication
of the paper), &lt;a href="https://www.stat.berkeley.edu/~breiman/randomforest2001.pdf"&gt;Random forests&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In 2001, Breiman published the paper
&lt;a href="http://www2.math.uu.se/~thulin/mm/breiman.pdf"&gt;Statistical Modeling: The Two Cultures&lt;/a&gt;.
In it, Breiman identified that there were two somehow conflicting cultures in the discipline
of statistical modeling. One that was focusing on modeling (and trying to understand) the
stochastic process generating some random data. While the other followed an algorithmic
approach focused on obtaining results (minimizing the error between the model results and
the data), and considered the stochastic process a black box. Today we would probably call
them &lt;em&gt;statistics&lt;/em&gt; and &lt;em&gt;machine learning&lt;/em&gt;, and the division between them is clear. And in a way,
machine learning is not even considered part of statistics. While this division among the two
fields may or may not be a good thing, identifying in 2001 that both communities existed, were
different and had different needs, surely helped overcome the frustration of both communities at
that time, and sped up their development. One example that illustrate the differences can be
seen on how in the area of neural networks, publishing research papers is mostly driven by 
the obtained results, more than by the theory behind the results. Ali Rahimi gave
&lt;a href="https://www.youtube.com/watch?v=Qi1Yry33TQE"&gt;his view&lt;/a&gt; on this when receiving the test-of-time
award at NeurIPS 2017.&lt;/p&gt;
&lt;p&gt;But this post is not about machine learning, but about &lt;a href="https://pandas.pydata.org/"&gt;pandas&lt;/a&gt;.
And about the two cultures in the pandas community, that I personally don't think are often
well identified, causing frustration to some users, and making more complex taking decisions
regarding the API of the project.&lt;/p&gt;
&lt;h2&gt;Dr Jekyll and Mr Hyde&lt;/h2&gt;
&lt;p&gt;&lt;img alt="" src="/static/img/blog/two_cultures/dr_jekyll_mr_hyde.jpeg"&gt;&lt;/p&gt;
&lt;p&gt;To describe the two cultures, let me talk about my own professional experience.
For the last years I've been mainly working as a data scientist. Since the developers of
&lt;a href="https://scikit-learn.org/stable/"&gt;scikit-learn&lt;/a&gt; are doing all the &lt;em&gt;fun&lt;/em&gt; work in machine learning,
and implementing all the complex algorithms for the rest of us, I'll argue that my job (and the
job of many other data scientists, some will probably disagree) is to work on data analysis to
find out what needs to be done, and data engineering to make it work in production.&lt;/p&gt;
&lt;p&gt;What I call &lt;strong&gt;data analysis&lt;/strong&gt; is performed in a &lt;a href="https://jupyter.org/"&gt;Jupyter notebook&lt;/a&gt;,
where I analyze and visualize the data. I found out what is wrong with it, and I quickly
grow the cells of my &lt;code&gt;Untitled23.ipynb&lt;/code&gt; hoping I'll never have to look back at my dirty code.
What I value the most is being able to write code fast, and focus in the problem I'm solving, and
not in the code. To the extend I alias every Python library I import with incomprehensible names
like &lt;code&gt;np&lt;/code&gt;, &lt;code&gt;pd&lt;/code&gt;, &lt;code&gt;plt&lt;/code&gt;,... to make sure I save few microseconds compared to typing the actual
names. And I really appreciate the software making as many decisions as needed to save me from
having to spend the time on being explicit on what I want. Ok, this may be a bit exaggerated,
I don't really let my notebook names be untitled whatever, or use aliases, but I think you get the idea.&lt;/p&gt;
&lt;p&gt;On the other hand, when working in &lt;strong&gt;data engineering&lt;/strong&gt; I use vim, and I write all my code in
Python files in a clear directory structure. Every file and directory are carefully named so I can
easily find them later. Every function is well documented, and the best coding standards are applied.
All my code is version controlled with git, and code reviewed by my colleagues. I write every single
line of code knowing that I will have to revisit it many times, and I optimize for its simplicity and
its clarity.  The thing I'm more adverse to is &lt;em&gt;magic&lt;/em&gt; happening, and any software making decisions
for me. I want to be in control, I want everything in my code to be deterministic, and I want
everything in my code to be explicit. Everything that Tim Peters wrote in
&lt;a href="https://www.python.org/dev/peps/pep-0020/"&gt;PEP-20&lt;/a&gt;, the Zen of Python, applies:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Beautiful is better than ugly.&lt;/li&gt;
&lt;li&gt;Explicit is better than implicit.&lt;/li&gt;
&lt;li&gt;Simple is better than complex.&lt;/li&gt;
&lt;li&gt;Readability counts.&lt;/li&gt;
&lt;li&gt;Errors should never pass silently.&lt;/li&gt;
&lt;li&gt;...&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;One pandas to rule them all&lt;/h2&gt;
&lt;p&gt;&lt;img alt="" src="/static/img/blog/two_cultures/ring.jpeg"&gt;&lt;/p&gt;
&lt;p&gt;What I find the most interesting part about &lt;em&gt;the two cultures&lt;/em&gt; I just described, is that I use
pandas for both. I think pandas is the best tool for both use cases, and I won't admit I'm biased
here, since I'm a pandas maintainer because I use the software, and not the other way round.&lt;/p&gt;
&lt;p&gt;But how is that possible? Both use cases are radically different. Is pandas designed in a way that
is able offer both kind of users the API and features they need? Is that always possible?&lt;/p&gt;
&lt;p&gt;The next of this post will try to find an answer by analyzing some examples.&lt;/p&gt;
&lt;h2&gt;Show me the code&lt;/h2&gt;
&lt;h3&gt;Creating data from a Python dict&lt;/h3&gt;
&lt;p&gt;Let's start with a single example, by manually creating some data:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt;

&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;num_legs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pandas&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Series&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;unicorn&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;spider&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;penguin&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;})&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;num_legs&lt;/span&gt;
&lt;span class="n"&gt;unicorn&lt;/span&gt;    &lt;span class="mi"&gt;4&lt;/span&gt;
&lt;span class="n"&gt;spider&lt;/span&gt;     &lt;span class="mi"&gt;8&lt;/span&gt;
&lt;span class="n"&gt;penguin&lt;/span&gt;    &lt;span class="mi"&gt;2&lt;/span&gt;
&lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;int64&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I think we can agree that pandas is letting us create our data in the simplest possible way. There
could be other ways (and there are other ways that pandas supports), but creating a Series looks to
me as simple as it can be. That's what I want as a data analyst.&lt;/p&gt;
&lt;p&gt;But as a data engineer, there are more things to consider. Imagine that my data, instead of having 3
samples, had 3 million. How much memory is pandas consuming to store in memory my data? And why?
For simplicity, let's consider only the values (and not the name of the animals):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;num_legs&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;memory_usage&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="mi"&gt;24&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The values in our Series are consuming 24 bytes. If we see again the representation of our Series,
we can see how the data type (aka dtype) is &lt;code&gt;int64&lt;/code&gt;. Meaning that every value will consume 64
bits (8 bytes). 8 bytes per value, multiplied by 3 values (the number of legs for unicorn, spider
and penguin) totals 24 bytes. But why 64 bits? pandas decided for us that representation, which can
store numbers from around -9e18 to 9e18. But do we really expect animals to have a number of legs
with 18 digits? Or do we expect negative numbers of legs at all? Probably not. We know it, but
pandas doesn't. Because pandas doesn't know anything about our domain, or what is reasonable,
it's deciding for us a conservative representation for our data that won't cause us problems
(as opposed as one that saves some memory).&lt;/p&gt;
&lt;p&gt;This is working well for us as data analysts, but not as data engineers writing production code.
In this case, the Series constructor has a parameter &lt;code&gt;dtype&lt;/code&gt; that we can use to tell pandas to not
decide for us how to internally represent the data, but to tell it explicitly. This is the result:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt;

&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;num_legs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pandas&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Series&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;unicorn&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;spider&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;penguin&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;
&lt;span class="o"&gt;...&lt;/span&gt;                          &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;uint8&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;num_legs&lt;/span&gt;
&lt;span class="n"&gt;unicorn&lt;/span&gt;    &lt;span class="mi"&gt;4&lt;/span&gt;
&lt;span class="n"&gt;spider&lt;/span&gt;     &lt;span class="mi"&gt;8&lt;/span&gt;
&lt;span class="n"&gt;penguin&lt;/span&gt;    &lt;span class="mi"&gt;2&lt;/span&gt;
&lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;uint8&lt;/span&gt;

&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;num_legs&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;memory_usage&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="mi"&gt;3&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;In this example, pandas provides a reasonable API for both kind of users. It doesn't force us to
specify the data type when we don't care. But we're able to when we do care. Whether we want to
optimize for our system resources (mainly memory) or our own time is up to us.&lt;/p&gt;
&lt;h3&gt;How many legs do unicorns have?&lt;/h3&gt;
&lt;p&gt;&lt;img alt="" src="/static/img/blog/two_cultures/unicorn.jpeg"&gt;&lt;/p&gt;
&lt;p&gt;An important question we face is, how many legs do unicorns have? In the previous example, we specified
they have 4, but do unicorns really have 4 legs? Did anybody have ever seen a unicorn? Let's try to be
prudent and say that we don't know how many legs they have. By convention, when we have an unknown
or missing value, we represent it as &lt;code&gt;NaN&lt;/code&gt; (Not a Number). Every number in a computer is represented
using binary numbers (e.g. &lt;code&gt;01001011&lt;/code&gt;). &lt;code&gt;NaN&lt;/code&gt; is represented internally as one specific sequence of
bits, reserved to have the meaning of &lt;code&gt;NaN&lt;/code&gt;. There is a convention that &lt;em&gt;translates&lt;/em&gt; how every binary
sequence corresponds to the number they represent. And this &lt;em&gt;translation&lt;/em&gt; has some exceptions, including
one value that represents the floating point number &lt;code&gt;NaN&lt;/code&gt;. If that sounds too complex, think that in
binary, &lt;code&gt;0000&lt;/code&gt; can represent the number 0, &lt;code&gt;0001&lt;/code&gt; the 1, &lt;code&gt;0010&lt;/code&gt;: 2, &lt;code&gt;0011&lt;/code&gt;: 3... and &lt;code&gt;1111&lt;/code&gt;: 15.
And what microprocessors manufacturers decided is something like letting represent only from 0 to 14
(instead of from 0 to 15, that we could encode with 4 bits), and reserve the &lt;code&gt;1111&lt;/code&gt; to mean &lt;code&gt;NaN&lt;/code&gt;.
Things are in reality more complex, since &lt;code&gt;NaN&lt;/code&gt; representations only exists for floating points numbers
(aka float), which are decimals. But that explanation should give an intuition.&lt;/p&gt;
&lt;p&gt;So, back to the example, if we want to represent that we don't know how many legs unicorns have, we
can simply do:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;num_legs&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;unicorn&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;NaN&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;num_legs&lt;/span&gt;
&lt;span class="n"&gt;unicorn&lt;/span&gt;    &lt;span class="n"&gt;NaN&lt;/span&gt;
&lt;span class="n"&gt;spider&lt;/span&gt;     &lt;span class="mf"&gt;8.0&lt;/span&gt;
&lt;span class="n"&gt;penguin&lt;/span&gt;    &lt;span class="mf"&gt;2.0&lt;/span&gt;
&lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;float64&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Many things happened here. We can see, how besides the expected change of having &lt;code&gt;NaN&lt;/code&gt; unicorn legs,
now we are back to consuming 64 bits. And not only that, but also the rest of values in the column now are
decimal (float) values. As I just explained, and can also be seen in the example on how &lt;code&gt;NaN&lt;/code&gt; is created,
&lt;code&gt;NaN&lt;/code&gt; is a float value. Modern computers don't have an integer representation for &lt;code&gt;NaN&lt;/code&gt;, so for pandas
to do what we asked it to do, converting the column to float was the &lt;em&gt;only&lt;/em&gt; option (not really the only,
but let's pretend for a second).&lt;/p&gt;
&lt;p&gt;It feels a bit weird to see in the Series representation that a penguin has 2.0 legs. It's conceptually
wrong, and also misleading making us believe that animals can have a decimal number of legs. There are
also technical implications too, we are consuming 4 times more memory now. And also operations among
integers don't take the same time as operations among floats at the CPU level (note that while floats
are a more complex representation, modern CPU's are highly optimized for them, and operations can even be
faster for floats than for integers).&lt;/p&gt;
&lt;p&gt;But there is something else, see this example:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="mf"&gt;0.1&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mf"&gt;0.2&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mf"&gt;0.3&lt;/span&gt;
&lt;span class="bp"&gt;False&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Floating point numbers are approximations. They are mapping an infinite set of numbers (let's say all
real numbers) to the finite set of possible representations with 64 bits (&lt;code&gt;2 ** 64&lt;/code&gt;). In many
cases using this approximate values won't make a difference (the height of a person keeps being the
same if we change the 20th decimal). But, if for example a column contains an integer id that we use
to join two data sets, converting it to floating point can mean data loss or bugs. Since floating points
are just approximations, we may try to join by &lt;code&gt;20.0000000001 == 19.9999999999&lt;/code&gt;, which won't match.
So, converting an integer column to its floating point representation can be dangerous, and probably
more for the data engineering use cases described before.&lt;/p&gt;
&lt;p&gt;In pandas 0.24 we introduced a new data type to mix integer values with missing values. This is done
by instead of using the float &lt;code&gt;NaN&lt;/code&gt; to represent the missing values, we internally keep a separate
Boolean array that identifies where the missing values are. This adds an extra layer of complexity
inside pandas, but avoids problems like the one just described. By default, pandas still uses the
original types, but we can write the previous code as follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;num_legs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pandas&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Series&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;unicorn&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;spider&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;penguin&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;
&lt;span class="o"&gt;...&lt;/span&gt;                          &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;UInt8&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;num_legs&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;unicorn&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;NaN&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;num_legs&lt;/span&gt;
&lt;span class="n"&gt;unicorn&lt;/span&gt;    &lt;span class="n"&gt;NaN&lt;/span&gt;
&lt;span class="n"&gt;spider&lt;/span&gt;       &lt;span class="mi"&gt;8&lt;/span&gt;
&lt;span class="n"&gt;penguin&lt;/span&gt;      &lt;span class="mi"&gt;2&lt;/span&gt;
&lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;UInt8&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Note that &lt;code&gt;UInt8&lt;/code&gt; represents the pandas type with the mask, and &lt;code&gt;uint8&lt;/code&gt; (lowercase) represents the
original type based on numpy. Also note that the new type may not be as stable as the old, and may not
implement all the operations.&lt;/p&gt;
&lt;p&gt;While the new data type fixes this specific problem, the fact that pandas silently casts a data type
when needed is very convenient for the use cases of data analysts, but in my opinion does a poor job
to the interests of precision and reliability of data engineers. And while the &lt;code&gt;.loc[]&lt;/code&gt; syntax is very
convenient, doesn't allow us to solve the problem with a simple parameter. A new
&lt;a href="https://pandas.pydata.org/pandas-docs/stable/user_guide/options.html"&gt;pandas option&lt;/a&gt; could be an option
to control whether we want pandas to automatically cast columns when needed, or raise an exception instead.
But as far as I know, there has not been discussion about it.&lt;/p&gt;
&lt;h2&gt;The most popular pandas function&lt;/h2&gt;
&lt;p&gt;CSV is in general a poor format to store data. It has a clear advantage, that is being able
to open CSV files in a text editor. Other than that, I think all are disadvantages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Inefficient storage (space that file uses in disk)&lt;/li&gt;
&lt;li&gt;Inefficient I/O (because the volume of data, and also the required casting)&lt;/li&gt;
&lt;li&gt;Lack of types (everything is a string in a CSV, so original types are lost)&lt;/li&gt;
&lt;li&gt;Lack of a standard (different quoting, delimiters,...)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Despite of those, CSV happens to be one of the most popular formats out there, being the
page &lt;a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html"&gt;pandas.read_csv&lt;/a&gt;
the one with most visits in the pandas documentation.&lt;/p&gt;
&lt;p&gt;To manage all the trickiness of the format, &lt;code&gt;pandas.read_csv&lt;/code&gt; provides as much as 50
arguments, to customize for your file format, and for your needs.
&lt;a href="https://github.com/InvestmentSystems/static-frame"&gt;StaticFrame&lt;/a&gt; a project (somehow)
aiming to compete with pandas, contains the next sentence in its README file:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The Pandas CSV reader far out-performs the NumPy-based reader in StaticFrame: thus, for now, using Frame.from_pandas(pd.read_csv(fp)) is recommended for loading CSV files.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This gives an idea of all the complexity in the CSV parser, not only in terms of the parameters,
but also in terms of how optimized it is for performance.&lt;/p&gt;
&lt;p&gt;Despite being one of the most powerful and optimized CSV parsers out there,
&lt;a href="http://twitter.com/dontusethiscode"&gt;James Powell&lt;/a&gt; gave a
&lt;a href="https://www.youtube.com/watch?v=QkQ5HHEu1b4&amp;amp;t=1554"&gt;lightning talk at PyData London 2019&lt;/a&gt;
on how the parser could be easily improved in several ways for a use case he's got.&lt;/p&gt;
&lt;p&gt;Those include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Assume string columns are properly encoded and load them directly into memory&lt;/li&gt;
&lt;li&gt;Optimize date casting by assuming a specific format, and a limited set of values&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Again, no matter the great job done in implementing pandas, the software is
being unable to fully satisfy all user cases. &lt;code&gt;pandas.read_csv&lt;/code&gt; does again a
good job at making life easy to data analysts (as defined at the beginning of this
post). And it also does an impressive job at adding parameters to empower users that
know what they are doing and have production-ready code need (data engineers). But
even with an insane number of parameters like 50, looks like loading a CSV file into
memory may be too complex for a single generic function.&lt;/p&gt;
&lt;p&gt;What is the solution here? Personally, I think that having &lt;em&gt;one pandas to rule them all&lt;/em&gt;
is still possible and the best option. But not a &lt;code&gt;pandas.read_csv&lt;/code&gt; to rule them all.
My view is that pandas shouldn't include I/O modules that are able to load data from
every possible format, and in every possible way. That's just impossible.
But pandas could do a better job at allowing and encouraging an ecosystem of I/O
pandas plugins. I proposed in &lt;a href="https://github.com/pandas-dev/pandas/issues/26804"&gt;this issue&lt;/a&gt;
a first refactoring that would make this possible. It is still under discussion,
since the proposed changes are big.  I'll write in a different article more details about this proposal.&lt;/p&gt;
&lt;h2&gt;Lazy pandas&lt;/h2&gt;
&lt;p&gt;&lt;img alt="" src="/static/img/blog/two_cultures/lazy_pandas.jpeg"&gt;&lt;/p&gt;
&lt;p&gt;To conclude this article, I will talk about what in my opinion is one of the biggest
differences between the needs of data analysts using pandas in a Jupyter notebook,
compared to data engineers using it to write production pipelines.&lt;/p&gt;
&lt;p&gt;See this example:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;num_legs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pandas&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Series&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;unicorn&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;spider&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;penguin&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;})&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;num_legs&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;median&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="mf"&gt;4.0&lt;/span&gt;

&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;num_legs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;num_legs&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;to_frame&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;num_legs&lt;/span&gt;
         &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="n"&gt;unicorn&lt;/span&gt;  &lt;span class="mi"&gt;4&lt;/span&gt;
&lt;span class="n"&gt;spider&lt;/span&gt;   &lt;span class="mi"&gt;8&lt;/span&gt;
&lt;span class="n"&gt;penguin&lt;/span&gt;  &lt;span class="mi"&gt;2&lt;/span&gt;

&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;num_legs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;num_legs&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rename&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;legs&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;})&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;num_legs&lt;/span&gt;
         &lt;span class="n"&gt;legs&lt;/span&gt;
&lt;span class="n"&gt;unicorn&lt;/span&gt;     &lt;span class="mi"&gt;4&lt;/span&gt;
&lt;span class="n"&gt;spider&lt;/span&gt;      &lt;span class="mi"&gt;8&lt;/span&gt;
&lt;span class="n"&gt;penguin&lt;/span&gt;     &lt;span class="mi"&gt;2&lt;/span&gt;

&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;num_legs&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;kind&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;num_legs&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;legs&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;biped&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="o"&gt;...&lt;/span&gt;                                              &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;quadruped&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="o"&gt;...&lt;/span&gt;                                              &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;octoped&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;})&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;num_legs&lt;/span&gt;
         &lt;span class="n"&gt;legs&lt;/span&gt;       &lt;span class="n"&gt;kind&lt;/span&gt;
&lt;span class="n"&gt;unicorn&lt;/span&gt;     &lt;span class="mi"&gt;4&lt;/span&gt;  &lt;span class="n"&gt;quadruped&lt;/span&gt;
&lt;span class="n"&gt;spider&lt;/span&gt;      &lt;span class="mi"&gt;8&lt;/span&gt;    &lt;span class="n"&gt;octoped&lt;/span&gt;
&lt;span class="n"&gt;penguin&lt;/span&gt;     &lt;span class="mi"&gt;2&lt;/span&gt;      &lt;span class="n"&gt;biped&lt;/span&gt;

&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;num_legs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;num_legs&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;num_legs&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;legs&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;=&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
         &lt;span class="n"&gt;legs&lt;/span&gt;       &lt;span class="n"&gt;kind&lt;/span&gt;
&lt;span class="n"&gt;unicorn&lt;/span&gt;     &lt;span class="mi"&gt;4&lt;/span&gt;  &lt;span class="n"&gt;quadruped&lt;/span&gt;
&lt;span class="n"&gt;penguin&lt;/span&gt;     &lt;span class="mi"&gt;2&lt;/span&gt;      &lt;span class="n"&gt;biped&lt;/span&gt;

&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;num_legs&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;to_parquet&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;num_legs.parquet&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;And compare it with this other code:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pandas&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Series&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;unicorn&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;spider&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;penguin&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;})&lt;/span&gt;
&lt;span class="o"&gt;...&lt;/span&gt;        &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;to_frame&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="o"&gt;...&lt;/span&gt;        &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rename&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;legs&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;})&lt;/span&gt;
&lt;span class="o"&gt;...&lt;/span&gt;        &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;assign&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;kind&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;legs&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;biped&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="o"&gt;...&lt;/span&gt;                                                    &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;quadruped&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="o"&gt;...&lt;/span&gt;                                                    &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;octoped&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;}))&lt;/span&gt;
&lt;span class="o"&gt;...&lt;/span&gt;        &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;query&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;legs &amp;lt;= 4&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;...&lt;/span&gt;        &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;to_parquet&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;num_legs.parquet&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Before you are tempted to think on which one is better, let's discuss which
problem solves each of them.&lt;/p&gt;
&lt;p&gt;The first version is part of an iterative process where at every step we need
to visualize how our data looks like. We also may need not only to visualize the
data, but &lt;em&gt;understand&lt;/em&gt; or verify it, for example by checking which is the median
of one column. It is likely that at the end of writing that code, we don't care
about it anymore, since we already verified what was in the data, and extracted
the insights we care about.&lt;/p&gt;
&lt;p&gt;In the second case, while doing almost the same, the code is written to be read
and to be maintained. If there is a bug in the code, it should be easy to
understand what it does, and fix it. The goal is not to discover anything
while writing the code. But just to add a functionality to a system, and to be
able to run it in a reliable and performant way.&lt;/p&gt;
&lt;p&gt;For more information about the style in the second approach, you can check
the must-read &lt;a href="https://tomaugspurger.github.io/method-chaining"&gt;Method Chaining&lt;/a&gt;
by the pandas maintainer &lt;a href="https://tomaugspurger.github.io/pages/about.html"&gt;Tom Augspurger&lt;/a&gt;.
Also, I discussed about method chaining in my talk
&lt;a href="https://www.youtube.com/watch?v=hK6o_TDXXN8"&gt;Towards pandas 1.0&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Back to the example, pandas let us write code in a way that suits both
data analysts and data engineers. But there is something else that is worth
considering. In the first version, the operations must be executed one at
a time, since they are independent. But in the example using method chaining,
there is no need to execute anything until &lt;code&gt;to_parquet&lt;/code&gt; is run. The reason
is that the result is not made available to the user or anywhere else.&lt;/p&gt;
&lt;p&gt;This may sound irrelevant at first, since we are going to execute it anyway.
But being able to postpone the actual execution until a later stage, can
be extremely useful in some situations. In the example, if pandas postpones
the execution until it knows all what the user wants to do with all the data,
it could optimize the execution. For example, if the row of the spider is
going to be discarded, why load it to memory and why compute which is its
kind? Some memory and some computation power and time can be saved. In this
toy example it doesn't make a difference, but imagine you want to operate
with 1Tb of data in a file, apply some transformations,
and save the result in another file in disk. With the &lt;em&gt;data analyst approach&lt;/em&gt;
this is not feasible when running the code in a normal laptop. And while
pandas is not able to work in an out-of-core way, or optimize the execution
even when using method chaining, that could be implemented.&lt;/p&gt;
&lt;p&gt;There are related tools where this lazy execution approach already
exists, mainly &lt;a href="https://dask.org/"&gt;Dask&lt;/a&gt;. Dask implements a
pandas-like API, where operations are evaluated in a lazy way, and the
final task graph is not only optimized, but distributed over a cluster.
&lt;a href="https://github.com/vaexio/vaex"&gt;Vaex&lt;/a&gt; is another example of pandas-like
API implemented with lazy evaluation.
&lt;a href="https://youtu.be/2Tt0i823-ec"&gt;This talk&lt;/a&gt; has a demo showing how Vaex
uses lazy evaluation to deal with data sets with more than one billion
rows.&lt;/p&gt;
&lt;p&gt;Lazy evaluation may be out of scope for pandas, and there are many things
that should be changed even before being considered. But in my opinion is
another example on the different needs of the different pandas users.&lt;/p&gt;
&lt;p&gt;I guess a dual pandas would be possible, and for the user, may be a
simple pandas option &lt;code&gt;pandas.options.lazy_execution = True&lt;/code&gt; would be enough.
Together with few methods to allow users to trigger the execution of a task
graph (e.g. a &lt;code&gt;.collect()&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;There are also other approaches that could be considered. With the recent
addition of &lt;a href="https://pandas.pydata.org/pandas-docs/stable/development/extending.html#extension-types"&gt;pandas extension arrays&lt;/a&gt;,
custom data types can be implemented. And having types for memory
maps, or calculated columns could be an option that could allow
some sort of laziness. In the example, we could have a normal
DataFrame, that could have a kind column that does not actually save
the strings &lt;code&gt;biped&lt;/code&gt;, &lt;code&gt;quadruped&lt;/code&gt;,... but instead stores the
function applied, and to which column. The actual lookup could then
happen after the data is filtered.&lt;/p&gt;
&lt;p&gt;Whatever could be the approach, it would require major changes to
pandas internals, and it's not something that could be implemented
easily. Custom data types can be implemented, but currently some
operations will convert the data to numpy arrays, and would not
allow having a proper lazy data type.&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;I think the number of pandas users, and the different kinds of work
that are being done are evidence of many good design decisions and
implementation. But conflicting interests among groups of users do
exist. In some cases is doable to find a good solution for most
use cases. In others is not obvious and serving better our users would
require a huge amount of work.&lt;/p&gt;
&lt;p&gt;Personally, I think a more modular pandas architecture would make it
easier to adjust to every kind of user. By having more than one version
of &lt;code&gt;pandas.read_csv&lt;/code&gt; different users could implement solutions that
better suit their needs. Same could apply to other areas.&lt;/p&gt;
&lt;p&gt;But probably the most important challenge to get those implemented is
not what is the technical solution, but it's in how pandas is developed.
The project is mostly developed by volunteers, including the maintainers
(the people who review the contributions, discuss in the issues that
users open...). Our roadmap is not determined by the needs
of your company or your industry. In my personal case, my roadmap
is determined by my personal interests on what I want to work on,
and on the kind of things I need or I want to see in pandas myself.
If your company would be more productive with certain pandas features or
developments, you should consider hiring someone to improve pandas
based in your interests. You can contact &lt;a href="https://numfocus.org/"&gt;NumFOCUS&lt;/a&gt;
who manages the pandas funding, can assist with any question, and
is in direct contact with the pandas maintainers. Besides hiring someone
in your own team, you could also provide funds to develop pandas that
are managed by NumFOCUS. Also feel free to &lt;a href="mailto:garcia.marc@gmail.com"&gt;contact me&lt;/a&gt;
directly if you want more advice, and are interested in this.&lt;/p&gt;</content><category term="pandas"></category></entry><entry><title>Setting up Fedora</title><link href="https://datapythonista.github.io/blog/setting-up-fedora.html" rel="alternate"></link><published>2018-12-05T00:00:00+00:00</published><updated>2018-12-05T00:00:00+00:00</updated><author><name>Marc Garcia</name></author><id>tag:datapythonista.github.io,2018-12-05:/blog/setting-up-fedora.html</id><summary type="html">&lt;p&gt;Today I've got my new Dell XPS (with Ubuntu preinstalled), and this is the procedure
to set it up, and get my perfect working environment. This is expected to be useful
mainly for my &lt;strong&gt;future self&lt;/strong&gt;, but sharing it here in case someone else can find
ideas or tips that …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Today I've got my new Dell XPS (with Ubuntu preinstalled), and this is the procedure
to set it up, and get my perfect working environment. This is expected to be useful
mainly for my &lt;strong&gt;future self&lt;/strong&gt;, but sharing it here in case someone else can find
ideas or tips that are useful. Also happy to receive comments on how you do things
differently (and potentially better).&lt;/p&gt;
&lt;p&gt;My operating system of choice is &lt;a class="reference external" href="https://spins.fedoraproject.org/mate-compiz/"&gt;Fedora MATE Compiz&lt;/a&gt;,
I think GNOME 3 was a big mistake, so staying in what was GNOME 2.&lt;/p&gt;
&lt;p&gt;After downloading the ISO, I create the live USB with &lt;a class="reference external" href="https://unetbootin.github.io/"&gt;UNetbootin&lt;/a&gt;.
This works well, but it has a problem. The label of the volume is not updated, and it becomes inconsistent
with the one that GRUB loads. This will create a lot of warnings like this:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
dracut-initqueue[602]: Warning dracut-initqueue timeout - starting timeout scripts
&lt;/pre&gt;
&lt;p&gt;With couple of final warnings:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
Warning: /dev/disk/by-label/Fedora-Live-WS-x86_64-29-1 does not exist
Warning: /dev/mapper/live-rw does not exist
&lt;/pre&gt;
&lt;p&gt;To fix it, we just need to know the label of our live USB (can be obtained in the rescue terminal by
calling &lt;tt class="docutils literal"&gt;blkid&lt;/tt&gt;). And then, in the GRUB menu, press &lt;cite&gt;e&lt;/cite&gt; with the &lt;cite&gt;Start Fedora Live&lt;/cite&gt; option
selected, and replace the value of &lt;cite&gt;LABEL&lt;/cite&gt; by the correct one. A &lt;cite&gt;Ctrl-x&lt;/cite&gt; will make the system
boot with the updated configuration, and should start normally. This
&lt;a class="reference external" href="https://www.youtube.com/watch?v=C3iSqmfPRxY"&gt;video&lt;/a&gt; shows the process step by step.&lt;/p&gt;
&lt;p&gt;The default configurations during the installation work well for me (using 50Gb for &lt;cite&gt;/&lt;/cite&gt;, the rest
for &lt;cite&gt;/home/&lt;/cite&gt;, and &lt;cite&gt;ext4&lt;/cite&gt; filesystem). But I encrypt &lt;cite&gt;/home/&lt;/cite&gt;, which is not enabled by default.&lt;/p&gt;
&lt;p&gt;Once the new system is installed, and running, those are the tasks I perform.&lt;/p&gt;
&lt;div class="section" id="configuration"&gt;
&lt;h2&gt;Configuration&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;Merge both panels into one, and leave it to the bottom (removing the workspaces and Thunderbird,
which I not use)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Mouse setup: enable touchpad click, natural scrolling and increase acceleration&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Disable screensaver, and make windows be selected when mouse moves over them&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Change the terminal shorcuts to change and move tabs (I got used to the KDE shortcuts and never
bothered in learning the GNOME ones)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Change the default search engine in Firefox to &lt;a class="reference external" href="https://duckduckgo.com/"&gt;DuckDuckGo&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Set up couple of aliases in &lt;cite&gt;~/.bashrc&lt;/cite&gt;: &lt;tt class="docutils literal"&gt;alias &lt;span class="pre"&gt;rgrep=&amp;quot;grep&lt;/span&gt; &lt;span class="pre"&gt;-R&amp;quot;&lt;/span&gt;&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;alias &lt;span class="pre"&gt;vi=&amp;quot;vim&amp;quot;&lt;/span&gt;&lt;/tt&gt; (which
doesn't seem to be required anymore)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Set up &lt;cite&gt;vim&lt;/cite&gt; for Python (and remove some unwanted features like folding):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
syntax on
set number
set autoindent
set expandtab
set shiftwidth=4
set tabstop=4
set nofoldenable

execute pathogen#infect()
set statusline+=%#warningmsg#
set statusline+=%{SyntasticStatuslineFlag()}
set statusline+=%*
let g:syntastic_always_populate_loc_list = 1
let g:syntastic_auto_loc_list = 0
let g:syntastic_check_on_open = 1
let g:syntastic_check_on_wq = 0
&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="installing-software"&gt;
&lt;h2&gt;Installing software&lt;/h2&gt;
&lt;p&gt;Quite happy with the software that comes preinstalled with Fedora, but few things left to install.
First adding &lt;a class="reference external" href="https://rpmfusion.org"&gt;RPM Fusion&lt;/a&gt; repositories:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
sudo dnf install https://download1.rpmfusion.org/free/fedora/rpmfusion-free-release-$(rpm -E %fedora).noarch.rpm https://download1.rpmfusion.org/nonfree/fedora/rpmfusion-nonfree-release-$(rpm -E %fedora).noarch.rpm
&lt;/pre&gt;
&lt;p&gt;Then updating the system:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
sudo dnf update
&lt;/pre&gt;
&lt;p&gt;Then installing the development group:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
sudo dnf groupinstall &amp;quot;Development Tools&amp;quot;
&lt;/pre&gt;
&lt;p&gt;Also installing all the missing packages (or not missing, but had this list for some years now):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
sudo dnf install vim-enhanced git vlc gimp inkscape unzip
&lt;/pre&gt;
&lt;p&gt;And finally installing &lt;a class="reference external" href="https://conda.io/miniconda.html"&gt;Miniconda&lt;/a&gt;. I prefer Miniconda over
Anaconda, because I don't like to have any package in the base environment. So, in every
environment I'm sure there are the packages I'm using (and it's not falling back to the base
environment version, which can be different of the expected).&lt;/p&gt;
&lt;/div&gt;
</content></entry><entry><title>Useful git commands</title><link href="https://datapythonista.github.io/blog/useful-git-commands.html" rel="alternate"></link><published>2018-11-08T00:00:00+00:00</published><updated>2018-11-08T00:00:00+00:00</updated><author><name>Marc Garcia</name></author><id>tag:datapythonista.github.io,2018-11-08:/blog/useful-git-commands.html</id><summary type="html">&lt;p&gt;While &lt;cite&gt;git&lt;/cite&gt; is surely one of my favorite tools, and increases my productivity
in a sometimes unbelivable way (like when working on 3 or 5 features at the
same time), some times there are operations that can be a bit tricky.&lt;/p&gt;
&lt;p&gt;There are plenty of git tutorials and guides to …&lt;/p&gt;</summary><content type="html">&lt;p&gt;While &lt;cite&gt;git&lt;/cite&gt; is surely one of my favorite tools, and increases my productivity
in a sometimes unbelivable way (like when working on 3 or 5 features at the
same time), some times there are operations that can be a bit tricky.&lt;/p&gt;
&lt;p&gt;There are plenty of git tutorials and guides to get started and that explain
the basic concepts. This post is not one of them. If that is what you need,
you can check these great resources:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://rogerdudler.github.io/git-guide/"&gt;git - the simple guide&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://medium.com/girl-writes-code/git-is-a-directed-acyclic-graph-and-what-the-heck-does-that-mean-b6c8dec65059"&gt;Git is a Directed Acyclic Graph and What the Heck Does That Mean?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://think-like-a-git.net/"&gt;Think Like (a) Git&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://git-scm.com/doc"&gt;Official documentation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There is another quite popular resource, that doesn't focus on explaining
the concepts, but on what to do if you get into certain cases (aka problems):&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://ohshitgit.com/"&gt;Oh shit,git!&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;More on the style of the latter, in this post I'll explain some operations
that are somehow advanced, I don't think are well known, but I use them
frequently. So, hopefully they can be useful to others.&lt;/p&gt;
&lt;div class="section" id="i-ve-got-some-cool-changes-but-my-history-is-a-mess"&gt;
&lt;h2&gt;I've got some cool changes, but my history is a mess&lt;/h2&gt;
&lt;p&gt;There are many reasons why this can happen. The one that I encounter most
frequently is people opening a pull request, that does not only contain
the user changes (and possibly some merges from master), but instead it
contains commits from other users in the branch, as if they were part of
the pull request. I never spent the time to research what is the cause, but
this is what I usually recommend or do.&lt;/p&gt;
&lt;p&gt;Whether it is the previous case, or because of any other reason, if you have
some changes in your branch mixed with a messy git history, the easiest
way I know to go back to a state under control is:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;git fetch upstream&lt;/tt&gt;: Just updating our local repository.&lt;/li&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;git merge upstream/master&lt;/tt&gt;: Getting anything in the latest repository
version into our branch.&lt;/li&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;git reset &lt;span class="pre"&gt;--soft&lt;/span&gt; upstream/master&lt;/tt&gt;: This will make that the git history
in our branch is exactly as the one in master, replacing our messy history.
And it will leave in our staging area all the changes that we made, compared
to master.&lt;/li&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;git commit &lt;span class="pre"&gt;-m&lt;/span&gt; &amp;quot;All my changes in a single commit&amp;quot;&lt;/tt&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Now the history in our branch will be equivalent as if we just created
the branch from the latest version, and added a single commit with all our
changes. As usual, we shouldn't rewrite the history if someone else pulled
our commits. But if this is a local branch, or it is remote but only used
to open a pull request, that should be all right.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="i-have-changes-in-the-working-directory-and-i-want-to-change-branch"&gt;
&lt;h2&gt;I have changes in the working directory, and I want to change branch&lt;/h2&gt;
&lt;p&gt;There are also different cases for this. The simplest case (but not
common in my case) is that you are working in a branch, and want to
go to make some changes to a different one, but your current changes are
not in a state that you want to commit.&lt;/p&gt;
&lt;p&gt;The other cases (the ones that happen to me in practice) are:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;You start working in some changes, and you realize that you are in the
wrong branch.&lt;/li&gt;
&lt;li&gt;You are making some last minute addition to a pull request, and before
you commit and push, the pull request is merged. So, you want to continue
the work in a new branch.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The problem is that when you have uncommitted changes in your working
directory, and you try to change branch, you get the next error message:
&lt;cite&gt;error: Your local changes to the following files would be overwritten by
checkout&lt;/cite&gt; preventing any branch change until you commit those changes.
But committing in the current branch is not what we want.&lt;/p&gt;
&lt;p&gt;The solution in this case is &lt;tt class="docutils literal"&gt;git stash&lt;/tt&gt;. With it, the changes in the
working directory are saved into a stack, and the working directory becomes
clean.  This allows us to freely switch branches, and perform other operations.
Once we have the environment ready, and we are in the branch in which the
stacked changes belong to, then we can simply &lt;tt class="docutils literal"&gt;git stash apply&lt;/tt&gt;. We will get
the uncommitted changes back to the working directory.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="i-want-to-test-or-edit-someone-else-pull-request"&gt;
&lt;h2&gt;I want to test or edit someone else pull request&lt;/h2&gt;
&lt;p&gt;This is something that mainly project maintainers do, but that can be useful
for anyone. In general, when someone opens a pull request, the changes are
reviewed, and feedback is provided, both in the GitHub (or similar)
interface. And the author, who already got the branch locally, makes changes
and run the code. But in some cases, it may be useful to get the changes of the
pull request locally, so they can be run, and edited.&lt;/p&gt;
&lt;p&gt;One example could be a stale pull request, that was opened many months ago
and that the author is not interesting in updating anymore. But it contains
code, that with few changes, would be nice to get merged.&lt;/p&gt;
&lt;p&gt;Git is a distributed system, and there is nothing in git itself that tells
which is the &amp;quot;official&amp;quot; repository, and which are forks. To interact
with other repositories from your local copy, all you need is to set a
remote, fetch the changes, and switch to their branches. This would be
done with the commands:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;git remote add &lt;span class="pre"&gt;&amp;lt;remote-name-for-user-fork&amp;gt;&lt;/span&gt; &lt;span class="pre"&gt;&amp;lt;url-to-user-fork&amp;gt;&lt;/span&gt;&lt;/tt&gt;&lt;/li&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;git fetch &lt;span class="pre"&gt;&amp;lt;remote-name-for-user-fork&amp;gt;&lt;/span&gt;&lt;/tt&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Now, we already have locally all the data in the repo of the author of the
pull request. Next thing is to checkout the branch used for the pull request.
This can be done with:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;git branch &lt;span class="pre"&gt;&amp;lt;branch-name&amp;gt;&lt;/span&gt; &lt;span class="pre"&gt;--track&lt;/span&gt; &lt;span class="pre"&gt;&amp;lt;remote-name-for-user-fork&amp;gt;/&amp;lt;branch-name&amp;gt;&lt;/span&gt;&lt;/tt&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Now we have the code in the pull request in our working directory. And we can
run or edit.&lt;/p&gt;
&lt;p&gt;GitHub has an option when creating a pull request &amp;quot;Allow edits from
maintainers&amp;quot;, that is checked by default. If the author of the pull request
left it checked, then maintainers can push to the pull request branch
after editing it locally. So, the updates are made in the same pull request,
which can be merged when it's ready.&lt;/p&gt;
&lt;p&gt;For people that are not maintainers, when the checkbox was unchecked, or when
the fork of the author does not exist anymore, pushing to &lt;cite&gt;origin&lt;/cite&gt; (your own
fork), and opening a new pull request is required.&lt;/p&gt;
&lt;p&gt;If editing other people branches is something that needs to be done often, it
is probably a good idea to use &lt;cite&gt;hub&lt;/cite&gt;, a tool from GitHub. It can be installed
with conda:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;conda install &lt;span class="pre"&gt;-c&lt;/span&gt; &lt;span class="pre"&gt;conda-forge&lt;/span&gt; hub&lt;/tt&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And then, checking out the branch from a pull request is as simple as:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;hub checkout &lt;span class="pre"&gt;&amp;lt;github-url-of-the-pull-request&amp;gt;&lt;/span&gt;&lt;/tt&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Which will set up the remotes, and make the branch track the parent, so
changes can be pushed with a simple &lt;tt class="docutils literal"&gt;git push&lt;/tt&gt; given the right permissions.&lt;/p&gt;
&lt;/div&gt;
</content></entry><entry><title>Blog moved</title><link href="https://datapythonista.github.io/blog/blog-moved.html" rel="alternate"></link><published>2018-09-08T00:00:00+01:00</published><updated>2018-09-08T00:00:00+01:00</updated><author><name>Marc Garcia</name></author><id>tag:datapythonista.github.io,2018-09-08:/blog/blog-moved.html</id><summary type="html">&lt;p&gt;It's been a while since I wanted to move my blog out of blogger.&lt;/p&gt;
&lt;p&gt;Today I finally did it. :)&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;hello world (from Pelican)&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This new blog uses Pelican, and is hosted on GitHub pages. Which will
let me create blog posts by simply using restructuredText, or
Jupyter notebooks.&lt;/p&gt;
&lt;p&gt;You …&lt;/p&gt;</summary><content type="html">&lt;p&gt;It's been a while since I wanted to move my blog out of blogger.&lt;/p&gt;
&lt;p&gt;Today I finally did it. :)&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;hello world (from Pelican)&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This new blog uses Pelican, and is hosted on GitHub pages. Which will
let me create blog posts by simply using restructuredText, or
Jupyter notebooks.&lt;/p&gt;
&lt;p&gt;You can check the source code here: &lt;a class="reference external" href="https://github.com/datapythonista/datapythonista.github.io"&gt;https://github.com/datapythonista/datapythonista.github.io&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;More info: &lt;a class="reference external" href="https://blog.getpelican.com/"&gt;https://blog.getpelican.com/&lt;/a&gt;&lt;/p&gt;
</content></entry><entry><title>#pandasSprint write-up</title><link href="https://datapythonista.github.io/blog/pandassprint-write-up.html" rel="alternate"></link><published>2018-03-22T01:57:00+00:00</published><updated>2018-03-22T01:57:00+00:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2018-03-22:/blog/pandassprint-write-up.html</id><summary type="html">&lt;p&gt;The past 10th of March took place &lt;a href="https://python-sprints.github.io/pandas/"&gt;#pandasSprint&lt;/a&gt;.
To the best of my knowledge, an unprecedented kind of event, where around 500 people worked
together in improving the documentation of the popular pandas library.&lt;/p&gt;
&lt;p&gt;As one of the people involved in the organization of the event, I wanted to write …&lt;/p&gt;</summary><content type="html">&lt;p&gt;The past 10th of March took place &lt;a href="https://python-sprints.github.io/pandas/"&gt;#pandasSprint&lt;/a&gt;.
To the best of my knowledge, an unprecedented kind of event, where around 500 people worked
together in improving the documentation of the popular pandas library.&lt;/p&gt;
&lt;p&gt;As one of the people involved in the organization of the event, I wanted to write about why
I think this event was much more than the contributions sent, and the fun day we had. And
also provide information on how it was planned, to help future organizers.&lt;/p&gt;
&lt;h2&gt;Some historical context&lt;/h2&gt;
&lt;p&gt;To explain where the idea of the #pandasSprint came from, I need to go back in time more
than 15 years. Those were the times where open source was named free software, people queued
to see &lt;a href="https://en.wikipedia.org/wiki/Richard_Stallman"&gt;Richard Stallman&lt;/a&gt; talks, and
companies like SCO and Microsoft were in the dark side of proprietary software. Free
software was more about freedom than about software, and the free software community was
working hard and united to build the software that could challenge the status quo.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://trisquel.info/files/richard%20stallman.jpg"&gt;&lt;/p&gt;
&lt;p&gt;Now we’re in 2018, and things changed a lot. SCO doesn’t exist anymore, and Microsoft is one
of the companies supporting more open source. Employing more Python core developers than any
other company, sponsoring major events like PyCon or EuroPython, and funding non-profits
like &lt;a href="https://www.numfocus.org/"&gt;NumFOCUS&lt;/a&gt;,
&lt;a href="https://www.python.org/psf/"&gt;The Python Software Foundation&lt;/a&gt; and even
&lt;a href="http://www.linuxfoundation.org/"&gt;The Linux Foundation&lt;/a&gt;. Python is growing in popularity, and
nobody questions the advantages of open source software.&lt;/p&gt;
&lt;p&gt;But what happened to all the free software hackers who untiringly were making their projects
be to the highest standards? Of course there are still many people there, but my perception
is that the growth in popularity of open source projects didn’t translate linearly to a
growth in the number of contributors. And I think pandas is one of the clearest examples.&lt;/p&gt;
&lt;p&gt;For the last years, pandas has been becoming a de-facto standard in data analytics and data
science. Recently, Stack Overflow published that
&lt;a href="https://stackoverflow.blog/2017/09/14/python-growing-quickly/"&gt;almost 1% of their traffic from developed countries is caused by pandas&lt;/a&gt;.
The book Python for data analysis by pandas creator
&lt;a href="https://twitter.com/wesmckinn/status/974303935530876928"&gt;sold more more 250,000 copies&lt;/a&gt;,
and the pandas website has around
&lt;a href="https://twitter.com/jorisvdbossche/status/974322924034449408"&gt;400,000 activeusers per month&lt;/a&gt;.
It’s difficult to know how many pandas users exist, but some
&lt;a href="https://twitter.com/teoliphant/status/974056911627866113"&gt;informed opinions talk about 5 million&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://stackoverflow.blog/wp-content/uploads/2017/09/related_tags_over_time-1-1200x1200.png"&gt;&lt;/p&gt;
&lt;p&gt;What about the contributors? In a quick look at
&lt;a href="https://github.com/pandas-dev/pandas/graphs/contributors"&gt;GitHub&lt;/a&gt;, I counted 12 developers
that have been active in the last year, and that contributed more than 20 commits to the project.
This leaves a ratio of 1 significant contributor for more than 400,000 users. Not long before
the #pandasSprint the project achieved 1,000 contributors. Meaning that 1 in each 5,000 ever made
a contribution.&lt;/p&gt;
&lt;p&gt;You can find these small or big depending on your expectations. And it’s difficult to compare
without numbers about Python projects 10 years ago. But my feeling is that we transitioned from a
free software community of developers actively participating in the projects, to a community of
mainly users, who in many cases see free software as
&lt;a href="https://en.wikipedia.org/wiki/Free_as_in_Freedom"&gt;free beer&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;How to become part of the open source community&lt;/h2&gt;
&lt;p&gt;I don’t know why people become part of the open source community, in terms of participating
actively on it. But I know how I did. It’s a beautiful and sad story that I want to share.&lt;/p&gt;
&lt;p&gt;Around 12 years ago, I was quite new to Python, but really liking the language compared to
what I used before. Most of what I was doing was web based, so I quickly discovered Django,
and felt in love. What in PHP (the de-facto standard at that time) took one week or more to
implement, in Django was done in minutes, and with much higher quality. Django was simply
amazing, the web framework for perfectionists with deadlines. But in some areas not as
mature as it is now. And I’m talking mainly about localization. The system to translate
static text was amazing, but you couldn't make calendars start in Monday, or use the comma
as a decimal separator. That was a big problem for me, as my users in Spain wouldn't be
happy using the US localization. The good news was that it was open source, so I started to
take a look on what could be done.&lt;/p&gt;
&lt;p&gt;When I submitted my first bug reports and patches to Django, I found the best mentor a
newcomer to open source can find, Malcolm Treddinick. He was the core developer more
involved in the localization part of Django. Malcolm helped me in every step, and I learned
a lot from him about Python, Django, subversion... But I also learned from him (and also
from others in the community) about kindness and collaboration. It was a really welcoming
community, and honestly, at the beginning I found it quite surprising the amount of time
people was happy to spend helping and giving support to someone who didn’t have so much to
contribute. After some time, I managed to be more experienced, and I was able to contribute
back, taking care of the Catalan and Spanish translations for some years, and doing a major
&lt;a href="https://datapythonista.blogspot.co.uk/2009/12/new-localization-system-already-in.html"&gt;refactoring of Django's localization system&lt;/a&gt;,
as part of a &lt;a href="https://summerofcode.withgoogle.com/"&gt;Google summer of code&lt;/a&gt;. But who could
know that beforehand.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://puzzling.org/wp-content/uploads/2013/03/2834869959_85974cbd42_b-248x300.jpg"&gt;&lt;/p&gt;
&lt;p&gt;I was in shock when in 2013
&lt;a href="https://www.djangoproject.com/weblog/2013/mar/19/goodbye-malcolm/"&gt;Malcolm passed away&lt;/a&gt;.
Besides being a tragedy for him and his close ones, it was also for many of us, who barely
met him in person, but considered him a friend. The Django Software Foundation created the
&lt;a href="https://www.djangoproject.com/foundation/prizes/"&gt;Malcolm Tredinnick Memorial Prize&lt;/a&gt; in
his honor. The prize is awarded, quoting the DSF page “to the person who best exemplifies
the spirit of Malcolm’s work - someone who welcomes, supports and nurtures newcomers;
freely gives feedback and assistance to others, and helps to grow the community”.&lt;/p&gt;
&lt;p&gt;Malcolm was unique, but the open source community is the amazing community it is, because
there are so many amazing people who exemplifies the spirit of Malcolm every day.&lt;/p&gt;
&lt;h2&gt;London Python Sprints&lt;/h2&gt;
&lt;p&gt;So, with such an amazing community (and I experienced it enough to be sure about it), what
is it preventing more people to get involved? I would say most people thinks that
technically speaking, they are not good enough for the projects. That you need the mind of
&lt;a href="https://en.wikipedia.org/wiki/Alan_Turing"&gt;Alan Turing&lt;/a&gt;,
&lt;a href="https://en.wikipedia.org/wiki/Dennis_Ritchie"&gt;Dennis Ritchie&lt;/a&gt; or
&lt;a href="https://en.wikipedia.org/wiki/Linus_Torvalds"&gt;Linus Torvalds&lt;/a&gt; to make a contribution. I
strongly disagree. Even the less technical people can participate in many things such as
translations, writing documentation, ticket triaging… There are also many great projects in
their early stages were contributing code is much easier than contributing to the more
complex and intimidating ones.&lt;/p&gt;
&lt;p&gt;Then, what’s the problem? Personally, I think the only problem is getting started. The first
time, it’s difficult to find a task to get started. It’s difficult to understand the
&lt;a href="https://docs.google.com/presentation/d/1rOSYXZPyMe9KXnbVK_xbJzw_-ijxd6bIxndmvPU6L2o/edit?usp=sharing"&gt;logistics of sending a pull request&lt;/a&gt;.
It’s difficult to know beforehand whether project maintainers will welcome our small
contributions. And it may be difficult to even know that we need a task to work in, that we
need to send a pull request, or that there is a community out there working on every project.
But these are just difficult until someone is able to help you get started.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://secure.meetupstatic.com/photos/event/5/e/a/f/highres_465084239.jpeg"&gt;&lt;/p&gt;
&lt;p&gt;With this idea in mind, &lt;a href="https://www.meetup.com/Python-Sprints/"&gt;London Python Sprints&lt;/a&gt; was
born. A place where open source contributors could mentor newcomers in their first steps. And
personally, I think it’s very successful. Not only we managed to send around 50 pull requests
to different projects in 2017, but people who did the first pull request with us, are now the
mentors helping others get started.&lt;/p&gt;
&lt;h2&gt;#pandasSprint: the idea&lt;/h2&gt;
&lt;p&gt;&lt;img alt="" src="https://secure.meetupstatic.com/photos/event/6/2/2/1/highres_468505121.jpeg"&gt;&lt;/p&gt;
&lt;p&gt;While the experience in London was great, it was very low scale. And we could do much better.
All it takes for many people to love becoming a contributor, is to have some guidance in these
first steps. We already had the experience from several months of sprints in London, and with
some preparation we could help other user groups do the same.&lt;/p&gt;
&lt;p&gt;Why pandas? There are plenty of great projects to contribute to. But for pandas... Everybody
loves pandas, it’s very popular. It’s a welcoming project in the spirit of Malcolm. Improving
the documentation would be something very useful. And it’s one of the projects I’m more
familiar with&lt;/p&gt;
&lt;p&gt;But it’s probably clear that the goal wasn’t that much about the specific project or
contributions. But about letting people get into the open source world in the way many of us
love it. Becoming part of it, and not just being a user of some software we don’t need to pay
for.&lt;/p&gt;
&lt;h2&gt;#pandasSprint: the implementation&lt;/h2&gt;
&lt;p&gt;So, we wanted to have a huge open source party, but of course that required a huge amount of
work.&lt;/p&gt;
&lt;p&gt;The first thing was to make sure the pandas core developers were happy with it. It was going
to be a lot of work from their side, and they know much more about pandas than anyone else,
and could tell whether it was a good idea, or provide useful feedback. An email to
&lt;a href="https://twitter.com/jreback"&gt;Jeff Reback&lt;/a&gt; was enough to start. He loved the idea, even if I
think he didn’t believed at that time it was going to be something as big as it finally was. :)&lt;/p&gt;
&lt;h3&gt;Dividing the work&lt;/h3&gt;
&lt;p&gt;The next thing was to make sure everybody had something to work on the day of the sprint.
Working on the documentation made it possible. There are around
&lt;a href="https://docs.google.com/spreadsheets/d/10EpQFkVDqiIFLLVGtIWzCMRACz20yWuta3_DU0qV6-E/edit?usp=sharing"&gt;1,200 API pages&lt;/a&gt;
in the pandas documentation. Writing a script to get the list was easy. We could even gather
some information on the state of the documentation (which pages had examples, which methods
had mistakes in their documented parameters...).&lt;/p&gt;
&lt;p&gt;The trickiest part was the system to share docstrings in pandas. There are many functions and
methods in pandas, that are similar enough to have a shared template for the documentation,
customized with few variables specific to each page. The original idea was to use Python
introspection system to find the exact ones sharing a template, so we could avoid duplicates.
That was more complex than it originally seemed, and we finally delegated the task of finding
out to each user group. &lt;/span&gt;&lt;span style="font-weight: normal;"&gt;To help with that, we
divided the pages in groups by topics, and assigned whole groups to each sprint chapter.
Sharing of docstrings was more likely to happen inside these groups. For example, all the
functions in Series.str where in a group. Functions like
&lt;a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.str.lower.html"&gt;lower()&lt;/a&gt;,
&lt;a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.str.upper.html"&gt;upper()&lt;/a&gt;,
&lt;a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.str.capitalize.html"&gt;capitalize()&lt;/a&gt;
use the same template, so it should be somehow easy to detect it in the chapter working on that group.&lt;/p&gt;
&lt;h3&gt;Documentation&lt;/h3&gt;
&lt;p&gt;Then, after being able to provide each participant a task, we had to make sure everybody knew
what to do. For it, there were two main things. First, having documentation explaining all the
steps. And second having mentors in every city.&lt;/p&gt;
&lt;p&gt;For the documentation, we had 3 main documents:
- &lt;a href="https://python-sprints.github.io/pandas/guide/pandas_setup.html"&gt;Set up instructions&lt;/a&gt;
  (installing requirements, cloning the repository, compiling C extensions...)
- &lt;a href="http://pandas-docs.github.io/pandas-docs-travis/contributing_docstring.html"&gt;Guide&lt;/a&gt;
  on how to write a docstring for pandas
- &lt;a href="https://python-sprints.github.io/pandas/guide/pandas_pr.html"&gt;Instructions&lt;/a&gt;
  on how to validate the changes, and submit them&lt;/p&gt;
&lt;p&gt;The most complex part was defining how a “perfect” docstring had to look like. Following some
standards would be very useful for pandas users. All the pages would be implemented in the best
possible way we could think of. And users would be able to get used to one format, and find
information faster.&lt;/p&gt;
&lt;p&gt;We started with a draft of a guide in the form of
&lt;a href="https://github.com/pandas-dev/pandas/pull/19704/files"&gt;pull request&lt;/a&gt;, so everybody could
review and add comments. And then it was a bit of discussion on the topics with disagreements
or unclear. I think the result was great. But of course we couldn’t anticipate all the cases.&lt;/p&gt;
&lt;p&gt;We also had to write &lt;a href="https://github.com/pandas-dev/pandas/pull/20016/files"&gt;documentation&lt;/a&gt;
about shared docstrings, and what was the preferred way to implement it.
&lt;a href="https://twitter.com/TomAugspurger"&gt;Tom Augspurger&lt;/a&gt; took care of it.&lt;/p&gt;
&lt;h3&gt;Mentoring&lt;/h3&gt;
&lt;p&gt;A key thing was to make sure in every location we had people who could mentor participants.
We created a &lt;a href="https://gitter.im/py-sprints/pandas-doc"&gt;gitter channel&lt;/a&gt; for the event, but it
would be difficult to remotely help in more than specific things. Everybody was in their own
local sprint, and we also had different time zones, so availability during the sprint would
be limited.&lt;/p&gt;
&lt;p&gt;So, what we did was to ask
&lt;a href="https://docs.google.com/spreadsheets/d/138095mUxOTOCCXmvQGz7YOh-0yWLoTH_8_IlrAI5w2c/edit?usp=sharing"&gt;somebody from each chapter to work on a taskbefore the sprint&lt;/a&gt;.
In most cases that was the same organizers. I don't know if that is true, but I had the
feeling that some organizers were underestimating how complex improving a single API
documentation page is. And how difficult is to help a large group of people who is doing
their first open source contribution can be. Letting them prepare before hand should be
useful in different ways: Organizers would be better prepared, and have a better sprint,
without so much stress and uncertainty. They should be able to help participants better.
The "mini" sprint of the organizers would be a proof of concept that would let us
anticipate problems in the documentation, the procedure...&lt;/p&gt;
&lt;p&gt;Not all the organizers found the time to prepare, as we were ready to start this stage
less than a week before the global sprint date. But I think it was very useful for the
ones who could prepare for the sprint.&lt;/p&gt;
&lt;h3&gt;Tools&lt;/h3&gt;
&lt;p&gt;One of the areas we worked on preparing the sprint, was in having better tools.
&lt;a href="https://twitter.com/jorisvdbossche"&gt;Joris Van den Bossche&lt;/a&gt;, besides being key in all
the parts of the sprint, did an amazing job on this part. We implemented a way to
&lt;a href="https://github.com/pandas-dev/pandas/pull/19840/files"&gt;build a single document in Sphinx&lt;/a&gt;,
and a &lt;a href="https://github.com/pandas-dev/pandas/blob/master/scripts/validate_docstrings.py"&gt;script to validated formatting errors in docstrings&lt;/a&gt;.
We also set up a &lt;a href="https://github.com/pandas-dev/pandas/pull/20015/files"&gt;sphinx plugin to easily include plots in the documentation&lt;/a&gt;,
which &lt;a href="http://pandas-docs.github.io/pandas-docs-travis/generated/pandas.DataFrame.plot.kde.html"&gt;made some pages look really great&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Last minute, we also build a &lt;a href="https://python-sprints.github.io/pandas/dashboard.html"&gt;dashboard&lt;/a&gt;
with a list of checkpoints that the users could follow during the day, so it was
clearer to know what to do, and it should help them make better contributions.&lt;/p&gt;
&lt;h3&gt;Promotion&lt;/h3&gt;
&lt;p&gt;Promoting the event, and finding the people willing to participate was done in
different ways: The first one was to direct message the organizers of different
communities. Among all the great things of the Python community, is how well
organized it is. In a &lt;a href="https://www.meetup.com/pro/pydata"&gt;single page&lt;/a&gt; there are
the links to the almost 100 PyData meetups all around the world. In the Python
website there is a &lt;a href="https://wiki.python.org/moin/LocalUserGroups"&gt;wiki&lt;/a&gt; with
tens of Python user groups. Not everybody we contacted was interested, or even
answered, but most of the groups were really happy with the idea.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.python.org/psf/"&gt;The Python Software Foundation&lt;/a&gt;, &lt;a href="https://www.numfocus.org/"&gt;NumFOCUS&lt;/a&gt;
were also key in spreading the word about the event.&lt;/p&gt;
&lt;p&gt;As the sprint was to work on the documentation, we also contacted
&lt;a href="http://www.writethedocs.org/"&gt;Write the docs&lt;/a&gt;, a global community focused on
writing technical documentation. Some of their members joined the sprint too.&lt;/p&gt;
&lt;h2&gt;The sprint&lt;/h2&gt;
&lt;p&gt;For the day of the sprint, we've got a last minute surprise. I really think
what every participant of the sprint was going to do, was something really
great. Even if in a way it felt more like a Saturday with friends. And I
think it was worth that people knew how important is to contribute to the
open source projects that power from the scientific research to the
financial markets, or the data science infrastructure of so many companies
in the world. So, just few hours after the sprint we spoke with
&lt;a href="https://twitter.com/wesmckinn"&gt;Wes McKinney&lt;/a&gt;, creator of pandas,
&lt;a href="https://twitter.com/NaomiCeder"&gt;Naomi Ceder&lt;/a&gt;, chair of the Python Software
Foundation, and Leah Silen, executive director at
&lt;a href="https://twitter.com/NumFOCUS"&gt;NumFOCUS&lt;/a&gt;, to see if they could record a
short message to the participants. Even with the very short notice, all them
sent really great messages that we could show the participants at the
beginning of the sprints.&lt;/p&gt;
&lt;iframe allowfullscreen="" class="YOUTUBE-iframe-video"
        data-thumbnail-src="https://i.ytimg.com/vi/YnFKV2oxs8Q/0.jpg"
        frameborder="0" height="266"
        src="https://www.youtube.com/embed/YnFKV2oxs8Q?feature=player_embedded" width="320"&gt;&lt;/iframe&gt;

&lt;p&gt;It's difficult to know what happened in the sprint at a global scale. I
think in London we've got a great time, with nice atmosphere and a luxury
location provided by our sponsor &lt;a href="https://twitter.com/TechAtBloomberg"&gt;Bloomberg&lt;/a&gt;.
I think for most of us the sprint seemed too short. Even if I think it was
a typical British pub follow up to the sprint, that I couldn't join.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://secure.meetupstatic.com/photos/event/a/5/1/5/highres_469122261.jpeg"&gt;&lt;/p&gt;
&lt;p&gt;In other locations, for what I know the experience was also good. It's worth
taking a look at the &lt;a href="https://twitter.com/hashtag/pandasSprint"&gt;twitter feed of the sprint&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://2.bp.blogspot.com/-Cyqt0qDvzfU/WrL7uGMLE-I/AAAAAAAAy3o/wiQzl-n-45sDUpNBpTBuQYIvEdlxRnqGgCLcBGAs/s320/DX9KVEaX0AAhZ0N.jpg"&gt;
&lt;img alt="" src="https://3.bp.blogspot.com/-idbpUQxods4/WrL7tfBPrAI/AAAAAAAAy3c/fRlBRkiszl03L2OHb90YJ8FuM5ZdatrQgCLcBGAs/s320/DX9KVEXX4AIpNYv.jpg"&gt;
&lt;img alt="" src="https://2.bp.blogspot.com/-AWSA-0nxm08/WrL7tniUZbI/AAAAAAAAy3k/u59ZVgzqyEUTG5nd3wBjHi51BweaH13XgCLcBGAs/s320/DX9KVEWWkAQR4hg.jpg"&gt;
&lt;img alt="" src="https://2.bp.blogspot.com/-Q5v-KXlNu1c/WrL7tkMJDFI/AAAAAAAAy3g/KPHHNDTV3xM7pXvKoEiSlNHT04gIJW3_ACLcBGAs/s320/DX9KVEXWsAImaHY.jpg"&gt;&lt;/p&gt;
&lt;p&gt;Also, I really enjoyed reading the write-ups that some organizers and participats wrote:
- From Iva and Tsvetelina, organizers in Sofia: &lt;a href="https://www.facebook.com/evolutiontc/posts/2040798282603060"&gt;&lt;/a&gt;
- From Priyanka, a participant in Amsterdam: &lt;a href="https://www.linkedin.com/pulse/pandassprint-amsterdam-my-experiences-priyanka-ojha/"&gt;&lt;/a&gt;
- From &lt;a href="https://twitter.com/IHackPY"&gt;Himanshu&lt;/a&gt;, organiser in &lt;a href="https://twitter.com/PythonKanpur"&gt;Kanpur&lt;/a&gt;, India: &lt;a href="https://kanpurpython.wordpress.com/2018/03/15/experience-of-pandas-documentation-sprint/"&gt;&lt;/a&gt;
- Live streaming of the sprint in Shen Zhen: &lt;a href="https://www.youtube.com/watch?v=SK-sF_biP04"&gt;&lt;/a&gt;
- From Marc, participant in Toronto: &lt;a href="https://towardsdatascience.com/making-my-first-open-source-software-contribution-8ebf622be33c"&gt;https://towardsdatascience.com/making-my-first-open-source-software-contribution-8ebf622be33c&lt;/a&gt;
- From &lt;a href="https://bluekiri.com/"&gt;Bluekiri&lt;/a&gt;, sponsor in Mallorca: &lt;a href="https://medium.com/bluekiri/pandas-documentation-sprint-90f5a76c0e24"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;And it's worth taking a look at this analysis on the impact on the sprint
in the pandas GitHub activity by &lt;a href="https://twitter.com/jorisvdbossche"&gt;Joris&lt;/a&gt;:
&lt;a href="https://jorisvandenbossche.github.io/blog/2018/03/13/pandas-sprint-activity/"&gt;https://jorisvandenbossche.github.io/blog/2018/03/13/pandas-sprint-activity/&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;#pandasSprint aftermath&lt;/h2&gt;
&lt;p&gt;This is what I think was the aftermath of the sprint:
- A lot of hard work before the sprint by all the local organizers and core developers
- More than 200 pull requests sent, around 150 already merged
- Many people really loved the experience
- An incredible work by the pandas core development team after the sprint
- In London, our sprint after the 10th of March have long waiting list, which
  was not happening before the #pandasSprint
- Several people keeps contributing to the pandas documentation after
  sending their first contribution&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://1.bp.blogspot.com/-H5C_zl4ms8w/WrL7_nbUOkI/AAAAAAAAy3s/In1eAslaH0cgylzT__9RRYFpIGsnj8-3ACLcBGAs/s320/Screenshot%2Bat%2B2018-03-22%2B00-41-14.png"&gt;&lt;/p&gt;
&lt;p&gt;And what I think it's more important. We did a small but great step in making
sprints a popular event format in the Python community, to add the missing piece
to the numerous conferences, meetups based on talks, dojos, workshops and others.&lt;/p&gt;
&lt;p&gt;Several people asked me when is the next one. In London we are having two sprints
this week. Man AHL is hosting this great &lt;a href="http://ahl.com/hackathon"&gt;hackathon&lt;/a&gt;
in one month. I hope to see other user groups organizing sprints in the future.
And about another worldwide sprint... May be in some months we could do a PyData
Festival and have 10,000 people contributing to 20 different projects during a
whole weekend? :)&lt;/p&gt;</content><category term="pandas"></category></entry><entry><title>My NIPS write up</title><link href="https://datapythonista.github.io/blog/my-nips-write-up.html" rel="alternate"></link><published>2017-12-17T00:03:00+00:00</published><updated>2017-12-17T00:03:00+00:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2017-12-17:/blog/my-nips-write-up.html</id><summary type="html">&lt;p&gt;Just as a quick disclaimer, this post is about my personal experience and opinions at NIPS 2017, and I'm not an AI researcher, I work as a data scientist in the industry. For a more technical summary of the talks and papers presented, you may want to check this &lt;a href="https://cs.brown.edu/~dabel/blog/posts/misc/nips_2017.pdf"&gt;document …&lt;/a&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;Just as a quick disclaimer, this post is about my personal experience and opinions at NIPS 2017, and I'm not an AI researcher, I work as a data scientist in the industry. For a more technical summary of the talks and papers presented, you may want to check this &lt;a href="https://cs.brown.edu/~dabel/blog/posts/misc/nips_2017.pdf"&gt;document by David Abel&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Deep learning rigor and interpretability&lt;/h2&gt;

&lt;div&gt;This is quite a controversial topic, but this is how I see it. There are two main approaches to the idea of statistics/learning:&lt;/div&gt;

&lt;div&gt;&lt;ol&gt;&lt;li&gt;Understand how learning works, and replicate it based on this understanding&lt;/li&gt;&lt;li&gt;Focus on results, no matter if it's at the cost of poor understanding&lt;/li&gt;&lt;/ol&gt;&lt;div&gt;I think these two approaches were first dividing statisticians and machine learning practitioners, as Leo Breiman describes in [The two cultures](http://www2.math.uu.se/~thulin/mm/breiman.pdf). And in a similar way, today it divides the Deep learning school, which is somehow winning in terms of results, from other techniques.&lt;/div&gt;&lt;/div&gt;

&lt;div&gt;
&lt;/div&gt;

&lt;div&gt;My view on deep learning is that we've managed to understand in a general way the how the human brain works. Not why, but with the research of people like Santiago Ramon y Cajal, Camilo Golgi, Donald Hebb..., we know that it's a network of neurons, and that the "intelligence" is on how the neurons connect, and not in the neurons themselves.&lt;/div&gt;

&lt;div&gt;
&lt;/div&gt;

&lt;div&gt;With the research of&amp;nbsp;Warren McCulloch, Walter Pitts, John Hopfield, Geofreey Hinton..., we can replicate this structure of neurons in an artificial way. Just with a set of connected linear regressions, with activation functions to break the linearity. And with current computation power, including optimized hardware like GPUs, we can implement networks of neurons at a huge scale. We know that the model works, because it works for the human brain, and we're confident it's the same. But we don't know how each neuron is connected in the brain (how much signal it needs to receive from the other networks to activate), so we miss the weights of the linear regressions.&lt;/div&gt;

&lt;div&gt;
&lt;/div&gt;

&lt;div&gt;With techniques like backpropagation, stochastic gradient decent... we can optimize the weights to make useful things, like image or sound recognition and generation.&lt;/div&gt;

&lt;div&gt;
&lt;/div&gt;

&lt;div&gt;So, how I see it, the main question is:&lt;/div&gt;

&lt;div&gt;- &lt;li&gt;Does it matter the rigor, how much we understand about what we do, how much we understand our models and their predictions? Or we just care about minimizing the out of sample error?&lt;/li&gt;
&lt;div&gt;This may be a free interpretation of what was being discussed at NIPS, for example at [Ali Rahimi's talk](https://www.youtube.com/watch?v=Qi1Yry33TQE), or at the [interpretability debate](https://www.youtube.com/watch?v=2hW05ZfsUUo). It was interesting to see how excited people was about the debate, and the "celebrities" on the stage:&lt;/div&gt;&lt;/div&gt;

&lt;div&gt;
&lt;/div&gt;

&lt;div&gt;
&lt;/div&gt;

&lt;div&gt;I think someone important was missing from the debate, and it's what Chris Olah and Shan Carter describe as [research debt](https://distill.pub/2017/research-debt/). Like in software, it's not only important what do you have today. It's important what will you have in the future. The best the internal quality of your software, the easier will be to improve it and add new features in the future. I think every good sofware engineer is aware of how important is to keep technical debt under control. But I don't think most researchers are aware that our understanding of the research today, is key for future research.&lt;/div&gt;

&lt;div&gt;
&lt;/div&gt;

&lt;div&gt;So, in my opinion, it's not that important that with deep learning we can have state of the art results in many areas. I don't think we'll have much better results in the future, unless we focus on quality research, and not just trying random things to get a small increase in the model accuracy.&lt;/div&gt;

&lt;div&gt;
&lt;/div&gt;

&lt;h2&gt;GANs&lt;/h2&gt;

&lt;div&gt;I think Generative Adversarial Networks were by far the most popular topic at NIPS. I'm not sure how many talks [Ian Goodfellow](https://twitter.com/goodfellow_ian) gave, but it don't think it wasn't far from one every day. And it was all sort of applications of GANs, including many for creativity and design. We're not yet in the point of being able to generate arbitrary images with high definition, but it doesn't seem it'll take that long to have even more impressive results than what we've already seen. One of the most discussed articles was the [GAN that generates celebrity faces](http://research.nvidia.com/publication/2017-10_Progressive-Growing-of).&lt;/div&gt;

&lt;h2&gt;Bayesian statistics&lt;/h2&gt;

&lt;div&gt;Bayesian statistics was also very present during the whole NIPS. Many times together with deep learning, like in the [Bayesian deep learning and deep Bayesian learning](https://www.youtube.com/watch?v=LVBvJsTr3rg) talk, the [Bayesian deep learning workshop](http://bayesiandeeplearning.org/), or the [Bayesian GAN paper](https://arxiv.org/abs/1705.09558). Gaussian processes and Bayesian optimization was also present from the tutorials, to the workshops.&lt;/div&gt;

&lt;div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;img alt="" src="https://2.bp.blogspot.com/-1Mxh3NYVT6c/WjWW7-KrdFI/AAAAAAAAymg/9JkkoIwR_IkJugjkMLN7zHJvZVfGuRUNQCLcBGAs/s320/IMG_20171207_095819.jpg"&gt;&lt;div&gt;
&lt;/div&gt;&lt;div&gt;
&lt;/div&gt;&lt;div&gt;Surprisingly to me, most of the papers presented about multi-armed bandit problems were based on frequentist statistics. And I say surprisingly, because I think the industry is mostly adopting Bayesian methods for A/B testing, one of the main applications. In my opinion Bayesian methods are much simpler and intuitive, and tend to offer better results. One of the hot topics in this area is lowering the false discovery rate in repeated tests. And many paper about contextual bandits were also presented, and are that I discovered at NIPS.&lt;/div&gt;&lt;h2&gt;Reinforcement learning&lt;/h2&gt;RL was the last of the main topics that kept repeating during the whole NIPS, if I'm not missing any. Both based on the classic q-learning, or by using deep learning representations.
&lt;h2&gt;Other topics&lt;/h2&gt;&lt;div&gt;There were a couple of other topics that I found interesting, and that they were new to me:&lt;/div&gt;&lt;div&gt;- &lt;li&gt;Optimal transportation&lt;/li&gt;&lt;li&gt;Distribution regression&lt;/li&gt;
&lt;div&gt;A great talk, but not because of the technical content, was the "Improvised Comedy as a Turing Test", where two researchers and comedian performed improvised comedy with a robot implemented by them:&lt;/div&gt;&lt;div&gt;
&lt;/div&gt;&lt;img alt="" src="https://3.bp.blogspot.com/-K53U9yH7cuw/WjWbIGnNteI/AAAAAAAAynE/DQIjDM4FhY8IQcEk2WwL6XRHXozcMEa-ACLcBGAs/s320/IMG_20171208_114630.jpg"&gt;&lt;div&gt;
&lt;/div&gt;&lt;h2&gt;About the conference&lt;/h2&gt;&lt;/div&gt;&lt;div&gt;It was the first time for me attending an academic conference, and some things weren't very intuitive, being used to open source of business conferences. This is a random list with my thoughts:&lt;/div&gt;&lt;div&gt;- &lt;li&gt;I found the location quite good:&lt;/li&gt;&lt;ul&gt;&lt;li&gt;Near to a main airport, so I could fly directly from London&lt;/li&gt;&lt;li&gt;Good temperature&lt;/li&gt;&lt;li&gt;Many hotels nearby&lt;/li&gt;&lt;li&gt;English speaking country&lt;/li&gt;&lt;li&gt;The only problem with the location was that people from several countries (e.g. Iran) were banned from attending, as the organizers mentioned in the home page of the conference&lt;/li&gt;
&lt;/ul&gt;- &lt;li&gt;I found the use of an app to communicate during the conference quite convenient. Even if the app had some obvious flaws, like the mess with the list of discussions, it added a lot of value&lt;/li&gt;
&lt;ul&gt;&lt;li&gt;I found it difficult to know what to expect about food. I think in all previous conference I attended (and they are not few), breakfast and lunch was provided. At #NIPS it was advertised in the schedule that breakfast wasn't offered first time in the morning, no other mention. Then, breakfast was provided later in the morning (one day the 
&lt;img alt="" src="https://2.bp.blogspot.com/-sytt8-nPHl8/WjWYACiZGuI/AAAAAAAAymo/FMSCxkkEsTgxLw20XjnvuJH6iJyR9Ux2gCLcBGAs/s320/IMG_20171205_112058.jpg"&gt;
&lt;/div&gt;
&lt;img alt="" src="https://3.bp.blogspot.com/-z7jNlTYgsng/WjWYIPJzDxI/AAAAAAAAyms/UtTvsA9wQekj_yOomq9dkEXEuCQt-zzgQCLcBGAs/s320/IMG_20171206_103655.jpg"&gt;&lt;div&gt;
&lt;/div&gt;- &lt;li&gt;Compared to open source conferences, I found the atmosphere at NIPS very different. May be it's by the nature of research and open source, but my experience is that open source conferences have a very collaborative environment. You don't necessarily need to like or use someone else's project, to have a friendly discussion or appreciate his contribution. But I felt research quite a competitive environment. More than once I saw people in presentations or posters addressing the presenter in a not very nice way. Challenging their research, trying to point out that they know better. I think providing constructive feedback is always great, but I found sad this feeling of mine (that may be biased by just the few examples I saw) that researchers see each others more as rivals, than as part of a community that delivers together.&lt;/li&gt;
&lt;h2&gt;Systems&lt;/h2&gt;&lt;/div&gt;&lt;div&gt;On the systems part (mainly in the workshop), it was very interesting to see the talks about the main tensor software from the big companies at Silicon Valley:&lt;/div&gt;&lt;div&gt;- &lt;li&gt;&lt;a class="twitter-atreply pretty-link js-nav" data-mentioned-user-id="254107028" dir="ltr" href="https://twitter.com/TensorFlow" style="background: rgb(245, 248, 250); color: #1b95e0; font-family: &amp;quot;Helvetica Neue&amp;quot;, Helvetica, Arial, sans-serif; font-size: 14px; text-decoration: none; white-space: pre-wrap;"&gt;@TensorFlow&lt;/a&gt;&lt;span style="background-color: #f5f8fa; color: #14171a; font-family: &amp;quot;helvetica neue&amp;quot; , &amp;quot;helvetica&amp;quot; , &amp;quot;arial&amp;quot; , sans-serif; font-size: 14px; white-space: pre-wrap;"&gt; : &lt;/span&gt;&lt;a class="twitter-atreply pretty-link js-nav" data-mentioned-user-id="17661484" dir="ltr" href="https://twitter.com/rajatmonga" style="background: rgb(245, 248, 250); color: #1b95e0; font-family: &amp;quot;Helvetica Neue&amp;quot;, Helvetica, Arial, sans-serif; font-size: 14px; text-decoration: none; white-space: pre-wrap;"&gt;@rajatmonga&lt;/a&gt;&lt;span style="background-color: #f5f8fa; color: #14171a; font-family: &amp;quot;helvetica neue&amp;quot; , &amp;quot;helvetica&amp;quot; , &amp;quot;arial&amp;quot; , sans-serif; font-size: 14px; white-space: pre-wrap;"&gt; &lt;/span&gt;&lt;a class="twitter-atreply pretty-link js-nav" data-mentioned-user-id="20536157" dir="ltr" href="https://twitter.com/Google" style="background: rgb(245, 248, 250); color: #1b95e0; font-family: &amp;quot;Helvetica Neue&amp;quot;, Helvetica, Arial, sans-serif; font-size: 14px; text-decoration: none; white-space: pre-wrap;"&gt;@Google&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a class="twitter-atreply pretty-link js-nav" data-mentioned-user-id="776585502606721024" dir="ltr" href="https://twitter.com/PyTorch" style="background: rgb(245, 248, 250); color: #1b95e0; font-family: &amp;quot;Helvetica Neue&amp;quot;, Helvetica, Arial, sans-serif; font-size: 14px; text-decoration: none; white-space: pre-wrap;"&gt;@PyTorch&lt;/a&gt;&lt;span style="background-color: #f5f8fa; color: #14171a; font-family: &amp;quot;helvetica neue&amp;quot; , &amp;quot;helvetica&amp;quot; , &amp;quot;arial&amp;quot; , sans-serif; font-size: 14px; white-space: pre-wrap;"&gt; : &lt;/span&gt;&lt;a class="twitter-atreply pretty-link js-nav" data-mentioned-user-id="70831441" dir="ltr" href="https://twitter.com/soumithchintala" style="background: rgb(245, 248, 250); color: #1b95e0; font-family: &amp;quot;Helvetica Neue&amp;quot;, Helvetica, Arial, sans-serif; font-size: 14px; text-decoration: none; white-space: pre-wrap;"&gt;@soumithchintala&lt;/a&gt;&lt;span style="background-color: #f5f8fa; color: #14171a; font-family: &amp;quot;helvetica neue&amp;quot; , &amp;quot;helvetica&amp;quot; , &amp;quot;arial&amp;quot; , sans-serif; font-size: 14px; white-space: pre-wrap;"&gt; &lt;/span&gt;&lt;a class="twitter-atreply pretty-link js-nav" data-mentioned-user-id="2425151" dir="ltr" href="https://twitter.com/facebook" style="background: rgb(245, 248, 250); color: #1b95e0; font-family: &amp;quot;Helvetica Neue&amp;quot;, Helvetica, Arial, sans-serif; font-size: 14px; text-decoration: none; white-space: pre-wrap;"&gt;@facebook&lt;/a&gt;&lt;/li&gt;&lt;li&gt;CTNK: Cha Zang, &lt;a class="twitter-atreply pretty-link js-nav" data-mentioned-user-id="74286565" dir="ltr" href="https://twitter.com/Microsoft" style="background: rgb(245, 248, 250); color: #1b95e0; font-family: &amp;quot;Helvetica Neue&amp;quot;, Helvetica, Arial, sans-serif; font-size: 14px; text-decoration: none; white-space: pre-wrap;"&gt;@Microsoft&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a class="twitter-atreply pretty-link js-nav" data-mentioned-user-id="824121287790493697" dir="ltr" href="https://twitter.com/ApacheMXNet" style="background: rgb(245, 248, 250); color: #1b95e0; font-family: &amp;quot;Helvetica Neue&amp;quot;, Helvetica, Arial, sans-serif; font-size: 14px; text-decoration: none; white-space: pre-wrap;"&gt;@ApacheMXNet&lt;/a&gt;&lt;span style="background-color: #f5f8fa; color: #14171a; font-family: &amp;quot;helvetica neue&amp;quot; , &amp;quot;helvetica&amp;quot; , &amp;quot;arial&amp;quot; , sans-serif; font-size: 14px; white-space: pre-wrap;"&gt; : &lt;/span&gt;&lt;a class="twitter-atreply pretty-link js-nav" data-mentioned-user-id="3187990776" dir="ltr" href="https://twitter.com/tqchenml" style="background: rgb(245, 248, 250); color: #1b95e0; font-family: &amp;quot;Helvetica Neue&amp;quot;, Helvetica, Arial, sans-serif; font-size: 14px; text-decoration: none; white-space: pre-wrap;"&gt;@tqchenml&lt;/a&gt;&lt;span style="background-color: #f5f8fa; color: #14171a; font-family: &amp;quot;helvetica neue&amp;quot; , &amp;quot;helvetica&amp;quot; , &amp;quot;arial&amp;quot; , sans-serif; font-size: 14px; white-space: pre-wrap;"&gt; &lt;/span&gt;&lt;a class="twitter-atreply pretty-link js-nav" data-mentioned-user-id="20793816" dir="ltr" href="https://twitter.com/amazon" style="background: rgb(245, 248, 250); color: #1b95e0; font-family: &amp;quot;Helvetica Neue&amp;quot;, Helvetica, Arial, sans-serif; font-size: 14px; text-decoration: none; white-space: pre-wrap;"&gt;@amazon&lt;/a&gt;&lt;/li&gt;
&lt;/div&gt;&lt;div&gt;On the fun side, TensorFlow presented their eager mode, and &lt;a href="https://twitter.com/soumithchintala"&gt;Soumith Chintala&lt;/a&gt; mentioned that "PyTorch implementes the eager mode, before the eager mode existed". And some time after he mentioned that PyTorch will implement distributions soon, the way TensorFlow does. So, the main innovation from each project, is copied from the competitor. :)&lt;/div&gt;&lt;div&gt;
&lt;/div&gt;&lt;img alt="" src="https://1.bp.blogspot.com/-gwvDnOMXP-0/WjWZzRQEbhI/AAAAAAAAym4/6UXpOVFq2LUdMvdRuQ74rrly0NvuPigogCLcBGAs/s320/IMG_20171208_133415.jpg"&gt;&lt;div&gt;
&lt;/div&gt;&lt;div&gt;
&lt;/div&gt;&lt;div&gt;Tensors aside, the star of the ML Systems workshop was &lt;a href="http://www.businessinsider.com/astounding-facts-about-googles-most-badass-engineer-jeff-dean-2012-1?IR=T"&gt;Jeff Dean&lt;/a&gt;. He discussed TPUs, and how Google is creating the infrastructure for training deep learning models. The interest in Google, deep learning and Jeff Dean was maximum, and the room was as crowded as a room can be. Some time before the talk, I had the honor to meet Jeff Dean, as the picture proves:&lt;/div&gt;&lt;div&gt;
&lt;/div&gt;&lt;img alt="" src="https://4.bp.blogspot.com/-A8e3KBK1H8U/WjWdnKXTzMI/AAAAAAAAynQ/9_Pa7PloYWAVzhrjYMciLlaH04R5Qm6yACLcBGAs/s320/b7145f54-cb90-4d92-b370-4d938ffb754c.jpg"&gt;
&lt;img alt="" src="https://3.bp.blogspot.com/-gvXWHbHt65Y/WjWd-H3i39I/AAAAAAAAynY/pkhlCwKFK0g7vZOrMvMvcJa1FwtkyYWfgCLcBGAs/s320/IMG_20171208_145408.jpg"&gt;
&lt;img alt="" src="https://4.bp.blogspot.com/-58pte2zkuNA/WjWd9kN-_bI/AAAAAAAAynU/8xrRtjV_L0wW8hRcpIHpLAxbG2a9jfLYQCLcBGAs/s320/IMG_20171208_145427.jpg"&gt;&lt;div&gt;
&lt;/div&gt;&lt;div&gt;
&lt;/div&gt;&lt;div&gt;On the more pragmatic part, it was interesting to see the poster about &lt;a href="https://github.com/catboost/catboost"&gt;CatBoost&lt;/a&gt;, Yandex's version of gradient boosting trees. I found the ideas in the paper quite interesting. There are different novel parts compared to xgboost. I spent a bit of time testing if the results were as good as presented, but the documentation is not yet as good as could be, and the API a bit confusing, and I finally gave up.&lt;/div&gt;&lt;div&gt;
&lt;/div&gt;&lt;div&gt;One of the most interesting insights from NIPS, wasn't actually presented. It was in a discussion with &lt;a href="https://twitter.com/GaelVaroquaux"&gt;Gael Varoquaux&lt;/a&gt;, core contributor of scikit-learn. I wanted to talk with him about scikit-learn, and see if we could help with its development as part of the &lt;a href="https://www.meetup.com/Python-Sprints/"&gt;London Python Sprints&lt;/a&gt; group. But given the current state and the nature of the project, that doesn't seem very useful at this point (See &lt;a href="https://datapythonista.blogspot.co.uk/2017/12/my-nips-write-up.html?showComment=1513602207828#c4342955784338059589"&gt;this comment&lt;/a&gt; for clarification on this). But what it was interesting about the conversation, was to discover the new &lt;a href="https://github.com/scikit-learn/scikit-learn/pull/9012"&gt;ColumnTransformer&lt;/a&gt;. While it's not yet merged, a pull request already exists to be able to apply sklearn transformers to a subset of columns. At the moment sklearn doesn't provide an easy way (or a way that you can understand your models later), and I think most of us were implementing this ourselves in our own projects.&lt;/div&gt;&lt;h2&gt;A sad story&lt;/h2&gt;&lt;div&gt;To conclude, I want to mention not something that I experienced myself at NIPS, but that many of us read later on, and it's &lt;a href="https://medium.com/@kristianlum/statistics-we-have-a-problem-304638dc5de5"&gt;Kristian Lum story&lt;/a&gt; about sexual harassment in research. Hopefully all this wave of scandals is the beginning of the end, from English politicians, to Hollywood... And it may not be fair, but while equally disgusting as all the other cases, I found it more surprising in research. That the brightest minds in their fields have been abusing and abused, is something that I find more shocking than in an industry like Hollywood.&lt;/div&gt;&lt;div&gt;
&lt;/div&gt;&lt;div&gt;The second part of the story, this one with names, came not much later, in this &lt;a href="https://www.bloomberg.com/news/articles/2017-12-16/google-researcher-accused-of-sexual-harassment-roiling-ai-field"&gt;Bloomberg article&lt;/a&gt;.&lt;/div&gt;&lt;div&gt;
&lt;/div&gt;&lt;div&gt;On a positive note, I think the problem is not that difficult to solve. In the Python community I think we've got all the mechanisms in place in order to avoid these problems as much as possible. With strict codes of conducts, to whistleblower channels in conferences like EuroPython, to a friendly and inclusive environment. The paradox is that the proportion of female attendees in Python conferences is much smaller than what I saw at NIPS. I'd bet a large number of women should make these cases less likely.&lt;/div&gt;&lt;div&gt;
&lt;/div&gt;&lt;div&gt;I hope the example of Kristian is not only useful to fix this specific case, but also to make it easier for other people to speak up, and finish with this forever.&lt;/div&gt;&lt;/p&gt;</content></entry><entry><title>Assigning yourself to a GitHub issue</title><link href="https://datapythonista.github.io/blog/assigning-yourself-to-github-issue.html" rel="alternate"></link><published>2017-10-13T21:30:00+01:00</published><updated>2017-10-13T21:30:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2017-10-13:/blog/assigning-yourself-to-github-issue.html</id><summary type="html">&lt;p&gt;Contributing to open source is one of the most rewarding experiences one can find. Just finding a bug or a new cool feature of a widely used library, working on it, and sharing it with the rest of the users. This is how open source has become so great and …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Contributing to open source is one of the most rewarding experiences one can find. Just finding a bug or a new cool feature of a widely used library, working on it, and sharing it with the rest of the users. This is how open source has become so great and so widely used.&lt;/p&gt;
&lt;p&gt;The workflow just described is relatively simply at a small scale, but can become trickier when many people is working in the same project at the same time.&lt;/p&gt;
&lt;p&gt;One idea I have in mind, is to create a macro-sprint, where many Python user groups of all around the world sprint on improving &lt;a href="https://github.com/pandas-dev/pandas"&gt;Pandas&lt;/a&gt; documentation. Pandas documentation isn't bad, but it could easily be improved by adding more examples to the DataFrame and Series methods for example. An example of page that could be improved by adding examples is the &lt;a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.rmul.html#pandas.Series.rmul"&gt;Series rmul method&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To organize this, every sprinting team could get a subset of methods. For example, one of the teams could work on the &lt;a href="https://pandas.pydata.org/pandas-docs/stable/api.html#conversion"&gt;Series conversion methods&lt;/a&gt;. This is a bit tricky, but even with a simple online spreadsheet with all the method categories, we could assign each to a group.&lt;/p&gt;
&lt;p&gt;Then, in a sprint with 20 people, working in the same methods, we would create another spreadsheet with each method, and every programmer could assign himself to the method he wants to work on. So, nobody else works on it, which would end up in a lot of wasted time and duplicated work.&lt;/p&gt;
&lt;p&gt;But of course, this is very tricky. In a coordinated sprint, working on something very structured like Pandas methods could work. But sounds ridiculous that each project has a spreadsheet with the list of issues, so every programmer can let the others know what she or he is working on.&lt;/p&gt;
&lt;p&gt;This was a solved problem 10 years ago when I was quite involved with the &lt;a href="https://www.djangoproject.com/"&gt;Django&lt;/a&gt; community. At that time, Django was using &lt;a href="https://trac.edgewall.org/"&gt;Trac&lt;/a&gt; to manage the tickets. And every ticket had an "Assigned to" field, where a programmer could let others know that they shouldn't work on it without talking to her or him first.&lt;/p&gt;
&lt;p&gt;What is this an issue today? While there are few companies that did as much as &lt;a href="https://github.com/"&gt;GitHub&lt;/a&gt; for the open source community, I think they made a big mistake. GitHub also has the "Assigned to" field, but this can only be edited by core developers of the project.&lt;/p&gt;
&lt;p&gt;Core developers are surely one of the bottlenecks of every open source community. Coming back to Pandas, there are at the time of writing this post, 100 open pull requests. So, it doesn't seem a good idea, that every time you want to work on an issue, you need to bother a core developer, so she or he assigns the ticket to you.&lt;/p&gt;
&lt;p&gt;Is this affecting the open source community? It's difficult to tell, but if we compare the number of assigned tickets in Pandas and Python, we can see how Pandas has 2,039 open issues, but only 30 of them are assigned (I bet all them to core developers).&lt;/p&gt;
&lt;p&gt;In comparison, if we check the &lt;a href="https://bugs.python.org/"&gt;Python bug tracker&lt;/a&gt;&amp;nbsp;(Python uses GitHub for the code, but not for the issues), we can see that around 50% of the tickets seem to be assigned to someone.&lt;/p&gt;
&lt;p&gt;It's difficult to tell what's the effect in code contributions, besides in ticket assignment, but it's reasonable to think that GitHub is discouraging users from contributing, by not letting them assign issues to themselves.&lt;/p&gt;
&lt;p&gt;As shown in this &lt;a href="https://github.com/isaacs/github/issues/100"&gt;thread&lt;/a&gt;, npm creator requested this feature in 2013. 4 years later, there are many +1's in this unofficial ticket (it's not a ticket for GitHub developers, it's for the creator of npm himself, to keep track of his request to GitHub). But the feature is still missing.&lt;/p&gt;
&lt;p&gt;Why GitHub is against, or has no interest, in a feature so obviously needed to have a healthy open source community is a mystery to me. But if you feel like I feel, please let &lt;a href="https://github.com/contact"&gt;GitHub support&lt;/a&gt; know.&lt;/p&gt;</content></entry><entry><title>PyData London 2017, write up</title><link href="https://datapythonista.github.io/blog/pydata-london-2017-write-up.html" rel="alternate"></link><published>2017-05-09T11:06:00+01:00</published><updated>2017-05-09T11:06:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2017-05-09:/blog/pydata-london-2017-write-up.html</id><summary type="html">&lt;p&gt;This is a post about my experience at &lt;a href="https://pydata.org/london2017/"&gt;PyData London 2017&lt;/a&gt;. About what I liked, what I learnt... Note that having 4 tracks, and so many people, my opinions are very biased. If you want to know how your experience would be, it'll be amazing, but different than mine. :)&lt;/p&gt;
&lt;p&gt;On …&lt;/p&gt;</summary><content type="html">&lt;p&gt;This is a post about my experience at &lt;a href="https://pydata.org/london2017/"&gt;PyData London 2017&lt;/a&gt;. About what I liked, what I learnt... Note that having 4 tracks, and so many people, my opinions are very biased. If you want to know how your experience would be, it'll be amazing, but different than mine. :)&lt;/p&gt;
&lt;p&gt;On the organization side, I think it's been excellent. Everything worked as expected, and when I've got a problem with wifi, I got it fixed literally in couple of minutes by the organizers. It was great to have sushi and burritos instead of last year sandwiches too. The slack channels were quite useful and well organized. I think the organizers deserve a 10, and that's very challenging when organizing a conference.&lt;/p&gt;
&lt;p&gt;More on the content side, I used to attend conferences mainly for talks. But this year I decided to try other things a conference can offer (networking, sprints, unconference sessions...). Some random notes:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: x-large;"&gt;Bayesian stuff&lt;/span&gt;&lt;/strong&gt;
&lt;b&gt;
&lt;/b&gt;I think probabilistic models is the are of data science with a higher entry barrier. This is a personal opinion, but shared by many others, including authors:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;i style="font-style: italic;"&gt;The Bayesian method is the natural approach to inference, yet it is hidden from readers behind chapters of slow, mathematical analysis. The typical text on Bayesian inference involves two to three chapters on probability theory, then enters what Bayesian inference is. Unfortunately, due to mathematical intractability of most Bayesian models, the reader is only shown simple, artificial examples. This can leave the user with a so-what feeling about Bayesian inference. In fact, this was the author's own prior opinion.&lt;/i&gt;&lt;/strong&gt;
&lt;strong&gt;&lt;a href="https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers"&gt;Cameron Davidson-Pilon&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;It looks like there is even terminology to define whether the approach used is mathematical (formulae and proofs quite cryptic to me), or computational (more focused on the implementation).&lt;/p&gt;
&lt;p&gt;It was luxury to have at PyData once more, &lt;a href="https://www.linkedin.com/in/vincentwarmerdam/"&gt;Vincent Warmerdam&lt;/a&gt;, from the PyData Amsterdam organization. He has been one step ahead of most of us, who are more focused on machine learning (I didn't meet any frequentist so far at PyData conferences). He already gave a talk last year about the topic,&amp;nbsp;&lt;a href="https://www.youtube.com/watch?v=BiYTLb-o1Dk&amp;amp;list=PLGVZCDnMOq0rzDLHi5WxWmN5vueHU5Ar7&amp;amp;index=2"&gt;The Duct Tape of Heroes: Bayes Rule&lt;/a&gt;, which was quite inspiring and make probabilistic models easier, and this year we've got another amazing talk, &lt;a href="https://pydata.org/london2017/schedule/presentation/36/"&gt;SaaaS: Sampling as an Algorithm Service&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;After that, we managed to have an unconference session with him, where we could see more in detail the examples presented in the talk. While Markov Chain Monte Carlo or Gibbs sampling aren't straight forward to learn, I think we all learnt a lot, so we can finish learning all the details easily by ourselves.&lt;/p&gt;
&lt;p&gt;There were other sessions about Bayesian stuff too:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;li&gt;&lt;a href="https://pydata.org/london2017/schedule/presentation/61/&amp;quot; style=&amp;quot;box-sizing: border-box; color: #337ab7; text-decoration-line: none; transition: all 295ms ease;"&gt;Bayesian optimisation with scikit-learn&lt;/a&gt;&amp;nbsp;- Thomas Huijskens&lt;/li&gt;&lt;li&gt;&lt;a href="https://pydata.org/london2017/schedule/presentation/15/&amp;quot; style=&amp;quot;box-sizing: border-box; color: #337ab7; text-decoration-line: none; transition: all 295ms ease;"&gt;Variational Inference and Python&lt;/a&gt;&amp;nbsp;- Peadar Coyle&lt;/li&gt;&lt;li&gt;&lt;a href="https://pydata.org/london2017/schedule/presentation/33/&amp;quot; style=&amp;quot;box-sizing: border-box; color: #337ab7; text-decoration-line: none; transition: all 295ms ease;"&gt;Bayesian Deep Learning with Edward (and a trick using Dropout)&lt;/a&gt;&amp;nbsp;- Andrew Rowan&lt;/li&gt;&lt;li&gt;&lt;a href="https://pydata.org/london2017/schedule/presentation/45/&amp;quot; style=&amp;quot;box-sizing: border-box; color: #337ab7; text-decoration-line: none; transition: all 295ms ease;"&gt;Segmenting Channel 4 Viewers using LDA Topic Modelling&lt;/a&gt;&amp;nbsp;- Thomas Nuttall&lt;/li&gt;
&lt;div&gt;And probably some others that I'm missing, so it looks like the interest on the area is growing, and &lt;a href="https://github.com/pymc-devs/pymc3"&gt;PyMC3&lt;/a&gt; looks to be the preferred option of most people.&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I've got good recommendations of books related to probabilistic models and Bayesian stuff, which shouldn't use the tough approach:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;li&gt;&lt;a href="https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers"&gt;Bayesian methods for Hackers&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="http://www.inference.eng.cam.ac.uk/mackay/itila/"&gt;Information theory, inference and learning algorithms&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.amazon.co.uk/Computer-Age-Statistical-Inference-Mathematical/dp/1107149894/ref=sr_1_1?s=books&amp;amp;ie=UTF8&amp;amp;qid=1494246251&amp;amp;sr=1-1&amp;amp;keywords=computer+age+statistical+inference"&gt;Computer age statistical inference&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.crcpress.com/Statistical-Rethinking-A-Bayesian-Course-with-Examples-in-R-and-Stan/McElreath/p/book/9781482253443"&gt;Statistical Rethinking: A Bayesian course with examples in R and Stan&lt;/a&gt;&lt;/li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There is a Meetup in London, which is the place to be to meet other Bayesians:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;li&gt;&lt;a href="https://www.meetup.com/Bayesian-Mixer-London/"&gt;Bayesian Mixer London&lt;/a&gt;&lt;/li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span style="font-size: x-large;"&gt;&lt;strong&gt;Frequentist stuff&lt;/strong&gt;&lt;/span&gt;
&lt;div style="text-align: center;"&gt;
&lt;/div&gt;&lt;strong&gt;&lt;This space is for sale, contact the administrator of the page&gt;&lt;/strong&gt;
&lt;div style="text-align: center;"&gt;
&lt;/div&gt;&lt;div style="text-align: left;"&gt;&lt;span style="font-size: x-large;"&gt;&lt;strong&gt;Topic modeling and Gensim&lt;/strong&gt;&lt;/span&gt;&lt;/div&gt;&lt;div style="text-align: left;"&gt;
&lt;/div&gt;&lt;div style="text-align: left;"&gt;Another topic that it looks like it's trending is topic modelling, using vector spaces for NLP, and Gensim in particular. Including Latent Dirichlet allocation, one of the most amazing algorithms I've seen in action.&lt;/div&gt;&lt;div style="text-align: left;"&gt;
&lt;/div&gt;&lt;div style="text-align: left;"&gt;We also got a Gensim sprint during the conference, and we could not only learn about what Gensim does, but also why is a great open source project. In the past I could see how Gensim was able to answer the most similar documents immediately, in a dataset with more than one million samples. While the documentation gives many hints on how Gensim was designed with performance in mind, it was a pleasure to participate in a Gensim sprint, and see the code and the people who make this happen in action.&lt;/div&gt;&lt;div style="text-align: left;"&gt;
&lt;/div&gt;Amazing also to see&amp;nbsp;how &lt;a href="https://www.linkedin.com/in/levkonst/"&gt;Lev Konstantinovskiy&lt;/a&gt; managed to run a tutorial, a talk, a sprint and a lightning talk, during the conference.&lt;/p&gt;
&lt;p&gt;&lt;b style="font-size: x-large;"&gt;From theory to practice&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;It may be just my impression, but I'd say there have been more talks on applications of data science, and more diverse. While I remember talks on common applications like recommender systems in previous editions, I think it's been an increase on the talks on applications of all these techniques, in different areas.&lt;/p&gt;
&lt;p&gt;To name few:
- &lt;li&gt;&lt;a href="https://pydata.org/london2017/schedule/presentation/38/"&gt;Data science used to see the popularity of users in a Muslim dating app&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://pydata.org/london2017/schedule/presentation/16/"&gt;Intelligent ventilators, that make newborns breath when they need it&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://pydata.org/london2017/schedule/presentation/43/"&gt;Electrocardiogram analysis with time series techniques&lt;/a&gt;&lt;/li&gt;
&lt;div&gt;Also, the astronomy/aeroespace communities look to be quite active inside the PyData community&lt;/div&gt;&lt;div&gt;
&lt;/div&gt;&lt;div&gt;&lt;span style="font-size: x-large;"&gt;&lt;strong&gt;Data activism&lt;/strong&gt;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;
&lt;/div&gt;&lt;div&gt;Another area which I'd say it's growing is data activism. Or how to use data in a social or political way. We got a keynote on fact checking, and another about analyzing data for good, to prevent money laundry with government information.&lt;/div&gt;&lt;div&gt;
&lt;/div&gt;&lt;div&gt;&lt;a href="http://www.datakind.org/chapters/datakind-uk"&gt;DataKind UK&lt;/a&gt; looks to be the place to be, to participate on this efforts.&lt;/div&gt;&lt;div&gt;
&lt;/div&gt;&lt;div&gt;&lt;b style="font-size: x-large;"&gt;Pub Quiz&lt;/b&gt;&lt;/div&gt;
&lt;strong&gt;&lt;em&gt;That awkward moment when you thought you knew Python, but James Powell is your interviewer...&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Ok, it wasn't an interview, it was a pub quiz, but the feeling was somehow similar. 10 years working in Python, I passed challenging technical interviews for companies such as Bank of America or Google, and at some point you start to think you know what you're doing.&lt;/p&gt;
&lt;p&gt;Then, when you're relaxed in a pub, after and amazing but exhausting day, &lt;a href="https://twitter.com/dontusethiscode"&gt;James Powell&lt;/a&gt; starts running the pub quiz, and you feel that you don't know anything about Python. Some new Python 3 syntax, all time namespace tricks, and so many atypical cases...&lt;/p&gt;
&lt;p&gt;Luckily, all the dots started to connect, and I realized that few hours before, I was discussing with &lt;a href="https://twitter.com/holdenweb"&gt;Steve Holden&lt;/a&gt; about the new edition of his book &lt;a href="http://shop.oreilly.com/product/0636920012610.do"&gt;Python in a Nutshell&lt;/a&gt;. Which sounded like an introduction to me, but it looks like it provides all Python internals.&lt;/p&gt;
&lt;p&gt;Going back to the pub quiz, I think it's one of the most memorable moments in a conference. Great people, loads of laughs, and an amazing set of questions perfectly executed.&lt;/p&gt;
&lt;p&gt;&lt;span style="font-size: x-large;"&gt;&lt;strong&gt;Big Data becoming smaller&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;As I mentioned before, my experience at the conference is very biased, and very influenced by the talks I attended, the people I met... But my impression is that the boom on big data (large deep networks, spark...) is not a boom anymore.&lt;/p&gt;
&lt;p&gt;Of course there is a lot of people working with Spark, and researching in deep neural networks, but instead of growing, I felt like these things are loosing momentum, and people is focusing on other technologies and topics.&lt;/p&gt;
&lt;p&gt;&lt;b style="font-size: x-large;"&gt;Meetup groups&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;One of the things I was interested in, was on finding new interesting meetups. I think among the most popular ones in data science are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;li&gt;&lt;a href="https://www.meetup.com/PyData-London-Meetup/"&gt;https://www.meetup.com/PyData-London-Meetup/&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.meetup.com/London-Machine-Learning-Meetup/"&gt;https://www.meetup.com/London-Machine-Learning-Meetup/&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.meetup.com/London-ODSC/"&gt;https://www.meetup.com/London-ODSC/&lt;/a&gt;&lt;/li&gt;
&lt;div&gt;But I met many organizers of other very interesting meetups at the conference:&lt;/div&gt;&lt;div&gt;- &lt;li&gt;&lt;a href="https://www.meetup.com/London-Data-Science-Journal-Club/"&gt;https://www.meetup.com/London-Data-Science-Journal-Club/&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.meetup.com/London-Kaggle-Meetup/"&gt;https://www.meetup.com/London-Kaggle-Meetup/&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.meetup.com/project_euler/"&gt;https://www.meetup.com/project_euler/&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.meetup.com/DataKind-UK/"&gt;https://www.meetup.com/DataKind-UK/&lt;/a&gt;&lt;/li&gt;
&lt;div&gt;&lt;b style="font-size: x-large;"&gt;Some obvious things&lt;/b&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;
&lt;/div&gt;&lt;div&gt;To conclude, there are couple of tools/packages I discovered, that seemed everybody else was aware of.&lt;/div&gt;&lt;div&gt;
&lt;/div&gt;&lt;div&gt;It looks like &amp;nbsp;at some point, instant messaging of most free software projects moved from IRC to &lt;a href="https://gitter.im/"&gt;gitter&lt;/a&gt;. There you can find data science communities, like pandas, scikit-learn, as well as other non data science, like Django.&amp;nbsp;&lt;/div&gt;&lt;div&gt;
&lt;/div&gt;&lt;div&gt;A package that many people seems to be using, is &lt;a href="https://github.com/noamraph/tqdm"&gt;tqdm&lt;/a&gt;. You can use it over an iterator (like enumerate), and it shows a progress bar while the iterations is running. Funny, that besides being an abbreviation of progress in Arabic, i's an abbreviation for "I want/love you too much" in Spanish.&lt;/div&gt;&lt;div&gt;
&lt;/div&gt;&lt;div&gt;&lt;span style="font-size: x-large;"&gt;&lt;strong&gt;What's next?&lt;/strong&gt;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;
&lt;/div&gt;&lt;div&gt;Good news. If you couldn't attend PyData London 2017, or you didn't have enough of it, there are some things you can do:&lt;/div&gt;&lt;div&gt;- &lt;li&gt;Attend PyData Barcelona 2017, which will be as amazing as PyData London, also in English, and with top speakers like &lt;a href="https://twitter.com/teoliphant"&gt;Travis Oliphant&lt;/a&gt; (author of scipy and numpy) or &lt;a href="https://twitter.com/francescalted?lang=en"&gt;Francesc Alted&lt;/a&gt; (author of PyTables, Blosc, bcolz and numexpr).&lt;/li&gt;&lt;li&gt;Wait until the videos are published in the &lt;a href="https://www.youtube.com/user/PyDataTV"&gt;PyData channel&lt;/a&gt; (or watch the ones from other PyData conferences)&lt;/li&gt;&lt;li&gt;Join one of the 55 &lt;a href="https://www.meetup.com/pro/pydata/"&gt;PyData meetups&lt;/a&gt; around the world, or start yours (check &lt;a href="https://docs.google.com/document/d/1ozK-MXUEANuO-xN3tQSCQ7AaqOkubKBeivqC3s-gB8I/edit"&gt;this document&lt;/a&gt; to see how, &lt;a href="https://www.numfocus.org/"&gt;NumFOCUS&lt;/a&gt; will support you).&lt;/li&gt;&lt;li&gt;Join one of the other conferences happening later this year in Paris, Berlin, EuroPython in Italy, Warsaw... You can find all them at&amp;nbsp;&lt;a href="https://pydata.org/"&gt;https://pydata.org/&lt;/a&gt;&lt;/li&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;</content></entry><entry><title>PyData write-up</title><link href="https://datapythonista.github.io/blog/pydata-write-up.html" rel="alternate"></link><published>2016-05-12T00:32:00+01:00</published><updated>2016-05-12T00:32:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2016-05-12:/blog/pydata-write-up.html</id><summary type="html">&lt;p&gt;This last weekend I went to my third PyData, the one in London, and it's been such a great experience.&lt;/p&gt;
&lt;p&gt;Before, I went to PyData Amsterdam, and PyData Madrid, also this year.&lt;/p&gt;
&lt;p&gt;After the three conferences, which were very similar, but quite different at the same time, I just wanted …&lt;/p&gt;</summary><content type="html">&lt;p&gt;This last weekend I went to my third PyData, the one in London, and it's been such a great experience.&lt;/p&gt;
&lt;p&gt;Before, I went to PyData Amsterdam, and PyData Madrid, also this year.&lt;/p&gt;
&lt;p&gt;After the three conferences, which were very similar, but quite different at the same time, I just wanted to share what I liked, and what &lt;strong&gt;in my opinion&lt;/strong&gt; could be improved. I hope future organizers can find some useful information from my ideas and thought. And that includes my future self, for when I'm an organizer.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Organization&lt;/strong&gt;
&lt;b&gt;
&lt;/b&gt;I wasn't involved that much in the organization, but my believe is that more should be delegated. I couldn't see it that much in Amsterdam, but organizers of both Madrid and London looked extremely exhausted at the end of the conference. May be I'm too optimistic, but I'd say that more people would like to help. I think a good idea is probably to find volunteers for specific tasks. For example, probably some people would be happy to help in the registration. And organizers would have more time for other things, and to rest.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Event hosts&lt;/strong&gt;
&lt;b&gt;
&lt;/b&gt;I think in the three conferences there were amazing hosts (the people who gave the welcome speeches, closing notes...). Vincent and the Italian guy (sorry for not remembering your name if you read this) in Amsterdam,Guillem in Madrid, and Ian and Emlyn in London. I think the whole conference makes a difference having hosts with great humour and communication skills.
&lt;ul&gt;&lt;/ul&gt;&lt;div&gt;&lt;div&gt;&lt;strong&gt;Communication&lt;/strong&gt;&lt;/div&gt;&lt;div&gt;&lt;b&gt;
&lt;/b&gt;&lt;/div&gt;&lt;div&gt;I think communication is quite important during the conference. In Madrid was great (and somehow easy), because it was only a single track, so organizers could provide any information between talks to all attendees (where the beers will be, to remind people to sign up for lightning talks...). In Amsterdam with 2 tracks they managed it very well.&lt;/div&gt;&lt;div&gt;
&lt;/div&gt;&lt;div&gt;In London, I think the communication could be better. With 4 tracks it gets much more challenging, but I think just a bit more of communication was needed, like reminding about the lightning talks, reminding about the tweeted photos contest...&lt;/div&gt;&lt;div&gt;
&lt;/div&gt;&lt;div&gt;I personally didn't like that much slack (was my first time using it). The mobile version (the web, not the app) is not very intuitive, and I had problems to find the channels. I prefer twitter to be honest.&lt;/div&gt;&lt;div&gt;
&lt;/div&gt;&lt;strong&gt;Networking&lt;/strong&gt;&lt;/div&gt;&lt;div&gt;&lt;b&gt;
&lt;/b&gt;&lt;/div&gt;&lt;div&gt;I met really great people at all conferences. I don't think other industries have the great community as PyData (and also Python) does. I didn't see anyone trying to sell their product, but it was more about sharing, and getting to know what others do. I really like that.&lt;/p&gt;
&lt;p&gt;I'm not sure if it's just my perception, but I think in London the breaks (breakfast, lunch...) were much shorter. I think London was the conference with a higher number of proposals among the 3, so they tried to accommodate the maximum number of talks, but I personally would prefer to have more time for networking, even if that means few less talks.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Keynotes&lt;/strong&gt;
&lt;b&gt;
&lt;/b&gt;Good keynotes in general. Of course no every PyData is lucky enough to have a keynote from Travis Oliphant, or WesMcKinney, but the level was quite good.&lt;/p&gt;
&lt;p&gt;There were just a couple of things I couldn't understand (neither the people I talked to about):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;li&gt;In Madrid, Jaime (a numpy core developer) talk had to be a keynote. Even if there were already too of high level Christine and Francesc, I think people need to know that a talk from Jaime (an amazing one btw), is not the same as the one I did.&lt;/li&gt;&lt;li&gt;In London, the opposite, I couldn't see why Tetiana talk was a keynote. I won't say that the talk was bad, it was all right, but not at the level of Travis or Andreas for sure, and IMO it had to be a normal talk, and there had to be other talks at the same time as her talk&lt;/li&gt;
&lt;/div&gt;&lt;div&gt;&lt;strong&gt;Talks&lt;/strong&gt;&lt;/div&gt;&lt;div&gt;&lt;b&gt;
&lt;/b&gt;&lt;/div&gt;&lt;div&gt;Very good level. Of course there are some talks better than others, but in general I was quite happy with most of them.&lt;/div&gt;&lt;div&gt;
&lt;/div&gt;&lt;div&gt;As they are (or will be) in youtube, here you have the ones I liked more:&lt;/div&gt;&lt;div&gt;- &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=-aFTKM3nmZo"&gt;Travis Oliphant - KEYNOTE: Scaling Out PyData&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=BXID4teFfDc"&gt;Andreas Freise - KEYNOTE: Laser ranging in a new dimension&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=fli-yE5grtY"&gt;Linda Uruchurtu - Survival Analysis in Python and R&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=jgqTofYLMHM"&gt;Or Weizman - A B Testing: Harder than just a color change&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=By8xlYOCwws&amp;amp;list=PLGVZCDnMOq0o43_3tHLAblfdOWwFFg76T&amp;amp;index=10"&gt;Francesc Alted - New Computer Trends and How This Affects Us&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=o0EacbIbf58&amp;amp;list=PLGVZCDnMOq0o43_3tHLAblfdOWwFFg76T&amp;amp;index=11"&gt;Jaime Fernández - The Future of NumPy Indexing.&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=uju4RXEniA8&amp;amp;list=PLGVZCDnMOq0o43_3tHLAblfdOWwFFg76T&amp;amp;index=14"&gt;Ricardo Pio Monti - Modelling a text corpus using Deep Boltzmann Machines&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=BiYTLb-o1Dk&amp;amp;list=PLGVZCDnMOq0rzDLHi5WxWmN5vueHU5Ar7&amp;amp;index=2"&gt;Vincent Warmerdam - The Duct Tape of Heroes: Bayes Rule&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=GFcFNccbDM8&amp;amp;list=PLGVZCDnMOq0rzDLHi5WxWmN5vueHU5Ar7&amp;amp;index=25"&gt;Dennis Bohle, Ben Teeuwen - Realtime Bayesian A-B testing with Spark Streaming&lt;/a&gt;&lt;/li&gt;
&lt;div&gt;Of course this list is missing many amazing talks, but those are among the ones I remember more that I liked them.&lt;/div&gt;&lt;/div&gt;&lt;div&gt;
&lt;/div&gt;&lt;div&gt;&lt;strong&gt;Lighning talks&lt;/strong&gt;&lt;/div&gt;&lt;div&gt;
&lt;/div&gt;&lt;div&gt;To me, lightning talks are probably the best of a conference. I really like that in Madrid they had lightning talks both on Saturday and Sunday.&lt;/div&gt;&lt;div&gt;
&lt;/div&gt;&lt;div&gt;And for me, it was a mistake to have the lightning talks on Sunday both in Amsterdam and London. First, because people from abroad usually have to miss the end of the conference. And also, because it's great for networking to see all the lightning talks on Saturday, and be able to talk to the speakers on Sunday if you share the same interest.&lt;/div&gt;&lt;div&gt;
&lt;/div&gt;&lt;div&gt;So, IMO, at the end of both days is the best, on Saturday if just one of the days.&lt;/div&gt;&lt;div&gt;
&lt;/div&gt;&lt;div&gt;&lt;strong&gt;Unconference presentations&lt;/strong&gt;&lt;/div&gt;&lt;div&gt;&lt;b&gt;
&lt;/b&gt;&lt;/div&gt;&lt;div&gt;This is very biased by my personal experience, but I think the unconference presentation format was a failure. For what I could see it worked well for the workshop Vincent gave, because he was one of the speakers, and could tell about his workshop to a large audience. But for the rest, I don't think the majority of the attendees knew about that was in that slot.&lt;/div&gt;&lt;div&gt;
&lt;/div&gt;&lt;div&gt;To my talk about machine learning for digital advertising, just 4 people attended. I want to believe, that if the title of the presentation was on the schedule, many more people would have attended. So, in my opinion, if unconference presentations are present in future conferences, the online schedule should be updated, and a (big) board with what is going on in that track, should be present.&lt;/div&gt;&lt;div&gt;
&lt;/div&gt;&lt;div&gt;&lt;strong&gt;Food&lt;/strong&gt;
&lt;b&gt;
&lt;/b&gt;Comparing the three conferences, I think the food was much better in Amsterdam than in Madrid or London. In Madrid they got special meals for people who requested them (vegetarian, allergies...), I don't know in the other conferences. It's difficult to say if it's better to spend more money in better food, of course people like better food, but also cheaper tickets, and higher contributions to free software projects.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;What I could see is that more people decided to go to restaurants in Madrid and London than in Amsterdam. Ok, in Amsterdam there weren't any restaurants around, but I think better food is better for networking. The best is probably to find a good sponsor that pays for nice food, but that looks tricky. So, I think all options are all right.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conclusion&lt;/strong&gt;
&lt;b&gt;
&lt;/b&gt;The whole experince of PyData 2016 it's been amazing. Exhausting (specially the ones I had to take flights to go), but amazing, and really worth.&lt;/p&gt;
&lt;p&gt;The organizers have done an amazing job, the local communities, and for what I could see and hear, the ones from NumFOCUS.&lt;/p&gt;
&lt;p&gt;Now I have a beautiful laptop full of stickers, and several PyData T-shirts.&lt;/p&gt;
&lt;p&gt;There are few minor things that &lt;strong&gt;in my opinion&lt;/strong&gt; could be improved, to make the conference even better:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;li&gt;More time for networking&lt;/li&gt;&lt;li&gt;More communication from the organizers (telling all the time what is going on, sign up for lightning talks, unconferences, problems with the wifi, beers planed, community announcements, and even the smaller things)&lt;/li&gt;&lt;li&gt;More lightning talks&lt;/li&gt;&lt;li&gt;Labelling as keynotes the talks that really make a difference&lt;/li&gt;
&lt;div&gt;Thank you very much to all the people that made them possible, and see you again there next year!&lt;/div&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;</content></entry><entry><title>After Fedora installation tasks</title><link href="https://datapythonista.github.io/blog/after-fedora-installation-tasks.html" rel="alternate"></link><published>2015-12-23T19:38:00+00:00</published><updated>2015-12-23T19:38:00+00:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2015-12-23:/blog/after-fedora-installation-tasks.html</id><summary type="html">&lt;p&gt;What do I do after installing Fedora 23 MATE-Compiz?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;li&gt;Install Google Chrome&lt;/li&gt;&lt;li&gt;Merge both panels to the bottom, and auto-hide it&lt;/li&gt;&lt;li&gt;Change mouse setup to allow touchpad click and double finger scroll&lt;/li&gt;&lt;li&gt;Change look and feel setup to select window when the mouse moves over it&lt;/li&gt;&lt;li&gt;Disable screensaver&lt;/li&gt;&lt;li&gt;Change terminal …&lt;/li&gt;&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;p&gt;What do I do after installing Fedora 23 MATE-Compiz?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;li&gt;Install Google Chrome&lt;/li&gt;&lt;li&gt;Merge both panels to the bottom, and auto-hide it&lt;/li&gt;&lt;li&gt;Change mouse setup to allow touchpad click and double finger scroll&lt;/li&gt;&lt;li&gt;Change look and feel setup to select window when the mouse moves over it&lt;/li&gt;&lt;li&gt;Disable screensaver&lt;/li&gt;&lt;li&gt;Change terminal shortcuts&lt;/li&gt;&lt;li&gt;sudo dnf update&lt;/li&gt;&lt;li&gt;sudo dnf groupinstall "Development Tools"&lt;/li&gt;&lt;li&gt;sudo rpm -ivh http://download1.rpmfusion.org/free/fedora/rpmfusion-free-release-stable.noarch.rpm&lt;/li&gt;&lt;li&gt;sudo dnf install vim-enhanced git vlc gimp inkscape unzip&lt;/li&gt;&lt;li&gt;Install Anaconda&lt;/li&gt;&lt;li&gt;Copy my settings files: .vimrc .gitconfig .ssh&lt;/li&gt;&lt;li&gt;Add aliases to .bashrc:&lt;/li&gt;&lt;ul&gt;&lt;li&gt;alias vi="vim"&lt;/li&gt;&lt;li&gt;alias rgrep="grep -R"&lt;/li&gt;
&lt;li&gt;In Power Management, set up the computer to blank screen when laptop lid is closed&lt;/li&gt;- &lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;</content></entry><entry><title>Jupyter environment setup</title><link href="https://datapythonista.github.io/blog/jupyter-environment-setup.html" rel="alternate"></link><published>2015-12-22T14:07:00+00:00</published><updated>2015-12-22T14:07:00+00:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2015-12-22:/blog/jupyter-environment-setup.html</id><summary type="html">&lt;p&gt;This is a short note about how I set up my "data scientist" environment. Different people have different tastes, but what I use, and what I set up is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;li&gt;&lt;strong&gt;conda&lt;/strong&gt; for environment and package management (equivalent to virtualenv and pip to say)&lt;/li&gt;&lt;li&gt;Latest &lt;strong&gt;Python&lt;/strong&gt; (yes, Python 3)&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Jupyter&lt;/strong&gt;&amp;nbsp;(aka IPython …&lt;/li&gt;&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;p&gt;This is a short note about how I set up my "data scientist" environment. Different people have different tastes, but what I use, and what I set up is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;li&gt;&lt;strong&gt;conda&lt;/strong&gt; for environment and package management (equivalent to virtualenv and pip to say)&lt;/li&gt;&lt;li&gt;Latest &lt;strong&gt;Python&lt;/strong&gt; (yes, Python 3)&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Jupyter&lt;/strong&gt;&amp;nbsp;(aka IPython notebook)&lt;/li&gt;&lt;li&gt;Disable all the autocomplete quotes and brackets stuff, that comes by default with Jupyter&lt;/li&gt;&lt;li&gt;Set the IPython backend for matplotlib&lt;/li&gt;
&lt;div&gt;So, we download Anaconda from:&amp;nbsp;https://www.continuum.io/downloads (Linux 64 bits, Python 3, in my case). We install it by:&lt;/div&gt;&lt;div&gt;
&lt;/div&gt;&lt;blockquote class="tr_bq"&gt;bash&amp;nbsp;Anaconda3-2.4.1-Linux-x86_64.sh&lt;/blockquote&gt;&lt;div&gt;
&lt;/div&gt;&lt;div&gt;We can either restart the terminal, or type the next command, so we start using conda environment:&lt;/div&gt;&lt;div&gt;
&lt;/div&gt;&lt;blockquote class="tr_bq"&gt;. ~/.bashrc&lt;/blockquote&gt;&lt;div&gt;
&lt;/div&gt;&lt;div&gt;We can update conda and all packages:&lt;/div&gt;&lt;div&gt;
&lt;/div&gt;&lt;blockquote class="tr_bq"&gt;conda update conda &amp;amp;&amp;amp; conda update --all&lt;/blockquote&gt;&lt;div&gt;
&lt;/div&gt;&lt;div&gt;Then we create a new conda environment (this way we can change package versions without affecting the main conda packages). We name it myenv and specify the packages we want (numpy, pandas...).&lt;/div&gt;&lt;div&gt;
&lt;/div&gt;&lt;blockquote class="tr_bq"&gt;conda create --name myenv jupyter numpy scipy pandas matplotlib scikit-learn bokeh&lt;/blockquote&gt;&lt;div&gt;
&lt;/div&gt;&lt;div&gt;We activate the new environment:&lt;/div&gt;&lt;div&gt;
&lt;/div&gt;&lt;blockquote class="tr_bq"&gt;source activate myenv&lt;/blockquote&gt;&lt;div&gt;
&lt;/div&gt;&lt;div&gt;Now we have everything we wanted installed, let's change the configuration.&lt;/div&gt;&lt;div&gt;
&lt;/div&gt;&lt;div&gt;We start by creating a default ipython profile.&lt;/div&gt;&lt;div&gt;
&lt;/div&gt;&lt;blockquote class="tr_bq"&gt;ipython profile create&lt;/blockquote&gt;&lt;div&gt;
&lt;/div&gt;&lt;div&gt;Then we edit the file ~/.ipython/profile_default/ipython_kernel_config.py and we add the next lines to make matplotlib display the images with the inline backend, and with a decent size:&lt;/div&gt;&lt;div&gt;
&lt;/div&gt;&lt;blockquote class="tr_bq"&gt;c.InteractiveShellApp.matplotlib = 'inline' c.InlineBackend.rc = {'font.size': 10, 'figure.figsize': (18., 9.), 'figure.facecolor': 'white', 'savefig.dpi': 72, 'figure.subplot.bottom': 0.125, 'figure.edgecolor': 'white'} &lt;/blockquote&gt;
&lt;div&gt;
&lt;/div&gt;&lt;div&gt;To disable autoclosing brackets, run in a notebook:&lt;/div&gt;&lt;div&gt;
&lt;/div&gt;&lt;pre style="background-color: #f6f8fa; border-radius: 3px; box-sizing: border-box; color: #24292e; font-family: SFMono-Regular, Consolas, &amp;quot;Liberation Mono&amp;quot;, Menlo, Courier, monospace; font-size: 11.9px; font-stretch: normal; line-height: 1.45; overflow: auto; padding: 16px; word-break: normal; word-wrap: normal;"&gt;&lt;span class="pl-k" style="box-sizing: border-box; color: #d73a49;"&gt;from&lt;/span&gt; notebook.services.config &lt;span class="pl-k" style="box-sizing: border-box; color: #d73a49;"&gt;import&lt;/span&gt; ConfigManager
c &lt;span class="pl-k" style="box-sizing: border-box; color: #d73a49;"&gt;=&lt;/span&gt; ConfigManager()
c.update(&lt;span class="pl-s" style="box-sizing: border-box; color: #032f62;"&gt;&lt;span class="pl-pds" style="box-sizing: border-box;"&gt;'&lt;/span&gt;notebook&lt;span class="pl-pds" style="box-sizing: border-box;"&gt;'&lt;/span&gt;&lt;/span&gt;, {&lt;span class="pl-s" style="box-sizing: border-box; color: #032f62;"&gt;&lt;span class="pl-pds" style="box-sizing: border-box;"&gt;"&lt;/span&gt;CodeCell&lt;span class="pl-pds" style="box-sizing: border-box;"&gt;"&lt;/span&gt;&lt;/span&gt;: {&lt;span class="pl-s" style="box-sizing: border-box; color: #032f62;"&gt;&lt;span class="pl-pds" style="box-sizing: border-box;"&gt;"&lt;/span&gt;cm_config&lt;span class="pl-pds" style="box-sizing: border-box;"&gt;"&lt;/span&gt;&lt;/span&gt;: {&lt;span class="pl-s" style="box-sizing: border-box; color: #032f62;"&gt;&lt;span class="pl-pds" style="box-sizing: border-box;"&gt;"&lt;/span&gt;autoCloseBrackets&lt;span class="pl-pds" style="box-sizing: border-box;"&gt;"&lt;/span&gt;&lt;/span&gt;: &lt;span class="pl-c1" style="box-sizing: border-box; color: #005cc5;"&gt;False&lt;/span&gt;}}})&lt;/pre&gt;
&lt;div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;</content><category term="Python"></category><category term="Data Mining"></category></entry><entry><title>Google Earth on Fedora</title><link href="https://datapythonista.github.io/blog/google-earth-on-fedora-21.html" rel="alternate"></link><published>2015-01-19T01:58:00+00:00</published><updated>2015-01-19T01:58:00+00:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2015-01-19:/blog/google-earth-on-fedora-21.html</id><summary type="html">&lt;p&gt;Installing Google Earth in Fedora is trickier than it should. Here is a short HOWTO:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;li&gt;Download 64bits Fedora version from &lt;a href="https://www.google.com/earth/download/ge/agree.html"&gt;Google Earth site&lt;/a&gt;&lt;/li&gt;&lt;li&gt;sudo yum install google-earth-stable_current_x86_64.rpm&lt;/li&gt;&lt;li&gt;OOOPS!!! You got &lt;strong&gt;file /usr/bin from install of google-earth-stable-7.1.2.2041-0.x86_64 conflicts with file from package filesystem-3.2-28.fc21 …&lt;/strong&gt;&lt;/li&gt;&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;p&gt;Installing Google Earth in Fedora is trickier than it should. Here is a short HOWTO:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;li&gt;Download 64bits Fedora version from &lt;a href="https://www.google.com/earth/download/ge/agree.html"&gt;Google Earth site&lt;/a&gt;&lt;/li&gt;&lt;li&gt;sudo yum install google-earth-stable_current_x86_64.rpm&lt;/li&gt;&lt;li&gt;OOOPS!!! You got &lt;strong&gt;file /usr/bin from install of google-earth-stable-7.1.2.2041-0.x86_64 conflicts with file from package filesystem-3.2-28.fc21.x86_64&lt;/strong&gt;&lt;/li&gt;
  &lt;p&gt;rpm has an error, we need to fix it. We'll rebuild the rpm fixing the error with &lt;strong&gt;rpmrebuild&lt;/strong&gt;&lt;/p&gt; - &lt;li&gt;sudo yum install rpmrebuild&lt;/li&gt;&lt;li&gt;rpmrebuild -ep google-earth-stable_current_x86_64.rpm&lt;/li&gt;&lt;li&gt;A text editor with the spec file (rpm configuration file) is opened, you need to delete the line &lt;strong&gt;%dir %attr(0755, root, root) "/usr/bin"&lt;/strong&gt;&lt;/li&gt;&lt;li&gt;rpmrebuild will ask for confirmation and inform about the path of the generated rpm, just install it&lt;/li&gt;&lt;li&gt;sudo yum localinstall ~/rpmbuild/RPMS/x86_64/google-earth-stable-7.1.2.2041-0.x86_64.rpm&lt;/li&gt;
 &lt;p&gt;Now, the application is succesfully installed, but sometimes crashes when started. It looks like the best to it is to install the 32 bits verion, or Google Earth 6 (latest is 7 at the time of writing this post). Unless you need any specific feature from version 7 I recommend installing version 6 rather than the 32 bits version of 7. The latter requires many dependencies, and it's still buggy on Fedora.&lt;/p&gt;  &lt;p&gt;More info:&lt;/p&gt;- &lt;li&gt;&lt;a href="https://code.google.com/p/earth-issues/issues/detail?id=1525"&gt;https://code.google.com/p/earth-issues/issues/detail?id=1525&lt;/a&gt;&lt;/li&gt;&lt;/li&gt;
&lt;/ul&gt;</content></entry><entry><title>Skype on Fedora 21</title><link href="https://datapythonista.github.io/blog/skype-on-fedora-21.html" rel="alternate"></link><published>2015-01-18T19:33:00+00:00</published><updated>2015-01-18T19:33:00+00:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2015-01-18:/blog/skype-on-fedora-21.html</id><content type="html">&lt;p&gt;Here there is a blog post on how to install Skype on Fedora 21 by quickly creating an RPM package.&lt;/p&gt;

&lt;p&gt;&lt;p&gt;&lt;a href="http://mariuszs.github.io/blog/2014/skype_for_fedora_21.html"&gt;http://mariuszs.github.io/blog/2014/skype_for_fedora_21.html&lt;/a&gt;&lt;/p&gt; &lt;p&gt;It's also a great simplified tutorial on how to build any RPM.&lt;/p&gt;&lt;/p&gt;</content></entry><entry><title>LATEX awesomeness</title><link href="https://datapythonista.github.io/blog/latex-awesomeness.html" rel="alternate"></link><published>2014-12-02T03:39:00+00:00</published><updated>2014-12-02T03:39:00+00:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2014-12-02:/blog/latex-awesomeness.html</id><summary type="html">&lt;p&gt;I think LATEX is simply amazing by itself. More when writing an academic document, but for any kind of doc, using LATEX is really time and pain saving.&lt;/p&gt;
&lt;p&gt;The concept of creating a document class (defining all the styles of the document), and then simply forgetting on formats, and focusing …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I think LATEX is simply amazing by itself. More when writing an academic document, but for any kind of doc, using LATEX is really time and pain saving.&lt;/p&gt;
&lt;p&gt;The concept of creating a document class (defining all the styles of the document), and then simply forgetting on formats, and focusing on content is just amazing. Also the automatic management of references (bibliography), the automatic management of figure and table labels, and and the automatic creation of the table of contents. Not to mention how nice is creating formulas.&lt;/p&gt;
&lt;p&gt;But besides LATEX itself, what I found really cool is &lt;a href="http://www.sharelatex.com/"&gt;www.sharelatex.com&lt;/a&gt;. I've been using it for a while, and after discovering some new features (new for me, not sure how long they've been there), I found it was the perfect editor for LATEX.&lt;/p&gt;
&lt;p&gt;First advantage is the cloud usual stuff, no local installation needed, backups are managed by the service provider, accessible from different devices...&lt;/p&gt;
&lt;p&gt;But there are some other specific to the site:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;li&gt;Collaborative environment: see what others are writing in real time, conflict avoidance, always up-to-date, and even author chat&lt;/li&gt;&lt;li&gt;Version control system: Don't loose any version, history of changes is kept.&lt;/li&gt;&lt;li&gt;Ownership of your project: download a zip of all your files, sync to Dropbox, and also to Github (beta).&lt;/li&gt;&lt;li&gt;Extra features:&lt;/li&gt;&lt;ul&gt;&lt;li&gt;Spell check&lt;/li&gt;&lt;li&gt;Autocomplete&lt;/li&gt;&lt;li&gt;And last but not least: VIM keybindings!!!&lt;/li&gt;
&lt;/ul&gt;&lt;div&gt;Few of the features are for premium accounts only (+10 collaborators, Dropbox sync, full history access), but the free plan I'm using is exactly what I need so far.&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;</content></entry><entry><title>Brother printer on GNU/Linux</title><link href="https://datapythonista.github.io/blog/brother-stupid-printer-on-gnulinux.html" rel="alternate"></link><published>2012-07-10T16:58:00+01:00</published><updated>2012-07-10T16:58:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2012-07-10:/blog/brother-stupid-printer-on-gnulinux.html</id><summary type="html">&lt;p&gt;For some reason, brother printers (at least mine) do not take into account the settings specified for the printer in the regular way (Gnome settings in my case).&lt;/p&gt;
&lt;p&gt;But&amp;nbsp;mysteriously, there is a command which can be used to change them properly (&lt;span style="background-color: white;"&gt;brprintconf_mfc235c)&lt;/span&gt;&lt;span style="background-color: white;"&gt;. In my case, I was having problems …&lt;/span&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;For some reason, brother printers (at least mine) do not take into account the settings specified for the printer in the regular way (Gnome settings in my case).&lt;/p&gt;
&lt;p&gt;But&amp;nbsp;mysteriously, there is a command which can be used to change them properly (&lt;span style="background-color: white;"&gt;brprintconf_mfc235c)&lt;/span&gt;&lt;span style="background-color: white;"&gt;. In my case, I was having problems with top margin, and top of pages was not printed. Apparently it was because of page type, so I could fix it by:&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sudo brprintconf_mfc235c -pt A4 &lt;/code&gt;&lt;/p&gt;</content></entry><entry><title>Fixing Gnome 3 design mistakes</title><link href="https://datapythonista.github.io/blog/how-to-make-gnome-3-suck-less.html" rel="alternate"></link><published>2012-04-27T20:10:00+01:00</published><updated>2012-04-27T20:10:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2012-04-27:/blog/how-to-make-gnome-3-suck-less.html</id><summary type="html">&lt;p&gt;While there are some cool things in Gnome 3, I think mostly everyone will agree that there are many design mistakes. To me, it looks like a bad copy of the Mac desktop, and it's specially annoying that they also brought the "let Steve Jobs decide it for you" philosophy …&lt;/p&gt;</summary><content type="html">&lt;p&gt;While there are some cool things in Gnome 3, I think mostly everyone will agree that there are many design mistakes. To me, it looks like a bad copy of the Mac desktop, and it's specially annoying that they also brought the "let Steve Jobs decide it for you" philosophy to GNU. I don't really know who is leading the project, but looks like they should send a resume to Apple.&lt;/p&gt;
&lt;p&gt;Anyway, the reason for this post is that I realized that I'm not alone. And I realized in a strange way... Basically, it looks to be a consensus on which are the parts of Gnome 3 which suck more, and I arrived to this conclusion after seeing that there is a Fedora package to remove almost every non-sense feature Gnome brings.&lt;/p&gt;
&lt;p&gt;These include (among others):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;li&gt;Accessibility icon always on the bar&lt;/li&gt;&lt;li&gt;Alt-tab bothering system of grouping windows&lt;/li&gt;&lt;li&gt;Power off option not hidden by secret methods&lt;/li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I'm not a genius, so I don't usually share my opinions in Linus Torvalds style, but I think it's totally worth in this case.&lt;/p&gt;
&lt;p&gt;So, if you're using Gnome 3, you should probably check this link out:&lt;/p&gt;
&lt;p&gt;&lt;a href="http://fedoraproject.org/wiki/Features/GnomeShellConfigurability"&gt;http://fedoraproject.org/wiki/Features/GnomeShellConfigurability&lt;/a&gt;&lt;/p&gt;</content></entry><entry><title>Create user and database in Postgres</title><link href="https://datapythonista.github.io/blog/create-user-and-database-in-postgres.html" rel="alternate"></link><published>2011-06-27T13:00:00+01:00</published><updated>2011-06-27T13:00:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2011-06-27:/blog/create-user-and-database-in-postgres.html</id><summary type="html">&lt;p&gt;While I love Postgres, I get some problems every time I want to do the simple operation of creating a database with an associated user if it's been a while since the last time I did it.&lt;/p&gt;
&lt;p&gt;There are several posts on the Internet about Postgres authentication, but I couldn't …&lt;/p&gt;</summary><content type="html">&lt;p&gt;While I love Postgres, I get some problems every time I want to do the simple operation of creating a database with an associated user if it's been a while since the last time I did it.&lt;/p&gt;
&lt;p&gt;There are several posts on the Internet about Postgres authentication, but I couldn't find any explaining exactly what I wanted to know, so here is mine.&lt;/p&gt;
&lt;p&gt;This has been tested on &lt;strong&gt;Debian 6&lt;/strong&gt; and &lt;strong&gt;PostgreSQL 8.4&lt;/strong&gt;.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Install the PostgreSQL server (obvious)&lt;/li&gt;
&lt;li&gt;Create the user:
&lt;code&gt;
$ sudo -u postgres createuser -D -A -P &lt;my-user&gt;
&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Create the database
&lt;code&gt;
$ sudo -u postgres createdb -O &lt;my-user&gt; &lt;my-database&gt;
&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Edit /etc/postgresql/8.4/main/pg_hba.conf
&lt;code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h1&gt;Put your actual configuration here&lt;/h1&gt;
&lt;p&gt;local   all         all         password
host    all         all         127.0.0.1/32          password
&lt;/code&gt;
&lt;strong&gt;NOTE:&lt;/strong&gt; Make sure that your settings are placed after the comment saying where your configurations go. If you place them at the end, the default ones will be used, and you'll see this error when logging in:
&lt;code&gt;
psql: FATAL:  Ident authentication failed for user "&lt;my-user&gt;"
&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Actually, you'll probably want to customize the settings you want to use. My settings allow logging in from localhost using unencrypted password, but may be you want to access from another host, only grant access to some users or some databases, or use another authentication methods, so I would recommend you reading the &lt;a href="http://developer.postgresql.org/pgdocs/postgres/auth-pg-hba-conf.html"&gt;pg_hda.conf reference&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Finally, you'll be able to access by:
&lt;code&gt;
$ psql -U &lt;my-user&gt; -W
&lt;/code&gt;&lt;/p&gt;</content></entry><entry><title>Unified Python</title><link href="https://datapythonista.github.io/blog/unified-python.html" rel="alternate"></link><published>2011-06-25T01:19:00+01:00</published><updated>2011-06-25T01:19:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2011-06-25:/blog/unified-python.html</id><summary type="html">&lt;p&gt;After all these days at EuroPython, there is a thought that keep me thinking. It is about how Python have different ways to represent what it could be considered the same thing.&lt;/p&gt;
&lt;p&gt;On today's talk, Alex Martelli pointed out that "def" and "lambda" are actually the same concept. This was …&lt;/p&gt;</summary><content type="html">&lt;p&gt;After all these days at EuroPython, there is a thought that keep me thinking. It is about how Python have different ways to represent what it could be considered the same thing.&lt;/p&gt;
&lt;p&gt;On today's talk, Alex Martelli pointed out that "def" and "lambda" are actually the same concept. This was part of a more complete idea about that both of them have the wrong name ("function" should be the right), and that lambda actually should disappear, but that's another question.&lt;/p&gt;
&lt;p&gt;Also, yesterday, Raymond Hettinger reminded that class are actually dictionaries, something that most Pythonistas know, but which also made me thought.&lt;/p&gt;
&lt;p&gt;Then, there is something that I never saw very clearly, and it is the subtle difference between an instance and a dictionary, and how trivial it can be in some case, the difference between person['name'] and person.name.&lt;/p&gt;
&lt;p&gt;So, I wanted to do an experiment on how it could look Python, if it would try to merge all this entities in ones single format, and even some other things like avoiding assignments that doesn't follow the assignment pattern (I mean class or function definition here, where instead of &lt;em&gt;my_func = [...]&lt;/em&gt; it's used &lt;em&gt;def my_func[...]&lt;/em&gt;).&lt;/p&gt;
&lt;p&gt;Next, there is how the most stupid example I could invent looks like, but first some definitions to make it easier to understand the idea.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;map&lt;/strong&gt;: could be also "class", "dict", "obj", "hash",... and it's the structure for dictionaries, classes and instances.
&lt;strong&gt;seq&lt;/strong&gt;: a list or tuple, any linear sequence of values.
&lt;strong&gt;func&lt;/strong&gt;: a function or callable, that in Python is defined by "def" or "lambda".&lt;/p&gt;
&lt;p&gt;&lt;code&gt;
foods = seq:
    "meat"
    "milk"
    "bread"&lt;/p&gt;
&lt;p&gt;sounds = map:
    "bark" = "woof woof"
    "mew" = "meow meow"&lt;/p&gt;
&lt;p&gt;animal = map:
    "step_size" = None
    "sound" = None&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="ss"&gt;&amp;quot;move&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;func&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_steps&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="ss"&gt;&amp;quot;I&amp;#39;ve moved {} units&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_steps&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="k"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;step_size&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="ss"&gt;&amp;quot;talk&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;func&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sounds&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="k"&gt;self&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sound&lt;/span&gt;&lt;span class="err"&gt;}&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="ss"&gt;&amp;quot;eat&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;func&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;food&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="ss"&gt;&amp;quot;I&amp;#39;m eating {}&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;food&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;cat = map(animal):
    "step_size" = 80
    "sound" = "mew"&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;eat&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;func&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;self&lt;/span&gt;, &lt;span class="nv"&gt;food&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;:
    &lt;span class="nv"&gt;print&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;I only eat {} if I want to&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;.&lt;span class="nv"&gt;format&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;food&lt;/span&gt;&lt;span class="ss"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;azrael = map(cat):
    "owner_name" = "Gargamel"&lt;/p&gt;
&lt;p&gt;azrael.move(5)
for food in foods:
    azrael.eat(food)
&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Of course, there are too many things that should be considered before being able to implement this syntax, but can give an idea on how it could look a more &lt;em&gt;unified&lt;/em&gt; approach of Python syntax.&lt;/p&gt;
&lt;p&gt;See how the syntax for "sounds", which would be a dictionary, "cat", which would be a class, and "azrael", which would be a instance, is exactly the same.&lt;/p&gt;
&lt;p&gt;Being used to Python syntax, it's difficult to say if this syntax could be readable, so far I just find it weird. But what looks clear, is that this syntax would make the language simpler, from the implementation point of view, and probably from the programmer point of view, who would probably need to forget some OP concepts first.&lt;/p&gt;
&lt;p&gt;Whatever is the conclusion the reader can get from this example, I think it's quite interesting seeing how a class can look exactly the same way as a dictionary, and how an instance can look exactly as a subclass of the base class.&lt;/p&gt;</content><category term="Python"></category></entry><entry><title>Building RPMs for Python3.1</title><link href="https://datapythonista.github.io/blog/building-rpms-for-python31.html" rel="alternate"></link><published>2011-06-11T20:48:00+01:00</published><updated>2011-06-11T20:48:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2011-06-11:/blog/building-rpms-for-python31.html</id><summary type="html">&lt;p&gt;While it's been a long time since the first stable version Python 3 was released, it's not yet available on several operating systems. Looking for a repository with Python 3 rpms, I found &lt;a href="http://iuscommunity.org/Repos"&gt;IUS Community&lt;/a&gt;, but I had some problems with it, and I thought on building my own rpms …&lt;/p&gt;</summary><content type="html">&lt;p&gt;While it's been a long time since the first stable version Python 3 was released, it's not yet available on several operating systems. Looking for a repository with Python 3 rpms, I found &lt;a href="http://iuscommunity.org/Repos"&gt;IUS Community&lt;/a&gt;, but I had some problems with it, and I thought on building my own rpms.&lt;/p&gt;
&lt;p&gt;The process for building an rpm from a source tarball is pretty easy (if you know the steps). The only problem in this case, is that the .spec file delivered with Python is not updated, so the process fails.&lt;/p&gt;
&lt;p&gt;I did required changes to the .spec file, and I uploaded it to: &lt;a href="http://files.vaig.be/python-3.1.spec"&gt;http://files.vaig.be/python-3.1.spec&lt;/a&gt; (NOTE, that is necessary to edit the exact version of Python you're building in line 37. Version in uploaded file is 3.1.3, but it could be changes to 3.1.3, 3.1.4rc1,...).&lt;/p&gt;
&lt;p&gt;Next, you can find the steps for creating a RPM package for Python 3.1 on a CentOS 5 (using my custom .spec file):&lt;/p&gt;
&lt;p&gt;&lt;code&gt;&lt;/p&gt;
&lt;h1&gt;Install required software&lt;/h1&gt;
&lt;p&gt;yum install rpm-build gcc expat-devel db4-devel gdbm-devel sqlite-devel ncurses-devel readline-devel zlib-devel openssl-devel&lt;/p&gt;
&lt;h1&gt;Download Python source&lt;/h1&gt;
&lt;p&gt;cd /usr/src/redhat/SOURCES/
wget http://www.python.org/ftp/python/3.1.3/Python-3.1.3.tar.bz2&lt;/p&gt;
&lt;h1&gt;Download .spec (rpm specifications file)&lt;/h1&gt;
&lt;p&gt;cd /usr/src/redhat/SPECS/
wget http://files.vaig.be/python-3.1.spec&lt;/p&gt;
&lt;h1&gt;Generate RPMs (and SRPMs)&lt;/h1&gt;
&lt;p&gt;rpmbuild -ba /usr/src/redhat/SPECS/python-3.1.spec
&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Compiling Python and creating the RPM will take a while, but after this process, you'll have the RPMs at:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;
/usr/src/redhat/SRPMS/python3.1-3.1.3-1pydotorg.src.rpm
/usr/src/redhat/RPMS/&lt;YOUR-ARCH&gt;/python3.1-3.1.3-1pydotorg.i386.rpm
/usr/src/redhat/RPMS/&lt;YOUR-ARCH&gt;/python3.1-devel-3.1.3-1pydotorg.i386.rpm
/usr/src/redhat/RPMS/&lt;YOUR-ARCH&gt;/python3.1-tools-3.1.3-1pydotorg.i386.rpm
&lt;/code&gt;&lt;/p&gt;</content><category term="Python"></category></entry><entry><title>Joel test for software companies</title><link href="https://datapythonista.github.io/blog/joel-test-for-software-companies.html" rel="alternate"></link><published>2010-12-26T14:35:00+00:00</published><updated>2010-12-26T14:35:00+00:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2010-12-26:/blog/joel-test-for-software-companies.html</id><summary type="html">&lt;div&gt;&lt;blockquote&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;/blockquote&gt;Today I discovered Joel test, a test to evaluate software companies. While the article is pretty out-of-date, and there are some points that are exclusively for companies working on compiled programming languages, the article is still very interesting.&lt;/div&gt;

&lt;div&gt;
&lt;/div&gt;

&lt;div&gt;I think every software company should took the test. Also I think …&lt;/div&gt;</summary><content type="html">&lt;div&gt;&lt;blockquote&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;/blockquote&gt;Today I discovered Joel test, a test to evaluate software companies. While the article is pretty out-of-date, and there are some points that are exclusively for companies working on compiled programming languages, the article is still very interesting.&lt;/div&gt;

&lt;div&gt;
&lt;/div&gt;

&lt;div&gt;I think every software company should took the test. Also I think it can be useful for programmers, to evaluate if a company is a good place to work.&lt;/div&gt;

&lt;div&gt;
&lt;/div&gt;

&lt;div&gt;The original article is at:&lt;/div&gt;

&lt;p&gt;&lt;a href="http://www.joelonsoftware.com/articles/fog0000000043.html"&gt;http://www.joelonsoftware.com/articles/fog0000000043.html&lt;/a&gt;&lt;/p&gt;
&lt;div&gt;Let me provide a summary of original questions here:&lt;/div&gt;

&lt;div&gt;&lt;blockquote&gt;&lt;/blockquote&gt;- &lt;li&gt;Do you use source control?&lt;/li&gt;&lt;li&gt;Can you make a build in one step?&lt;/li&gt;&lt;li&gt;Do you make daily builds?&lt;/li&gt;&lt;li&gt;Do you have a bug database?&lt;/li&gt;&lt;li&gt;Do you fix bugs before writing new code?&lt;/li&gt;&lt;li&gt;Do you have an up-to-date schedule?&lt;/li&gt;&lt;li&gt;Do you have a spec?&lt;/li&gt;&lt;li&gt;Do programmers have a quiet working conditions?&lt;/li&gt;&lt;li&gt;Do you use the best tools money can buy?&lt;/li&gt;&lt;li&gt;Do you have testers?&lt;/li&gt;&lt;li&gt;Do new candidates write code during their interview?&lt;/li&gt;&lt;li&gt;Do you do hallway usability testing?&lt;/li&gt;
&lt;/div&gt;

&lt;div&gt;My personal update to the questions would be:&lt;/div&gt;

&lt;div&gt;- &lt;li&gt;Do you use a distributed source control system?&lt;/li&gt;&lt;li&gt;Do you use a bug database where users can report bugs directly?&lt;/li&gt;&lt;li&gt;Do you have a testing protocol, and specific resources for testing?&lt;/li&gt;&lt;li&gt;Do you fix bugs before implementing new features?&lt;/li&gt;&lt;li&gt;Do you have automated build or deployment procedures?&lt;/li&gt;&lt;li&gt;Do you have a roadmap, and you don't make important changes to the short term priorities?&lt;/li&gt;&lt;li&gt;Does your team work in good conditions (quiet environment, flexible schedule, freedom to choose development software, fair paycheck...)&lt;/li&gt;
&lt;div&gt;I think those questions can give you an idea on how efficient your company is, and indirectly, about the quality of your software.&lt;/div&gt;&lt;/div&gt;</content></entry><entry><title>Branching with Mercurial</title><link href="https://datapythonista.github.io/blog/branching-with-mercurial.html" rel="alternate"></link><published>2010-12-25T08:53:00+00:00</published><updated>2010-12-25T08:53:00+00:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2010-12-25:/blog/branching-with-mercurial.html</id><summary type="html">&lt;p&gt;This is a simple guide on how to do simple branching operations in Mercurial.&lt;/p&gt;
&lt;p&gt;First of all, let's comment the two different options for branching on Mercurial, and in most distributes source control systems.&lt;/p&gt;
&lt;p&gt;First option is to create a clone of the original repository to create a branch. This …&lt;/p&gt;</summary><content type="html">&lt;p&gt;This is a simple guide on how to do simple branching operations in Mercurial.&lt;/p&gt;
&lt;p&gt;First of all, let's comment the two different options for branching on Mercurial, and in most distributes source control systems.&lt;/p&gt;
&lt;p&gt;First option is to create a clone of the original repository to create a branch. This option can be simpler for the user, which has different directories for every branch, and there are not special operations to switch from one branch to another. Another advantage is that branches can be safely switched when some changes are not yet commited, as every branch is in a different directory.&lt;/p&gt;
&lt;p&gt;The second option would be to use Mercurial branching commands, and to keep all branches in the same repository. The main advantage of doing this, is that branches can be distributed when using push and pull operations. This is very important, if different programmers need to work with different branches, or if you want to replicate all branches when synchronizing your code with for example &lt;a href="http://code.google.com/"&gt;Google code&lt;/a&gt; or &lt;a href="https://bitbucket.org/"&gt;Bitbucket&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This second options is the one I'll cover in this simple guide.&lt;/p&gt;
&lt;p&gt;Imagine we have a started repository, with some code, and we never used branching before.&lt;/p&gt;
&lt;p&gt;If we perform:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;&lt;/p&gt;
&lt;h1&gt;hg branches&lt;/h1&gt;
&lt;p&gt;default                       69:3f5490390a0b
&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;we can see that we already have a branch named default, that is the one that has all our changesets and code.&lt;/p&gt;
&lt;p&gt;Now we want to start working on a new version of our application, but we want to be able to do bugfixing to the application we already deployed. We can do it, creating a new branch on our repository.&lt;/p&gt;
&lt;p&gt;Look at this example that creates a new branch named newversion, and we create a new file named newfile on it.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;&lt;/p&gt;
&lt;h1&gt;hg branch newversion&lt;/h1&gt;
&lt;h1&gt;touch newfile&lt;/h1&gt;
&lt;h1&gt;hg add newfile&lt;/h1&gt;
&lt;h1&gt;hg commit -m "commit on the new branch newversion"&lt;/h1&gt;
&lt;p&gt;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;After this, if we check for the branches again, we'll have this:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;&lt;/p&gt;
&lt;h1&gt;hg branches&lt;/h1&gt;
&lt;p&gt;newversion                    70:720062b481d7
default                       69:3f5490390a0b (inactive)
&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;After working on the new branch, we find a bug on the deployed version, and we want to fix it on the version that is deployed. So we have to switch to the default branch to see the content of this branch in our repository directory. We can get it by simply typing:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;&lt;/p&gt;
&lt;h1&gt;hg update default&lt;/h1&gt;
&lt;h1&gt;&amp;gt; bugfixedfile&lt;/h1&gt;
&lt;h1&gt;hg add bugfixedfile&lt;/h1&gt;
&lt;h1&gt;hg commit -m "bug fixed in default branch"&lt;/h1&gt;
&lt;p&gt;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;NOTE, that we shouldn't have files that are not under the control version system, and that are specific to a branch in the code, as Mercurial will keep those files on the new branch after switching. We can use the option -C if the files are temporary and we want to clear them.&lt;/p&gt;
&lt;p&gt;To know the current branch, we can use branch command with no parameters:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;&lt;/p&gt;
&lt;h1&gt;hg branch&lt;/h1&gt;
&lt;p&gt;default
&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;After fixing the bug in the default branch, we'll probably want to fix it in the new version too, so we'll proceed by:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;&lt;/p&gt;
&lt;h1&gt;hg update newversion&lt;/h1&gt;
&lt;h1&gt;hg merge default&lt;/h1&gt;
&lt;h1&gt;hg commit -m "merged from branch default"&lt;/h1&gt;
&lt;p&gt;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;After the new version is ready to be deployed, we'll probably want to merge it back to default, so default will go on being the deployed version. It's recommended to have all changes to the default branch merged to the new version branch, before merging it back to default.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;&lt;/p&gt;
&lt;h1&gt;hg update newversion&lt;/h1&gt;
&lt;h1&gt;hg merge default&lt;/h1&gt;
&lt;h1&gt;hg commit -m "merged from branch default"&lt;/h1&gt;
&lt;h1&gt;hg update default&lt;/h1&gt;
&lt;h1&gt;hg merge newversion&lt;/h1&gt;
&lt;h1&gt;hg commit -m "merged branch newversion into default"&lt;/h1&gt;
&lt;p&gt;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Finally, the last thing we would want to do is to close the branch where we developed the new version, as further changes to this version will be made to the default branch. It's as simple as:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;&lt;/p&gt;
&lt;h1&gt;hg update newversion&lt;/h1&gt;
&lt;h1&gt;hg commit --close-branch -m "closing branch newversion after being merged to default"&lt;/h1&gt;
&lt;p&gt;&lt;/code&gt;&lt;/p&gt;</content></entry><entry><title>Two simple steps to reduce bandwidth on static files</title><link href="https://datapythonista.github.io/blog/two-simple-steps-to-reduce-bandwidth-on.html" rel="alternate"></link><published>2010-12-05T03:41:00+00:00</published><updated>2010-12-05T03:41:00+00:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2010-12-05:/blog/two-simple-steps-to-reduce-bandwidth-on.html</id><summary type="html">&lt;p&gt;First step is to let Google host your JavaScript library of choice for you. Google Libraries API hosts JQuery, Mootools, Prototype... and you can directly link to them from your website.&lt;/p&gt;
&lt;p&gt;More info at:
&lt;a href="http://code.google.com/apis/libraries/devguide.html"&gt;http://code.google.com/apis/libraries/devguide.html&lt;/a&gt;&lt;/p&gt;
&lt;div&gt;Second step is to compress you CSS file …&lt;/div&gt;</summary><content type="html">&lt;p&gt;First step is to let Google host your JavaScript library of choice for you. Google Libraries API hosts JQuery, Mootools, Prototype... and you can directly link to them from your website.&lt;/p&gt;
&lt;p&gt;More info at:
&lt;a href="http://code.google.com/apis/libraries/devguide.html"&gt;http://code.google.com/apis/libraries/devguide.html&lt;/a&gt;&lt;/p&gt;
&lt;div&gt;Second step is to compress you CSS file (or files, but if you are gonna compress it to save bandwidth, probably you want to merge them in one for better performance). There are several websites which compress CSS files online, and for free. The one I found which works best is:
[http://www.lotterypost.com/css-compress.aspx](http://www.lotterypost.com/css-compress.aspx)&lt;/div&gt;</content><category term="Google App Engine"></category></entry><entry><title>Debugging with PDB and App Engine</title><link href="https://datapythonista.github.io/blog/debugging-with-pdb-and-app-engine.html" rel="alternate"></link><published>2010-12-04T23:48:00+00:00</published><updated>2010-12-04T23:48:00+00:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2010-12-04:/blog/debugging-with-pdb-and-app-engine.html</id><summary type="html">&lt;p&gt;Python debugger (pdb) doesn't work on App Engine SDK as usual. After adding to my project:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;
import pdb; pdb.set_trace()
&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;I got:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;
Blocking access to skipped file "&lt;my_path&gt;/.pdbrc"&lt;/p&gt;
&lt;p&gt;File "/usr/lib/python2.6/bdb.py", line 46, in trace_dispatch
    return self.dispatch_line(frame)
File "/usr/lib/python2.6/bdb.py …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Python debugger (pdb) doesn't work on App Engine SDK as usual. After adding to my project:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;
import pdb; pdb.set_trace()
&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;I got:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;
Blocking access to skipped file "&lt;my_path&gt;/.pdbrc"&lt;/p&gt;
&lt;p&gt;File "/usr/lib/python2.6/bdb.py", line 46, in trace_dispatch
    return self.dispatch_line(frame)
File "/usr/lib/python2.6/bdb.py", line 65, in dispatch_line
    if self.quitting: raise BdbQuit
&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;But, as posted in &lt;a href="http://morethanseven.net/2009/02/07/pdb-and-appengine.html"&gt;morethanseven&lt;/a&gt;, it's easy to make it work using:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;
import pdb 
import sys 
for attr in ('stdin', 'stdout', 'stderr'):
    setattr(sys, attr, getattr(sys, '&lt;strong&gt;%s&lt;/strong&gt;' % attr))
pdb.set_trace()
&lt;/code&gt;&lt;/p&gt;</content><category term="Google App Engine"></category></entry><entry><title>Linux and Debian simple boot</title><link href="https://datapythonista.github.io/blog/linux-and-debian-simple-boot.html" rel="alternate"></link><published>2010-01-01T20:46:00+00:00</published><updated>2010-01-01T20:46:00+00:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2010-01-01:/blog/linux-and-debian-simple-boot.html</id><summary type="html">&lt;div&gt;Today I've been researching on Linux and Debian booting.&lt;/div&gt;

&lt;div&gt;
&lt;/div&gt;

&lt;div&gt;There is an excellent article from IBM, which explains the procedure, and the involved parts:&lt;/div&gt;

&lt;div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;a href="http://www.ibm.com/developerworks/linux/library/l-linuxboot/"&gt;http://www.ibm.com/developerworks/linux/library/l-linuxboot/&lt;/a&gt;&lt;div&gt;
&lt;/div&gt;&lt;div&gt;Basically:&lt;/div&gt;&lt;div&gt;- &lt;li&gt;BIOS checks CMOS and choose the booting device&lt;/li&gt;&lt;li&gt;Control is given to device's MBR (physically first 512 …&lt;/li&gt;&lt;/div&gt;&lt;/p&gt;</summary><content type="html">&lt;div&gt;Today I've been researching on Linux and Debian booting.&lt;/div&gt;

&lt;div&gt;
&lt;/div&gt;

&lt;div&gt;There is an excellent article from IBM, which explains the procedure, and the involved parts:&lt;/div&gt;

&lt;div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;a href="http://www.ibm.com/developerworks/linux/library/l-linuxboot/"&gt;http://www.ibm.com/developerworks/linux/library/l-linuxboot/&lt;/a&gt;&lt;div&gt;
&lt;/div&gt;&lt;div&gt;Basically:&lt;/div&gt;&lt;div&gt;- &lt;li&gt;BIOS checks CMOS and choose the booting device&lt;/li&gt;&lt;li&gt;Control is given to device's MBR (physically first 512 bytes)&lt;/li&gt;&lt;li&gt;MBR checks for partitions on the device (in a self contained table), and gives control to bootable partition.&lt;/li&gt;&lt;li&gt;Then, Grub, LILO or whatever takes control, to load the kernel, and the file system.&lt;/li&gt;&lt;li&gt;Usually a &lt;a href="http://en.wikipedia.org/wiki/Initrd"&gt;initrd&lt;/a&gt; filesystem is loaded before the "real" one. This way, the kernel can access this filesystem, while the modules for loading the one in the root partition are not yet loaded.&lt;/li&gt;&lt;li&gt;Finally, init program is called, to load all &lt;a href="http://en.wikipedia.org/wiki/User_space"&gt;user-space&lt;/a&gt; applications.&lt;/li&gt;
&lt;div&gt;To set this up in a USB drive (my idea), in a simple way, we need:&lt;/div&gt;&lt;div&gt;
&lt;/div&gt;&lt;div&gt;Make the drive bootable, using the &lt;a href="http://en.wikipedia.org/wiki/Syslinux"&gt;syslinux&lt;/a&gt; tool, which is used for FAT filesystems:&lt;/div&gt;&lt;div&gt;syslinux /dev/sdb (or whatever device you want)&lt;/div&gt;&lt;div&gt;
&lt;/div&gt;&lt;div&gt;Then, mount the filesystem, and copy:&lt;/div&gt;&lt;div&gt;linux: the linux kernel binary&lt;/div&gt;&lt;div&gt;initrd.gz: compressed cpio file containing the initrd file tree&lt;/div&gt;&lt;div&gt;
&lt;/div&gt;&lt;div&gt;and&lt;/div&gt;&lt;div&gt;
&lt;/div&gt;&lt;div&gt;syslinux.cfg: syslinux settings, to let syslinux know where to find the kernel and the initrd. Basically:&lt;/div&gt;&lt;div&gt;
&lt;/div&gt;&lt;div&gt;default linux&lt;/div&gt;&lt;div&gt;append initrd=initrd.gz&lt;/div&gt;&lt;div&gt;
&lt;/div&gt;&lt;div&gt;Then, just restart, and your device will boot your kernel, and your filesystem.&lt;/div&gt;&lt;div&gt;
&lt;/div&gt;&lt;div&gt;Here, you can find a Linux kernel, and a initrd file, which will load a basic linux system, running the Debian installer:&lt;/div&gt;&lt;div&gt;
&lt;/div&gt;&lt;div&gt;&lt;a href="http://ftp.debian.org/debian/dists/stable/main/installer-i386/current/images/netboot/debian-installer/i386/"&gt;http://ftp.debian.org/debian/dists/stable/main/installer-i386/current/images/netboot/debian-installer/i386/&lt;/a&gt;&lt;/div&gt;&lt;div&gt;
&lt;/div&gt;&lt;div&gt;Some more info on it at:&lt;/div&gt;&lt;div&gt;
&lt;/div&gt;&lt;div&gt;&lt;a href="http://www.debian.org/releases/stable/i386/ch04s03.html.en"&gt;http://www.debian.org/releases/stable/i386/ch04s03.html.en&lt;/a&gt;&lt;/div&gt;&lt;div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/p&gt;</content><category term="Systems"></category><category term="IT"></category></entry><entry><title>New localization system already in trunk</title><link href="https://datapythonista.github.io/blog/new-localization-system-already-in.html" rel="alternate"></link><published>2009-12-22T22:52:00+00:00</published><updated>2009-12-22T22:52:00+00:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2009-12-22:/blog/new-localization-system-already-in.html</id><summary type="html">&lt;p&gt;Just few hours ago, Django's new localization system has been commited to trunk.&lt;div&gt;
&lt;/div&gt;&lt;div&gt;As some of you know, I did most of the work as my Google Summer of Code project, this year. Of course, together with &lt;a href="http://jannisleidel.com/"&gt;Jannis Leidel&lt;/a&gt;, who also did the final steps, including the commit.&lt;/div&gt;&lt;div&gt;
&lt;/div&gt;&lt;div&gt;Summarizing, with …&lt;/div&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;Just few hours ago, Django's new localization system has been commited to trunk.&lt;div&gt;
&lt;/div&gt;&lt;div&gt;As some of you know, I did most of the work as my Google Summer of Code project, this year. Of course, together with &lt;a href="http://jannisleidel.com/"&gt;Jannis Leidel&lt;/a&gt;, who also did the final steps, including the commit.&lt;/div&gt;&lt;div&gt;
&lt;/div&gt;&lt;div&gt;Summarizing, with this change Django will format all displayed data, according to user's current locale. For example, the calendar will display Sunday as the first day for users in the States, but Monday for users from most European countries. Also it'll format numbers and dates.&lt;/div&gt;&lt;div&gt;
&lt;/div&gt;&lt;div&gt;You can check the slides I presented at DjangoCon.&lt;/div&gt;&lt;div&gt;&lt;a href="http://docs.google.com/present/view?id=dfbzs3ks_16d26xjbd9"&gt;http://docs.google.com/present/view?id=dfbzs3ks_16d26xjbd9&lt;/a&gt;&lt;/div&gt;&lt;div&gt;
&lt;/div&gt;&lt;div&gt;Note that the setting is no longer USE_FORMAT_I18N (as in the slides), but USE_L10N.&lt;/div&gt;&lt;div&gt;
&lt;/div&gt;&lt;div&gt;You can also check the commit at:&lt;/div&gt;&lt;div&gt;&lt;a href="http://code.djangoproject.com/changeset/11964"&gt;http://code.djangoproject.com/changeset/11964&lt;/a&gt;&lt;/div&gt;&lt;div&gt;
&lt;/div&gt;&lt;div&gt;
&lt;/div&gt;&lt;/p&gt;</content><category term="Django"></category><category term="Django-i18n"></category></entry><entry><title>GSoC: Implementation of additional i18n features on Django</title><link href="https://datapythonista.github.io/blog/gsoc-implementation-of-additional-i18n.html" rel="alternate"></link><published>2009-04-24T19:09:00+01:00</published><updated>2009-04-24T19:09:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2009-04-24:/blog/gsoc-implementation-of-additional-i18n.html</id><summary type="html">&lt;p&gt;&lt;span&gt;&lt;span&gt;Here you have my proposal for Google Summer of Code &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;2009. It was approved previous week, and I'll be working on it during this summer.&lt;/span&gt;&lt;/span&gt;&lt;span style="font-size:180%;"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;
&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;The problem
&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;While Django provides an amazing system to translate texts, and displays localized dates in some parts of the admin; it has many data …&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;span&gt;&lt;span&gt;Here you have my proposal for Google Summer of Code &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;2009. It was approved previous week, and I'll be working on it during this summer.&lt;/span&gt;&lt;/span&gt;&lt;span style="font-size:180%;"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;
&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;The problem
&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;While Django provides an amazing system to translate texts, and displays localized dates in some parts of the admin; it has many data that could be internationalized, not it's not yet.&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;The information that developers should be able to localize/translate is mainly:&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; - &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;All  dates and related information (times, calendars...)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;All  numbers (mainly decimal ones)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Texts  (and any data in general) saved on the database&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;
 &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;More information on these issues can be found in the following blog post and this ticket:&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="http://vaig.be/2008/07/django-i18n-status.html"&gt;&lt;span&gt;&lt;span&gt;http://vaig.be/2008/07/django-i18n-status.html&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="http://code.djangoproject.com/ticket/7980"&gt;&lt;span&gt;&lt;span&gt;http://code.djangoproject.com/ticket/7980&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt; &lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;Proposal&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;The proposed solution for improving Django i18n includes several different tasks. Those tasks are:&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;ul&gt;&lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Import  locale data from CLDR&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Apply  i18n to Django dates and times&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Apply  i18n to Django numbers&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Allow  translating content on the database&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;span&gt;Fix already reported bug about i18n
&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Next are the details for every task. Note that all those specifications are subject to change, according to discussions with the mentor of the project, Django core developers team, and the main Django community.&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;Importing locale data
&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;The main repository of locale data is the Common Locale Data Repository (CLDR) by the Unicode Consortium &lt;/span&gt;&lt;/span&gt;http://cldr.unicode.org/.&lt;span&gt;&lt;span&gt; It provides a set of XML files with information such as date, time and number formatting for most languages.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;The idea of this task would be to create a python script (probably as a django-admin command), that will extract all necessary data from those XML files and put it into configuration files on the Django structure. This information will be used by Django to internationalize data on applications.&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;The idea of this script is to be used just by Django developers. It would mainly be a one-time execution script, and then it would be executed just when new locales are added (are some are changed).&lt;/p&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;All information gathered from CLDR files could be saved on django/conf/locale/{  language code }/formats/django.po&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Specific settings imported from CLDR could be (with English localized example):&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; - &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;SHORT_DATETIME_FORMAT  (12-31-2000 11:59 p.m.)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;LONG_DATETIME_FORMAT  (December 31th 2000, 11:59 p.m.)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;SHORT_DATE_FORMAT  (12-31-2000)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;LONG_DATE_FORMAT  (December 31th 2000)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;FIRST_DAY_OF_WEEK  (0 meaning Sunday)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;TIME_FORMAT  (11:59 p.m.)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;YEAR_MONTH_FORMAT  (December of 2000)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;MONTH_DAY_FORMAT  (December 31th)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;
 - &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;DECIMAL_NUMBER  FORMAT (1,000,000.123)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;
 &lt;p&gt;&lt;span&gt;&lt;span&gt;There are some locale based parameters that already exist on Django, on translation files (LC_MESSAGES) and could be deprecated on future releases of Django (when breaking backward compatibility). Those are:&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; - &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;DATETIME_FORMAT&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;DATE_FORMAT&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;TIME_FORMAT&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;YEAR_MONTH_FORMAT&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;MONTH_DAY_FORMAT&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;
 &lt;p&gt;For keeping the system flexible, existing default values on settings will be kept. Probably it would be worth to add new ones for the new customizable formats.&lt;/p&gt; &lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;Dates, times and calendar i18n&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;All dates and times displayed using Django should use the format defined for the current session locale. This is already implemented for some dates, like the ones displayed in admin's lists. Also a filter for formatting dates already exists in templates, which, together with the formats in the translation files, can do the job. But the good way to do that would be displaying the date by default on the session locale.&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;All Django forms (including admin forms) should accept the short date/datetime format of the current locale. Now it's possible to define the accepted formats using parameters of the widget, and this can be kept, but at least support for entering data formatted in current locale should be added. ISO and/or English locale can be kept as well. Existing data on input fields should be displayed in current locale too.&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;As Django 1.0 series is maintaining backward compatibility, those changes have to be implemented being compatible with existing behavior by default.&lt;/p&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;The calendar on admin's date/datetime field should also be displayed according to user session locale.&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;So basically those are the main tasks required for internationalizing Django dates:&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; - &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Format all python date/datetimes objects using locale settings when converted to string to be displayed. Basically it means models.DateField and models.DateTimeField values on model instances.&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Change  input widgets to display data and to allow entering data on the  format of the current locale.&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Display  admin calendar starting weeks on the day defined for current locale.&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;
 &lt;p&gt;&lt;span&gt;&lt;span&gt;With those changes next tickets would be fixed:&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; - &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;#1061  About first day on calendars&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;#5526  About accepting non-English formats on input widgets&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;#6231  About the output format of the SelectDateWidget&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;#6449  About default format of displayed dates&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;#6483  About supporting European dates on javascript routines&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;#7509  About supporting different formats on SplitDateTimeWidget&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;#7656  About inheriting i18n features of AdminDateWidget&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;
 &lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;Number i18n&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Right now, Django doesn't provide anything for localizing numbers on applications. All numeric values within Django applications are formatted using American formats. Users from many countries are not used to dealing with the American format, and a simple shop using Django can create confusion among users who, for example, expect the comma to be the decimal separator, and they find the point on prices.&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;As for the previous section, changes must be applied keeping backward compatibility.&lt;/p&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;So Django should display, and use by default the language of the current locale to format numbers. Basically that means:&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; - &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Format  numbers on templates using current session locale&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Display  and allow entering data using session locale on input widgets&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;
 &lt;p&gt;&lt;span&gt;&lt;span&gt;With those changes next ticket should be fixed:&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; - &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;#3940  About comma as decimal separator&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;
 &lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;Translating dynamic content&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Django has an amazing system for translating texts to any language. The only problem of this system is that it can just be used for static content (defined on source files, including templates), and not for dynamic content, created by users after deploying the web site. This can be useful for many different situations like an application that has a product catalog where product names and descriptions have to be translated, or a news website, where news can be translated to any language.&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;There are some external applications, widely used, that allow to do that on Django, but all of them have many different problems, like complex and tricky syntax for developers, ugly interface for users, bad design, bad scalability... Main applications are:&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; - &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;django-multilingual&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;transdb&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;django-transmeta&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;django-multilingual-model&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;
 &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;A comparison of the two first applications, and some ideas for a better solution, can be found on a presentation at&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="http://docs.google.com/Presentation?docid=dfbzs3ks_7f2z85hvr&amp;amp;hl=en"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;http://docs.google.com/Presentation?docid=dfbzs3ks_7f2z85hvr&amp;amp;hl=en&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Basically, a good solution to allow Django developers to translate their models should include:&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; - &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;An  easy way to specify translatable fields on models (or outside the  models)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;An  easy way to allow translating content using the admin or custom  forms&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Displaying  translated fields in session language by default (allowing to get  the value for a specific value)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;A  scalable way to save translations on the database&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;
 &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;To achieve those targets a lot of analysis is required, so, just some ideas are detailed here.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;For the model syntax there are many different options, some of them can be checked on this blog post, and this poll:&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="http://vaig.be/2009/03/django-multilingual-syntax-poll.html"&gt;&lt;span&gt;&lt;span&gt;http://vaig.be/2009/03/django-multilingual-syntax-poll.html&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="http://doodle.com/aicvayf8ss2mxm2h"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;http://doodle.com/aicvayf8ss2mxm2h&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;The most popular one is (using an example):&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    ::::
    &lt;span&gt;&lt;span&gt;class MyModel(model.Model):&lt;/span&gt;&lt;/span&gt;
     &lt;span&gt;my_field = CharField()&lt;/span&gt;
     &lt;span&gt;my_i18n_field = CharField()&lt;/span&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt; &lt;span class="nt"&gt;&amp;lt;span&amp;gt;&lt;/span&gt;class Meta:&lt;span class="nt"&gt;&amp;lt;/span&amp;gt;&lt;/span&gt;
     &lt;span class="nt"&gt;&amp;lt;span&amp;gt;&lt;/span&gt;translate = (&amp;#39;my_i18n_field&amp;#39;,)&lt;span class="nt"&gt;&amp;lt;/span&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;A way to translate models (and whole applications) without modifying its code would be great, in order to translate applications that already exist.&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;For the database backend there are also different options, including:&lt;/p&gt; - &lt;li&gt;To create a field on the model for every translation&lt;/li&gt;&lt;li&gt;To create a related model&lt;/li&gt;
 &lt;p&gt;&lt;span&gt;&lt;span&gt;There is just one generic ticket on Django that would be fixed:&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; - &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;#6460  About multilingual content on database&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;
 &lt;p&gt;May be it's not possible having a generic solution that fits most of the user-cases, and in that case could be worth making some modifications on Django to make it easier creating external applications that can do this job.&lt;/p&gt; &lt;h2&gt;Fix i18n bugs&lt;/h2&gt; &lt;p&gt;There are many bugs already accepted on Django trac, that would be fixed on this Summer of Code. A better review will be done, but some of them could be:&lt;/p&gt; - &lt;li&gt;#3907: LocaleMiddleware allows languages not supported by Django&lt;/li&gt;&lt;li&gt;#5494: Javascript catalog doesn't check project level locales&lt;/li&gt;&lt;li&gt;#7050: make-messages should ignore applications with custom localization&lt;/li&gt;
 &lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;Timeline&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;The estimated time line for this project, detailed in a weekly basis is:&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;ul&gt;&lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Week  01: Analysis and working environment setup
&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Week  02: &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;Import CLDR&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Week  03: Import CLDR&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Week  04: &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;I18n of dates and numbers&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Week  05: I18n of dates and numbers&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Week  06: I18n of dates and numbers&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Week  07: &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;Translation of dynamic content&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Week  08: Translation of dynamic content&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Week  09: Translation of dynamic content&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Week  10: Translation of dynamic content&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Week  11: Fix i18n bugs&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Week  12: Fix i18n bugs&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;&lt;/ul&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;My dedication to the project will be full time, around 40 hours per week. A total of 480 hours are estimated for the whole project.&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;About me&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;My name is Marc Garcia, I'm from Barcelona, Europe, and I'm 29 years old.&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;I am studying computer science at Universitat Oberta de Catalunya, an Internet-based university from Barcelona. Currently I'm not working but I have almost 8 years of programming experience (with different technologies, mainly Python, PHP and VB).&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;I started using Django in 2006, and at this time I developed and participated on the development of many websites, as well as many reusable applications for Django.&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;As examples of reusable Django applications note:&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; - &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;django-stdimage:  Saves ImageField files with standard names, allowing to delete them,  and creating automatic thumbnails.&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Transdb:  Allows translating database content&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;django-transmeta:  Also allows translating database content (different approach)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;django-cart:  Simple cart object to easily add/update/remove products to user  session&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;
 &lt;p&gt; &lt;/p&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;As examples of websites, note next ones:&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; - &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;http://elisa.fluendo.com  (main developer)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;http://www.andalucia.org  (developer of some parts, mainly the shop and the registration  system)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;http://www.muchomasqueunregalo.com (developer of the Django part of the web site, including the shopping system and product detail pages).&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;http://www.accopensys.com  (only developer)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;http://www.showroom.es  (only developer)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;http://www.tierratenis.com  (only developer)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;http://www.latelierdelraval.com  (only developer)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;http://www.restaurantalpunt.com  (only developer)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt;
 &lt;p&gt;&lt;span&gt;&lt;span&gt;I'm also one of the two official translators of Django to Castilian Spanish and Catalan. In addition, I was interviewed about localization on Django on &lt;em&gt;This Week in Django&lt;/em&gt; 20 (on 2008-04-27). I maintain a blog with many Django related posts at http://vaig.be.&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/p&gt;</content><category term="Django"></category><category term="Django-i18n"></category></entry><entry><title>django-cart released!</title><link href="https://datapythonista.github.io/blog/django-cart-released.html" rel="alternate"></link><published>2009-03-25T18:50:00+00:00</published><updated>2009-03-25T18:50:00+00:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2009-03-25:/blog/django-cart-released.html</id><summary type="html">&lt;p&gt;Until now, if you had to develop an online store in django, you had two options, use &lt;a href="http://www.satchmoproject.com/"&gt;satchmo&lt;/a&gt;, or write your own code. Satchmo is a huge application that tries to provide everything for all the cases, so for a simple shop you've to deal with hundreds of features that …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Until now, if you had to develop an online store in django, you had two options, use &lt;a href="http://www.satchmoproject.com/"&gt;satchmo&lt;/a&gt;, or write your own code. Satchmo is a huge application that tries to provide everything for all the cases, so for a simple shop you've to deal with hundreds of features that you're not going to use, and in some case it won't be enough flexible.&lt;/p&gt;
&lt;p&gt;So what I've not any complain for satchmo, the fact is that is not the ideal solution for some cases as some small shops with few options.&lt;/p&gt;
&lt;p&gt;With that said, this post is to announce the release of a new project that could help some people to do simple web shops in a very simple way. This project is &lt;a href="http://code.google.com/p/django-cart/"&gt;django-cart&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;While django-cart already existed, it was an unfinished (and unmaintained) project by Eric Woundenberg, to whom I'm very thankful for letting reuse it's project, and avoid confusion.&lt;/p&gt;
&lt;p&gt;So, what's django-cart. Django Cart is basically a django application that provides a Cart class, with add/remove/update and get methods to be used for storing products. The products model isn't included in the application, so you can define your products with the fields you need. Then you just need something like...&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;product_to_add&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;MyProductModel&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;objects&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="k"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;whatever&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;cart&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Cart&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;cart&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="k"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;product_to_add&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;product_to_add&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;price&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;and your product will be saved on the database, on a session based cart. Getting the content of the cart is as easy as itering the cart instance.&lt;/p&gt;
&lt;p&gt;And basically that's it. More information is available on the project page. Just note that the current version of the application is unstable, and hasn't been tested enough, so feel free to use it, but consider that you'll have to test it by yourself and report/fix some bugs.&lt;/p&gt;
&lt;p&gt;I hope all you like it!&lt;/p&gt;</content><category term="Django"></category></entry><entry><title>Getting client OS in Django</title><link href="https://datapythonista.github.io/blog/getting-client-os-in-django.html" rel="alternate"></link><published>2009-03-11T13:30:00+00:00</published><updated>2009-03-11T13:30:00+00:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2009-03-11:/blog/getting-client-os-in-django.html</id><summary type="html">&lt;p&gt;Some times it can be useful to serve our site content with little differences depending on the visitor operating system. I really think it's a bad idea changing the content or doing some big changes, depending on it, but this post can be useful for it as well.&lt;/p&gt;
&lt;p&gt;So, while …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Some times it can be useful to serve our site content with little differences depending on the visitor operating system. I really think it's a bad idea changing the content or doing some big changes, depending on it, but this post can be useful for it as well.&lt;/p&gt;
&lt;p&gt;So, while most time just some Javascript is used to customize user experience based on its operating system, few times it'll also be useful to do it in the server side.&lt;/p&gt;
&lt;p&gt;For those cases, here you've a simple context processor that will make available a template variable named "platform" which content can be "Linux", "Mac" or "Windows".&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;re&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;user_agent&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;#39;&amp;#39;&amp;#39; &lt;/span&gt;
&lt;span class="sd"&gt;    Context processor for Django that provides operating system&lt;/span&gt;
&lt;span class="sd"&gt;    information base on HTTP user agent.&lt;/span&gt;
&lt;span class="sd"&gt;    A user agent looks like (line break added):&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;quot;Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.6) \&lt;/span&gt;
&lt;span class="sd"&gt;    Gecko/2009020409 Iceweasel/3.0.6 (Debian-3.0.6-1)&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;user_agent&amp;#39;&lt;/span&gt;
    &lt;span class="c1"&gt;# Mozilla/5.0&lt;/span&gt;
    &lt;span class="n"&gt;regex&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;(?P&amp;lt;application_name&amp;gt;\w+)/(?P&amp;lt;application_version&amp;gt;[\d\.]+)&amp;#39;&lt;/span&gt;
    &lt;span class="n"&gt;regex&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39; \(&amp;#39;&lt;/span&gt;
    &lt;span class="c1"&gt;# X11&lt;/span&gt;
    &lt;span class="n"&gt;regex&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;(?P&amp;lt;compatibility_flag&amp;gt;\w+)&amp;#39;&lt;/span&gt;
    &lt;span class="n"&gt;regex&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;; &amp;#39;&lt;/span&gt;
    &lt;span class="c1"&gt;# U &lt;/span&gt;
    &lt;span class="n"&gt;regex&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;(?P&amp;lt;version_token&amp;gt;[\w .]+)&amp;#39;&lt;/span&gt;
    &lt;span class="n"&gt;regex&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;; &amp;#39;&lt;/span&gt;
    &lt;span class="c1"&gt;# Linux i686&lt;/span&gt;
    &lt;span class="n"&gt;regex&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;(?P&amp;lt;platform_token&amp;gt;[\w .]+)&amp;#39;&lt;/span&gt;
    &lt;span class="c1"&gt;# anything else&lt;/span&gt;
    &lt;span class="n"&gt;regex&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;; .*&amp;#39;&lt;/span&gt;

    &lt;span class="n"&gt;user_agent&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;META&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;HTTP_USER_AGENT&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;re&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;match&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;regex&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;user_agent&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;result_dict&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;groupdict&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;full_platform&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;result_dict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;platform_token&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="n"&gt;platform_values&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;full_platform&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39; &amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;platform_values&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Windows&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;Linux&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;Mac&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="n"&gt;platform&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;platform_values&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="n"&gt;platform_values&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Mac&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,):&lt;/span&gt;
            &lt;span class="c1"&gt;# Mac is given as &amp;quot;PPC Mac&amp;quot; or &amp;quot;Intel Mac&amp;quot;&lt;/span&gt;
            &lt;span class="n"&gt;platform&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;platform_values&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;platform&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;full_platform&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;
        &lt;span class="n"&gt;platform&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;user-agent&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;user_agent&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;full_platform&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;full_platform&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;platform&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;platform&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;To make it work just copy the code in a file&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;myproject&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;myapp&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;context_processors&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;add it to context processors in settings&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;TEMPLATE_CONTEXT_PROCESSORS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;myproject.myapp.context_processors.user_agent&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[...])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;and don't forget to add the RequestContext parameter if you are processing your template with render_to_response and want the variable available &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;django.template&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;RequestContext&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;render_to_response&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;mytemplate.html&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mycontext&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt; &lt;span class="n"&gt;style&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;font-weight:bold;&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;RequestContext&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Then you'll be able to do something like that in your templates:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="nt"&gt;&amp;lt;p&amp;gt;&lt;/span&gt;You are a &lt;span class="cp"&gt;{{&lt;/span&gt; &lt;span class="nv"&gt;platform&lt;/span&gt; &lt;span class="cp"&gt;}}&lt;/span&gt; user.&lt;span class="nt"&gt;&amp;lt;/p&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</content><category term="Django"></category></entry><entry><title>django-multilingual syntax poll</title><link href="https://datapythonista.github.io/blog/django-multilingual-syntax-poll.html" rel="alternate"></link><published>2009-03-10T00:00:00+00:00</published><updated>2009-03-10T00:00:00+00:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2009-03-10:/blog/django-multilingual-syntax-poll.html</id><summary type="html">&lt;p&gt;Those days there is some activity in the django model translation area, specially for the two new projects that joined &lt;a href="http://code.google.com/p/django-multilingual/"&gt;django-multilingual&lt;/a&gt; and &lt;a href="http://code.google.com/p/transdb/"&gt;transdb&lt;/a&gt; to achieve this: &lt;a href="http://code.google.com/p/django-transmeta"&gt;django-transmeta&lt;/a&gt; and &lt;a href="http://code.google.com/p/django-modeltranslation/"&gt;django-modeltranslation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;While there are some intentional differences among some projects (for example django-modeltranslation is the only one that can translate models without …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Those days there is some activity in the django model translation area, specially for the two new projects that joined &lt;a href="http://code.google.com/p/django-multilingual/"&gt;django-multilingual&lt;/a&gt; and &lt;a href="http://code.google.com/p/transdb/"&gt;transdb&lt;/a&gt; to achieve this: &lt;a href="http://code.google.com/p/django-transmeta"&gt;django-transmeta&lt;/a&gt; and &lt;a href="http://code.google.com/p/django-modeltranslation/"&gt;django-modeltranslation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;While there are some intentional differences among some projects (for example django-modeltranslation is the only one that can translate models without editing them), it would be great to merge all (or most) existing projects, and join the efforts to get our best application (and hopefully it'll worth to be included in Django itself).&lt;/p&gt;
&lt;p&gt;So, with the merge of those applications in mind, we're &lt;a href="http://groups.google.com/group/django-multilingual/browse_thread/thread/2fab1d1674090079"&gt;planning&lt;/a&gt; to create a branch on django-multilingual that will have the very best of each existing application, and any other cool idea.&lt;/p&gt;
&lt;p&gt;So if you have good Python/Django skills, and want to add some open source work in your CV... ;)  join us now!&lt;/p&gt;
&lt;p&gt;Or if you are a potential user of this application, or you just think that your opinion is worth to be shared, please fill the &lt;a href="http://doodle.com/aicvayf8ss2mxm2h"&gt;&lt;span style="font-weight:bold;"&gt;MODEL SYNTAX POLL&lt;/span&gt;&lt;/a&gt;, or mail &lt;a href="http://groups.google.com/group/django-multilingual/browse_thread/thread/2fab1d1674090079"&gt;us&lt;/a&gt; with your ideas.&lt;/p&gt;
&lt;p&gt;Here there are simple sample for each option on the poll:&lt;/p&gt;
&lt;p&gt;class Translation&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="n"&gt;MyModel&lt;/span&gt;(&lt;span class="n"&gt;model&lt;/span&gt;.&lt;span class="n"&gt;Model&lt;/span&gt;):
    &lt;span class="n"&gt;my_field&lt;/span&gt; = &lt;span class="n"&gt;CharField&lt;/span&gt;()

    &lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="n"&gt;Translation&lt;/span&gt;(&lt;span class="n"&gt;multilingual&lt;/span&gt;.&lt;span class="n"&gt;Translation&lt;/span&gt;):
        &lt;span class="n"&gt;my_i18n_field&lt;/span&gt; = &lt;span class="n"&gt;CharField&lt;/span&gt;()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;custom fields&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="n"&gt;MyModel&lt;/span&gt;(&lt;span class="n"&gt;model&lt;/span&gt;.&lt;span class="n"&gt;Model&lt;/span&gt;):
    &lt;span class="n"&gt;my_field&lt;/span&gt; = &lt;span class="n"&gt;CharField&lt;/span&gt;()
    &lt;span class="n"&gt;my_i18n_field&lt;/span&gt; = &lt;span class="n"&gt;TransCharField&lt;/span&gt;()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;separate model&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="n"&gt;MyModel&lt;/span&gt;(&lt;span class="n"&gt;model&lt;/span&gt;.&lt;span class="n"&gt;Model&lt;/span&gt;):
    &lt;span class="n"&gt;my_field&lt;/span&gt; = &lt;span class="n"&gt;CharField&lt;/span&gt;()
    &lt;span class="n"&gt;my_i18n_field&lt;/span&gt; = &lt;span class="n"&gt;CharField&lt;/span&gt;()

&lt;span class="nb"&gt;Class&lt;/span&gt; &lt;span class="n"&gt;MyModelTranslation&lt;/span&gt;(&lt;span class="n"&gt;TranslationOptions&lt;/span&gt;):
    &lt;span class="n"&gt;fields&lt;/span&gt; = (&lt;span class="s"&gt;&amp;#39;my_i18n_field&amp;#39;&lt;/span&gt;,)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;translate attrs in Meta&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="n"&gt;MyModel&lt;/span&gt;(&lt;span class="n"&gt;model&lt;/span&gt;.&lt;span class="n"&gt;Model&lt;/span&gt;):
    &lt;span class="n"&gt;my_field&lt;/span&gt; = &lt;span class="n"&gt;CharField&lt;/span&gt;()
    &lt;span class="n"&gt;my_i18n_field&lt;/span&gt; = &lt;span class="n"&gt;CharField&lt;/span&gt;()

    &lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="n"&gt;Meta:&lt;/span&gt;
        &lt;span class="n"&gt;translate&lt;/span&gt; = (&lt;span class="s"&gt;&amp;#39;my_i18n_field&amp;#39;&lt;/span&gt;,)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;translate=True in field options&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="n"&gt;MyModel&lt;/span&gt;(&lt;span class="n"&gt;model&lt;/span&gt;.&lt;span class="n"&gt;Model&lt;/span&gt;):
    &lt;span class="n"&gt;my_field&lt;/span&gt; = &lt;span class="n"&gt;CharField&lt;/span&gt;()
    &lt;span class="n"&gt;my_i18n_field&lt;/span&gt; = &lt;span class="n"&gt;CharField&lt;/span&gt;(&lt;span class="n"&gt;translate&lt;/span&gt;=&lt;span class="nb"&gt;True&lt;/span&gt;)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Do you have a better idea?
Just leave a comment here,
or write a mail on this &lt;a href="http://groups.google.com/group/django-multilingual/browse_thread/thread/2fab1d1674090079"&gt;thread&lt;/a&gt;&lt;/p&gt;</content><category term="Django"></category></entry><entry><title>Restrict multiple simultaneos executions of a Python program</title><link href="https://datapythonista.github.io/blog/restrict-multiple-simultaneos.html" rel="alternate"></link><published>2009-03-06T15:52:00+00:00</published><updated>2009-03-06T15:52:00+00:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2009-03-06:/blog/restrict-multiple-simultaneos.html</id><summary type="html">&lt;p&gt;Here you've a simple function to avoid a python script to be executed more than once at the same time:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;
def use_lock(func, lockfile):
    if not os.path.exists(lockfile):
        with open(lockfile, 'w') as f:
            f.write(str(os.getpid()))
        func()
        os.remove(lockfile)
        return True
    else:
        return None …&lt;/code&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;Here you've a simple function to avoid a python script to be executed more than once at the same time:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;
def use_lock(func, lockfile):
    if not os.path.exists(lockfile):
        with open(lockfile, 'w') as f:
            f.write(str(os.getpid()))
        func()
        os.remove(lockfile)
        return True
    else:
        return None
&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;To execute a function main() using a lock file "/var/run/myprogram.pid" just write:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;
use_lock(main, '/var/run/myprogram.pid')
&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Hope you find it useful.&lt;/p&gt;</content><category term="Python"></category></entry><entry><title>Numeric IP field for Django</title><link href="https://datapythonista.github.io/blog/numeric-ip-field-for-django.html" rel="alternate"></link><published>2009-03-06T13:05:00+00:00</published><updated>2009-03-06T13:05:00+00:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2009-03-06:/blog/numeric-ip-field-for-django.html</id><summary type="html">&lt;p&gt;Some time ago I needed to add an IP field to my model with more records (some hundred thousands). I was going to just add Django's IPAddressField, but I realized that it stores the data as text on the database, and I didn't like the idea.&lt;/p&gt;
&lt;p&gt;Basically, and IP address …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Some time ago I needed to add an IP field to my model with more records (some hundred thousands). I was going to just add Django's IPAddressField, but I realized that it stores the data as text on the database, and I didn't like the idea.&lt;/p&gt;
&lt;p&gt;Basically, and IP address is just 4 bytes of data, but it's text representation can use between 7 and 15 bytes. That's not a big different when your model will have few rows, but it's a different when you'll have a huge set of IP addresses, and specially if you want to join tables by it.&lt;/p&gt;
&lt;p&gt;The only inconvenient of storing the IPs as numbers is that are not human readable if you want to check them directly to database.&lt;/p&gt;
&lt;p&gt;So, here you have my code that can be used as a replacement of IPAddressField:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;IPy&lt;/span&gt; 
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;django.db&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;models&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;django&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;forms&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;django.utils.translation&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;ugettext&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;_ip_to_int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ip&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;IPy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;IP&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ip&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ip&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;_int_to_ip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;numeric_ip&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;IPy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;IP&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;numeric_ip&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strNormal&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;IPFormField&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;forms&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fields&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Field&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;clean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;_ip_to_int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="ne"&gt;ValueError&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="n"&gt;forms&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ValidationError&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; \
                &lt;span class="n"&gt;_&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;You must provide a valid IP address&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;super&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;IPFormField&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;clean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;IPField&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;models&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fields&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;PositiveIntegerField&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;#39;&amp;#39;&amp;#39; &lt;/span&gt;
&lt;span class="sd"&gt;    IP field for django for storing IPs as integers on database&lt;/span&gt;
&lt;span class="sd"&gt;    (Django&amp;#39;s field IPAddressField stores them as text)&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
    &lt;span class="vm"&gt;__metaclass__&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;models&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;SubfieldBase&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;to_python&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;isinstance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;long&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
                &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;_int_to_ip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;get_db_prep_save&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;_ip_to_int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="ne"&gt;ValueError&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;get_db_prep_value&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;_ip_to_int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;get_db_prep_lookup&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;lookup_type&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;super&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;IPField&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_db_prep_lookup&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
            &lt;span class="n"&gt;lookup_type&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="n"&gt;_ip_to_int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;formfield&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;defaults&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;form_class&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;IPFormField&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
        &lt;span class="n"&gt;defaults&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;update&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;super&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;IPField&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;formfield&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;defaults&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;span style="font-weight:bold;"&gt;NOTE&lt;/span&gt;: This code requires &lt;a href="http://c0re.23.nu/c0de/IPy/"&gt;IPy&lt;/a&gt;, a single file python library to work with IP addresses.&lt;/p&gt;</content><category term="Django"></category></entry><entry><title>Easier field translation with django-transmeta</title><link href="https://datapythonista.github.io/blog/easier-field-translation-with-django.html" rel="alternate"></link><published>2009-03-04T11:44:00+00:00</published><updated>2009-03-04T11:44:00+00:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2009-03-04:/blog/easier-field-translation-with-django.html</id><summary type="html">&lt;p&gt;&lt;a href="http://code.google.com/p/django-transmeta"&gt;django-transmeta&lt;/a&gt; is a new project that provides django field translations in a simpler way than existing ones like &lt;a href="http://code.google.com/p/django-multilingual/"&gt;django-multilingual&lt;/a&gt; and &lt;a href="http://code.google.com/p/transdb/"&gt;transdb&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The basis of that simplicity is creating a field in the database table for every translation, so internally we'll have something like:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;
CREATE TABLE app_model (
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;[...]
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;myfield_en varchar,
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;myfield_ca varchar …&lt;/code&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="http://code.google.com/p/django-transmeta"&gt;django-transmeta&lt;/a&gt; is a new project that provides django field translations in a simpler way than existing ones like &lt;a href="http://code.google.com/p/django-multilingual/"&gt;django-multilingual&lt;/a&gt; and &lt;a href="http://code.google.com/p/transdb/"&gt;transdb&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The basis of that simplicity is creating a field in the database table for every translation, so internally we'll have something like:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;
CREATE TABLE app_model (
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;[...]
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;myfield_en varchar,
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;myfield_ca varchar,
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;[...]
);
&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;where "en" and "ca" are the languages in our application (English and Catalan in this case).&lt;/p&gt;
&lt;p&gt;For the developer, translating a model is as simple as adding a metaclass to the model, and specify the fields to translate in its Meta class:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;
from transmeta import TransMeta&lt;/p&gt;
&lt;p&gt;class MyModel(models.Model):
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;code&gt;__metaclass__&lt;/code&gt; = TransMeta&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;name = models.CharField(max_length=64)
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;description = models.TextField()
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;price = models.FloatField()&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;class Meta:
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;translate = ('name', 'description', )
&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Even with this project is still as tricky as transdb and multilingual, its main goal is being really really simple, for its design, for developers, and its code (that mainly it's about 120 lines of code). It also breaks some limitations of transdb (its most simple predecessor IMHO) like translating non-text fields.&lt;/p&gt;
&lt;p&gt;I also want to mention that I just discovered a new project for translating model fields, named &lt;a href="http://code.google.com/p/django-modeltranslation"&gt;django-modeltranslation&lt;/a&gt;, that looks cool, but I don't like the (admin like) registering way to set translatable fields (too much complicated).&lt;/p&gt;</content><category term="Django"></category></entry><entry><title>Parsing unescaped urls in django</title><link href="https://datapythonista.github.io/blog/parsing-unescaped-urls-in-django.html" rel="alternate"></link><published>2009-02-19T15:40:00+00:00</published><updated>2009-02-19T15:40:00+00:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2009-02-19:/blog/parsing-unescaped-urls-in-django.html</id><summary type="html">&lt;p&gt;Modern browsers escape urls automatically before sending them to the server, but what happens if your application serves http requests to clients that doesn't escape urls?&lt;/p&gt;
&lt;p&gt;The answer is that can get unexpected results if you server works in Django (and probably in any python framework/application). That's because python's …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Modern browsers escape urls automatically before sending them to the server, but what happens if your application serves http requests to clients that doesn't escape urls?&lt;/p&gt;
&lt;p&gt;The answer is that can get unexpected results if you server works in Django (and probably in any python framework/application). That's because python's BaseHTTPServer.BaseHTTPRequestHandler handles urls according to standards, not from a human point of view.&lt;/p&gt;
&lt;p&gt;Let's see with an example, consider the next request:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;http://vaig.be/identify_myself?name=Marc Garcia&amp;amp;country=Catalonia&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;if you request it with a browser, it will escape the space in the url, so the server will get:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;http://vaig.be/identify_myself?name=Marc%20Garcia&amp;amp;country=Catalonia&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;but what if the client uses, for example, python's urllib2.urlopen without escaping (using urllib.quote)? Of course it is a mistake, but you, as server side developer can't control your clients.&lt;/p&gt;
&lt;p&gt;In that case the whole request that server receives is:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;GET http://vaig.be/identify_myself?name=Marc Garcia&amp;amp;country=Catalonia HTTP/1.1&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;and after being processed (splitted) by python's BaseHTTPServer.BaseHTTPRequestHandler, what we'll get from django is:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;
request.method == 'GET'
request.META['QUERY_STRING'] == 'name=Marc'
request.META['SERVER_PROTOCOL'] == 'Garcia&amp;amp;country=Catalonia HTTP/1.1'
&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;so our request.GET dictionary will look like:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;request.GET == {'name': 'Marc'}&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;what is not the expected value (from a human point of view).&lt;/p&gt;
&lt;p&gt;So, what we can do for avoiding this result is quite easy (and of course tricky), and is getting the GET values not from django request.GET dictionary but from the one returned by this function:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;
def _manual_GET(request):
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;if ' ' in request.META['SERVER_PROTOCOL']:
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;query_string = ' '.join(
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;[request.META['QUERY_STRING']] +
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;request.META['SERVER_PROTOCOL'].split(' ')[:-1]
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;)&lt;br&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;args = query_string.split('&amp;amp;')
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;result = {}
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;for arg in args:
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;key, value = arg.split('=', 1)
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;result[key] = value
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;return result
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;else:
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;return request.GET
&lt;/code&gt;&lt;/p&gt;</content><category term="Django"></category></entry><entry><title>CSS Centering</title><link href="https://datapythonista.github.io/blog/css-centering.html" rel="alternate"></link><published>2009-02-04T13:27:00+00:00</published><updated>2009-02-04T13:27:00+00:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2009-02-04:/blog/css-centering.html</id><summary type="html">&lt;p&gt;Today I find a solution for one of the most common problems I had with CSS, vertical centering. I really don't like CSS, and one of my examples to explain why, it was the lack of a elegant way to vertical align an element inside a div.&lt;/p&gt;
&lt;p&gt;First page I …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Today I find a solution for one of the most common problems I had with CSS, vertical centering. I really don't like CSS, and one of my examples to explain why, it was the lack of a elegant way to vertical align an element inside a div.&lt;/p&gt;
&lt;p&gt;First page I found was &lt;a href="http://www.jakpsatweb.cz/css/css-vertical-center-solution.html"&gt;http://www.jakpsatweb.cz/css/css-vertical-center-solution.html&lt;/a&gt; that is a great post, that gets a solution but very very tricky.&lt;/p&gt;
&lt;p&gt;Luckily while implementing that solution, I found a very is solution, described here: &lt;a href="http://www.w3.org/Style/Examples/007/center.html"&gt;http://www.w3.org/Style/Examples/007/center.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;As easy as:
&lt;code&gt;
div.container {
  display: table-cell;
  vertical-align: middle;
}
&lt;/code&gt;
I don't think that is very intuitive (at least for me), but it's simple.&lt;/p&gt;</content></entry><entry><title>Compare two XML strings in Python</title><link href="https://datapythonista.github.io/blog/compare-two-xml-strings-in-python.html" rel="alternate"></link><published>2008-08-28T19:05:00+01:00</published><updated>2008-08-28T19:05:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2008-08-28:/blog/compare-two-xml-strings-in-python.html</id><summary type="html">&lt;p&gt;I had to compare two XML strings for some unit tests, and if you want to do it without considering the indentation, or the newlines, it is a little bit tricky.&lt;br/&gt;&lt;br/&gt;I thought that parsing the original xml and returning it again (using minidom), I'd got a raw string without …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I had to compare two XML strings for some unit tests, and if you want to do it without considering the indentation, or the newlines, it is a little bit tricky.&lt;br/&gt;&lt;br/&gt;I thought that parsing the original xml and returning it again (using minidom), I'd got a raw string without any meaningless space, or any newline, but actually it returned the original string. Using toprettyxml() method also returns a trivial result, based on the original string (even when you specify the indent and the newline characters).&lt;br/&gt;&lt;br/&gt;So the best way I've found by now is to write a custom function that returns what I want, an XML string without any trivial character between tag and tag. Here you have the code:&lt;br/&gt;&lt;br/&gt;&lt;code&gt;def raw_xml(xml_str):&lt;br/&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;from xml.dom import minidom&lt;br/&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;xml = minidom.parseString(xml_str)&lt;br/&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;return u''.join([unicode(line).strip() for line in xml.toprettyxml().splitlines()])&lt;br/&gt;&lt;/code&gt;&lt;/p&gt;</content><category term="Development"></category><category term="IT"></category></entry><entry><title>Brother printer and GNU (aka Linux)</title><link href="https://datapythonista.github.io/blog/brother-printer-and-gnu-aka-linux.html" rel="alternate"></link><published>2008-08-17T16:12:00+01:00</published><updated>2008-08-17T16:12:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2008-08-17:/blog/brother-printer-and-gnu-aka-linux.html</id><summary type="html">&lt;p&gt;Some time ago I purchased a &lt;a href="http://www.brother.com/"&gt;Brother&lt;/a&gt; multifunctional priner/scanner/fax, the &lt;a href="http://www.brother.es/g3.cfm/s_page/67210/s_level/32130/s_product/MFC235CT1"&gt;MFC-235C&lt;/a&gt;.&lt;br/&gt;&lt;br/&gt;Today, after reinstalling my laptop, I had to install it again, and it has been as easy as the first. Specially because Brother has GNU (aka Linux) support, including GPL drivers for all printer features.&lt;br/&gt;&lt;br/&gt;As well …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Some time ago I purchased a &lt;a href="http://www.brother.com/"&gt;Brother&lt;/a&gt; multifunctional priner/scanner/fax, the &lt;a href="http://www.brother.es/g3.cfm/s_page/67210/s_level/32130/s_product/MFC235CT1"&gt;MFC-235C&lt;/a&gt;.&lt;br/&gt;&lt;br/&gt;Today, after reinstalling my laptop, I had to install it again, and it has been as easy as the first. Specially because Brother has GNU (aka Linux) support, including GPL drivers for all printer features.&lt;br/&gt;&lt;br/&gt;As well as the deserved publicity that I want to give to Brother in this post, I want to write a quick installation howto. I'm installing the printer locally using USB, and CUPS in my Debian. You should have this installed in your computer before starting the next steps (otherwise you'll have to add some steps, or change some).&lt;br/&gt;- &lt;br/&gt;    &lt;li&gt;apt-get install lpr&lt;/li&gt;&lt;br/&gt;   &lt;li&gt;Download lpr driver from &lt;a href="http://solutions.brother.com/linux/sol/printer/linux/lpr_drivers.html"&gt;http://solutions.brother.com/linux/sol/printer/linux/lpr_drivers.html&lt;/a&gt;&lt;/li&gt;&lt;br/&gt;   &lt;li&gt;dpkg -i &lt;downloaded driver&gt;&lt;/li&gt;&lt;br/&gt;   &lt;li&gt;Download cups driver from &lt;a href="http://solutions.brother.com/linux/sol/printer/linux/cups_drivers.html"&gt;http://solutions.brother.com/linux/sol/printer/linux/cups_drivers.html&lt;/a&gt;&lt;/li&gt;&lt;br/&gt;    &lt;li&gt;dpkg -i &lt;downloaded driver&gt;&lt;/li&gt;&lt;br/&gt;   &lt;li&gt;Go to the &lt;a href="http://solutions.brother.com/linux/sol/printer/linux/linux_faq-2.html"&gt;FAQ&lt;/a&gt; if you have any problem&lt;/li&gt;&lt;br/&gt;    &lt;li&gt;Download scanner sane driver from &lt;a href="http://solutions.brother.com/linux/sol/printer/linux/sane_drivers.html"&gt;http://solutions.brother.com/linux/sol/printer/linux/sane_drivers.html&lt;/a&gt;&lt;/li&gt;&lt;br/&gt;    &lt;li&gt;dpkg -i &lt;downloaded driver&gt;&lt;/li&gt;&lt;br/&gt;   &lt;li&gt;Got to the scanner &lt;a href="http://solutions.brother.com/linux/sol/printer/linux/linux_faq.html"&gt;FAQ&lt;/a&gt; if you have any problem (it's common having problems running sane with a standard user, but information on how to fix it is available at this FAQ).&lt;/li&gt;&lt;br/&gt;
&lt;br/&gt;And that's it! Very easy compared with the problems that I had doing the same installation for HP all-in-one printers.&lt;/p&gt;</content><category term="Systems"></category><category term="IT"></category></entry><entry><title>StdImage updated to trunk</title><link href="https://datapythonista.github.io/blog/stdimage-updated-to-trunk.html" rel="alternate"></link><published>2008-08-13T03:16:00+01:00</published><updated>2008-08-13T03:16:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2008-08-13:/blog/stdimage-updated-to-trunk.html</id><summary type="html">&lt;p&gt;Everything is changing on Django those days, and many people contacted me because StdImage stopped working with trunk.&lt;br/&gt;&lt;br/&gt;Basically all major changes (except GeoDjango) affected it, such as change from newforms to forms, signal refactoring, and file storage refactoring. Now it's up to date.&lt;br/&gt;&lt;br/&gt;Remind that &lt;a href="http://code.google.com/p/django-stdimage/"&gt;django-stdimage&lt;/a&gt; is a Django …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Everything is changing on Django those days, and many people contacted me because StdImage stopped working with trunk.&lt;br/&gt;&lt;br/&gt;Basically all major changes (except GeoDjango) affected it, such as change from newforms to forms, signal refactoring, and file storage refactoring. Now it's up to date.&lt;br/&gt;&lt;br/&gt;Remind that &lt;a href="http://code.google.com/p/django-stdimage/"&gt;django-stdimage&lt;/a&gt; is a Django application that provides a standardized  image field(standard name including row id, standard size, and ability to create automatic thumbnails, also standarized of course).&lt;/p&gt;</content><category term="Applications"></category><category term="Django"></category><category term="IT"></category></entry><entry><title>Cuil? WTF!</title><link href="https://datapythonista.github.io/blog/cuil-wtf.html" rel="alternate"></link><published>2008-08-08T18:24:00+01:00</published><updated>2008-08-08T18:24:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2008-08-08:/blog/cuil-wtf.html</id><summary type="html">&lt;p&gt;Few days ago a new search engine was published, and many media covered the it. I supposed for that, that it should be something important, but I think that in few days it'll only be important for its creators. Why I think that? Well, here you have my arguments for …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Few days ago a new search engine was published, and many media covered the it. I supposed for that, that it should be something important, but I think that in few days it'll only be important for its creators. Why I think that? Well, here you have my arguments for that conclusion.&lt;br/&gt;&lt;br/&gt;From &lt;a href="http://www.cuil.com/info/"&gt;Cuil&lt;/a&gt;: "Cuil searches more pages on the Web than anyone else—three times as many as Google and ten times as many as Microsoft."&lt;br/&gt;&lt;br/&gt;From &lt;a href="http://googleblog.blogspot.com/2008/07/we-knew-web-was-big.html"&gt;Google&lt;/a&gt;: "when our systems that process links on the web to find new content hit a milestone: 1 trillion (as in 1,000,000,000,000) unique URLs on the web at once!"&lt;br/&gt;&lt;br/&gt;From myself:  1,000,000,000,000 * 3 = 3,000,000,000,000&lt;br/&gt;&lt;br/&gt;From &lt;a href="http://www.alexa.com/data/details/main/vaig.be"&gt;Alexa&lt;/a&gt;: "Vaig.be    has a  traffic rank of 1,163,358"&lt;br/&gt;&lt;br/&gt;&lt;strong&gt;Conclusion&lt;/strong&gt;:  You're supposed to have 1 trillion pages, and you don't have my blog, that is the 1 million page more visited around the world? WTF!&lt;/p&gt;</content><category term="This blog"></category><category term="Internet"></category><category term="IT"></category></entry><entry><title>Firefox Add-ons (update)</title><link href="https://datapythonista.github.io/blog/firefox-add-ons-update.html" rel="alternate"></link><published>2008-08-07T23:56:00+01:00</published><updated>2008-08-07T23:56:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2008-08-07:/blog/firefox-add-ons-update.html</id><summary type="html">&lt;p&gt;Some time ago, I wrote&lt;a href="http://vaig.be/2007/04/25/firefox-extensions/"&gt; a post&lt;/a&gt; in this blog about the essential Firefox extensions for developers. After some time, that post is out of date, so I changed some of those extensions, and started using some new. Here is the updated list:&lt;br/&gt;&lt;br/&gt;&lt;a href="https://addons.mozilla.org/en-US/firefox/addon/1843"&gt;Firebug&lt;/a&gt;: Javascript debugging, graphical check of CSS …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Some time ago, I wrote&lt;a href="http://vaig.be/2007/04/25/firefox-extensions/"&gt; a post&lt;/a&gt; in this blog about the essential Firefox extensions for developers. After some time, that post is out of date, so I changed some of those extensions, and started using some new. Here is the updated list:&lt;br/&gt;&lt;br/&gt;&lt;a href="https://addons.mozilla.org/en-US/firefox/addon/1843"&gt;Firebug&lt;/a&gt;: Javascript debugging, graphical check of CSS properties (moving the cursor to an area of the web, you can see the html, css properties...), loading time statistics per file, and a infinite set of option.&lt;br/&gt;&lt;br/&gt;&lt;a href="https://addons.mozilla.org/en-US/firefox/addon/60"&gt;Web developer&lt;/a&gt;: Disabling CSS, Javascript, Resizing browser window to standard formats...&lt;br/&gt;&lt;br/&gt;&lt;a href="https://addons.mozilla.org/en-US/firefox/addon/249"&gt;HTML Validator&lt;/a&gt;: Offline version fo the w3c validator.&lt;br/&gt;&lt;br/&gt;&lt;a href="https://addons.mozilla.org/en-US/firefox/addon/321"&gt;SearchStatus&lt;/a&gt;: PageRank, and Alexa rank information.&lt;/p&gt;</content><category term="Applications"></category><category term="Internet"></category><category term="IT"></category></entry><entry><title>Translating Django apps. Good practices</title><link href="https://datapythonista.github.io/blog/translating-django-apps-good-practices.html" rel="alternate"></link><published>2008-08-01T18:59:00+01:00</published><updated>2008-08-01T18:59:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2008-08-01:/blog/translating-django-apps-good-practices.html</id><summary type="html">&lt;p&gt;In this article you'll find some tips, that could be useful for avoiding problems or extra work when translating your Django application.&lt;br/&gt;&lt;br/&gt;&lt;strong&gt;1. Setting up the environment&lt;/strong&gt;&lt;br/&gt;&lt;br/&gt;Doing some trivial changes to your project structure, can avoid you of translating many string (the ones that are already translated in Django …&lt;/p&gt;</summary><content type="html">&lt;p&gt;In this article you'll find some tips, that could be useful for avoiding problems or extra work when translating your Django application.&lt;br/&gt;&lt;br/&gt;&lt;strong&gt;1. Setting up the environment&lt;/strong&gt;&lt;br/&gt;&lt;br/&gt;Doing some trivial changes to your project structure, can avoid you of translating many string (the ones that are already translated in Django, or in any external application).&lt;br/&gt;&lt;br/&gt;For achieving it, my tip is to copy Django itself, and all external applications to your project path, not in a PYTHONPATH directory. It can also avoid compatibility problems, and version conflicts if you're working on several  projects. Then your project root will contain something like:&lt;br/&gt;&lt;br/&gt;&lt;code&gt;&lt;code&gt;__init__&lt;/code&gt;.py&lt;br/&gt;settings.py&lt;br/&gt;urls.py&lt;br/&gt;django/&lt;br/&gt;transdb/&lt;br/&gt;myapp/&lt;/code&gt;&lt;br/&gt;&lt;br/&gt;Next step is  patching Django (while it's not included in trunk) to omit the inclusion of already translated applications into your project. Here is the &lt;a href="http://code.djangoproject.com/attachment/ticket/7916/7916_v2.diff"&gt;patch&lt;/a&gt;, and you can also see &lt;a href="http://code.djangoproject.com/ticket/7050"&gt;#7050&lt;/a&gt; for further information, or know the status.&lt;br/&gt;&lt;br/&gt;Then, when executing &lt;em&gt;./manage.py makemessages&lt;/em&gt; you'll find in your project catalogs, just strings that aren't previously translated.&lt;br/&gt;&lt;br/&gt;&lt;strong&gt;2. Creating string&lt;/strong&gt;&lt;br/&gt;&lt;br/&gt;If you don't have a correct literal creation policy, then your translator will have extra work, problems, and your translation won't be as correct as it should.&lt;br/&gt;&lt;br/&gt;The first thing to do is write literals thinking in reusability (as  software reusability but for translations). I'll show it with some examples:&lt;br/&gt;&lt;br/&gt;Using&lt;br/&gt;&lt;br/&gt;&lt;code&gt;{% trans 'product' %}&lt;br/&gt;{% trans 'Product' %}&lt;br/&gt;{% trans 'product:' %}&lt;br/&gt;&lt;/code&gt;&lt;br/&gt;you'll create 3 different string in your translation. Using&lt;br/&gt;&lt;br/&gt;&lt;code&gt;{% trans 'product' %}&lt;br/&gt;{{ &lt;em&gt;("product")|capfirst }}&lt;br/&gt;{% trans 'product' %}:&lt;br/&gt;&lt;/code&gt;&lt;br/&gt;will create just one.&lt;br/&gt;&lt;br/&gt;Another thing to consider is that some times  you consider that a word has just one meaning, or at least you don't think that could be translated using different words. But actually, when translating it to another language it can be converted to different words depending on the context. Let's use an example.&lt;br/&gt;&lt;code&gt;&lt;br/&gt;&lt;em&gt;Play&lt;/em&gt; football&lt;br/&gt;&lt;em&gt;Play&lt;/em&gt; the guitar&lt;/code&gt;&lt;br/&gt;&lt;br/&gt;Probably for most native English  speakers &lt;em&gt;play&lt;/em&gt; doesn't have more than a subtle difference in two sentences, but if I translate it as follows:&lt;br/&gt;&lt;code&gt;&lt;br/&gt;&lt;/em&gt;("play") -&amp;gt; jugar&lt;/code&gt;&lt;br/&gt;&lt;br/&gt;Then you'll find something like&lt;br/&gt;&lt;br/&gt;&lt;code&gt;Play football -&amp;gt; Jugar a  futbol (what's correct)&lt;br/&gt;Play the guitar -&amp;gt; Jugar con la guitarra (what means "To have fun with the guitar", probably without generating any sound)&lt;/code&gt;&lt;br/&gt;&lt;br/&gt;This will be avoided most times, because usually we don't translate word my word, but there are few cases where we do that, and you should consider doing something like that in that case (actually I never had to do it :)&lt;br/&gt;&lt;br/&gt;&lt;code&gt;&lt;em&gt;("play &lt;!-- an instrument --&gt;")&lt;br/&gt;&lt;/em&gt;("play &lt;!-- a sport --&gt;")&lt;/code&gt;&lt;br/&gt;&lt;br/&gt;Then when you translate into Spanish:&lt;br/&gt;&lt;br/&gt;&lt;code&gt;"play &lt;!-- an instrument --&gt;" -&amp;gt; "tocar"&lt;br/&gt;"play &lt;!-- a sport --&gt;" -&amp;gt; "jugar"&lt;/code&gt;&lt;br/&gt;&lt;br/&gt;And I would also translate English into English:&lt;br/&gt;&lt;br/&gt;&lt;code&gt;"play &lt;!-- an instrument --&gt;" -&amp;gt; "play"&lt;br/&gt;"play &lt;!-- a sport --&gt;" -&amp;gt; "play"&lt;/code&gt;&lt;br/&gt;&lt;br/&gt;There will be infinite cases that will generate issues when translating, and it'll be impossible to control everyone. I just wanted to give some tips focused to Django applications.&lt;br/&gt;&lt;br/&gt;&lt;strong&gt;3. Translating&lt;/strong&gt;&lt;br/&gt;&lt;br/&gt;This article isn't intended to explain how to translate (I think that there is a degree at university for it ;) . But may be you should give some tips/explanations to your translators for better results.&lt;br/&gt;&lt;br/&gt;The first thing you should explain them is how to work with some special cases in your strings. Here you have the two mos common examples that they will found:&lt;br/&gt;&lt;code&gt;&lt;br/&gt;"This is normal text, &lt;big&gt;and this one is bigger&lt;/big&gt;"&lt;br/&gt;"Hello %(name)s"&lt;/code&gt;&lt;br/&gt;&lt;br/&gt;Unless you explain them what it means, probably you'll find something like that in you translated string (using Spanish in the example):&lt;br/&gt;&lt;br/&gt;&lt;code&gt;"Este texto es normal, &lt;grande&gt;y  éste es mayor&lt;/grande&gt;"&lt;br/&gt;"Hola %(nombre)s"&lt;/code&gt;&lt;br/&gt;&lt;br/&gt;Of course those translations doesn't generate the expected results, because the correct ones are:&lt;br/&gt;&lt;br/&gt;&lt;code&gt;"Este texto es normal, &lt;big&gt;y  éste es mayor&lt;/big&gt;"&lt;br/&gt;"Hola %(name)s"&lt;/code&gt;&lt;br/&gt;&lt;br/&gt;Another thing that could be clarified, specially if your translator is involved in the Web site that is being translated (or at least knows the context where every string is used), is not to create translations more specific than the original texts.&lt;br/&gt;&lt;br/&gt;For example, imagine that you've in your application a form for personal data, and one of the fields is called "name". Then you translate your application to Catalan, and your translator knows when translating "name", that is used as person name, and translate it as "nom propi" (first name). It will look nicer by now, while being incorrect for me, so later may be you'll add a form where you ask corporate information and you have a field "name" for the company name. You won't send the string "name" to the translator again, and your translation will be incorrect, so "nom propi" (first name) is not valid for the company name.&lt;br/&gt;&lt;br/&gt;&lt;strong&gt;4. Choosing the main language&lt;/strong&gt;&lt;br/&gt;&lt;br/&gt;Sometimes it isn't so obvious  the language your application is written in (I mean the language you use inside gettext strings, or trans/blocktrans tags).&lt;br/&gt;&lt;br/&gt;If you're writing an application that will be used widely in the world, and it will be translated to many languages, probably you think that English should be the right language for it, but in some cases there are some questions to take care on.&lt;br/&gt;- &lt;br/&gt; &lt;li&gt;Will your company have an international team (specially of Django developers)? If you have workers from many countries, probably English will be good for letting all of them write/read from the code.&lt;/li&gt;&lt;br/&gt;   &lt;li&gt;Will your translation team/company use English as it source language? The .po files will show your main language as source for translating string. If you hire a German to French translator, isn't a good idea writing your strings in English, so your/their work will increase a lot, and the reliability of the process will decrease.&lt;/li&gt;&lt;br/&gt;    &lt;li&gt; Are your coders fluent in English? It's more complicated (more work) to change a string from a the main language than from a translation. So if your developers can't write correct English, writing literals in their mother tongue language will save time and work.&lt;/li&gt;&lt;br/&gt;
&lt;br/&gt;Unluckily some times you'll have conflicts in previous questions, and you'll have to choose the lesser evil.&lt;/p&gt;</content><category term="Applications"></category><category term="Django"></category><category term="IT"></category></entry><entry><title>DjangoCon is still alive?</title><link href="https://datapythonista.github.io/blog/djangocon-is-still-alive.html" rel="alternate"></link><published>2008-07-29T19:15:00+01:00</published><updated>2008-07-29T19:15:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2008-07-29:/blog/djangocon-is-still-alive.html</id><summary type="html">&lt;p&gt;On July 13th, DjangoCon 2008 was announced, and the illusion and nervousness started for many djangonauts. The main problem here, is that due to the lack of time and experience, the number of attendees is limited to 200. That makes sense, but there are other things that doesn't make sense …&lt;/p&gt;</summary><content type="html">&lt;p&gt;On July 13th, DjangoCon 2008 was announced, and the illusion and nervousness started for many djangonauts. The main problem here, is that due to the lack of time and experience, the number of attendees is limited to 200. That makes sense, but there are other things that doesn't make sense to me. This post is about that, and it's intended to be a kind of constructive criticism.&lt;br/&gt;&lt;br/&gt;The fact is that many people is waiting to know if he/she can get a ticket to  start planning the trip to SF, ans specially to purchase flight tickets. In those two weeks since DjangoCon announcement, flight prices from Barcelona to SF have increased in a 30%. I don't think it's the only case.&lt;br/&gt;&lt;br/&gt;My question is...  It is so difficult to develop and run an application to register users, letting many djangonauts to save some money that could be given to the DSF? :) Are you coding it in PHP? ;)&lt;br/&gt;&lt;br/&gt;Seriously, if you need help, just ask for it, we are a community. But please, stop delaying ticket releasing, we have to get our tickets, make our plans, and we don't want to waste our money getting last time flight tickets. IMHO ticket realising should be priority #1.&lt;br/&gt;&lt;br/&gt;Finally I want to comment something else here in my blog, that previously submitted to DjangoCon organization. Program isn't closed, and probably this is planned and will be added later, but don't you think that BoF sessions are a must in the DjangoCon? I think that we should take profit of being all togheter, to discuss freely any subject about Django, or any related topic.&lt;/p&gt;</content><category term="Django"></category></entry><entry><title>Django i18n status</title><link href="https://datapythonista.github.io/blog/django-i18n-status.html" rel="alternate"></link><published>2008-07-26T04:11:00+01:00</published><updated>2008-07-26T04:11:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2008-07-26:/blog/django-i18n-status.html</id><summary type="html">&lt;p&gt;Here you have what, from my point of view, is the status of django i18n. Comments will be very welcome, specially from people from countries with other i18n needs than mine (based on the idea that Django i18n is perfect for people in the US, here is the troubleshooting for …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Here you have what, from my point of view, is the status of django i18n. Comments will be very welcome, specially from people from countries with other i18n needs than mine (based on the idea that Django i18n is perfect for people in the US, here is the troubleshooting for my country, for sure more problems exists for people in for example China).&lt;/p&gt;

&lt;p&gt;This list is part of the analysis that I'm doing to fix all those problems. If you want to participate in making Django also "The web framework for perfectionists outside the US", please contact me.&lt;/p&gt;

&lt;table border="0"&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Subject&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;
&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Comments&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Translation (static content)&lt;/td&gt;
&lt;td style="background-color: rgb(127, 255, 0);"&gt;Yes&lt;/td&gt;
&lt;td&gt;Django has an amazing translation system, easy to use, and exceptionally automated. Also it has bidi support. Despite of this, some problems can be found when translating django or applications to other languages (masculine/femenine...).&lt;/td&gt;
&lt;td&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Translation (database content)&lt;/td&gt;
&lt;td style="background-color: rgb(220, 20, 60);"&gt;No&lt;/td&gt;
&lt;td&gt;Django doesn't support model field translation, but it can be achieved using an external application such as [TransDb](http://code.google.com/p/transdb/), [django-multilingual](http://code.google.com/p/django-multilingual/), [django-utils](http://code.google.com/p/django-utils) translation service and [i18ndynamic](http://code.google.com/p/i18ndynamic/). As far as I know only TransDb and django-multilingual are working on Django's trunk.&lt;/td&gt;
&lt;td&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Calendar customization&lt;/td&gt;
&lt;td style="background-color: rgb(220, 20, 60);"&gt;No&lt;/td&gt;
&lt;td&gt;Patching Django is required to change first day of week in admin calendar (first day of week is Monday according to ISO and in many countries (most Europe, most South America, and some parts of Asia). See ticket [#1061](http://code.djangoproject.com/ticket/1061)&lt;/td&gt;
&lt;td&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Date format (when displaying)&lt;/td&gt;
&lt;td style="background-color: rgb(127, 255, 0);"&gt;Yes&lt;/td&gt;
&lt;td&gt;Dates displayed in admin are formatted according to current locale. Also custom dates can be easily formatted using date filter (f.e. {{ my_date|date:_("DATE_FORMAT") }} ).

The problem here, is that few internationalized formats are defined inside django, so using django formats you can internationalize a date with format "December 31th, 2000", but not with format "12/31/2000". It can be achieved creating date formats in your catalog.&lt;/td&gt;
&lt;td&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Date format (on inputs)&lt;/td&gt;
&lt;td style="background-color: rgb(220, 20, 60);"&gt;No&lt;/td&gt;
&lt;td&gt;Django allows specifying one or many input formats for a date form field (using the input_formats parameter of the form field).I think that there is no way to specify the format on the admin fields, specially because the format that generates the calendar is always the same.

Anyway what it's expected is not to specify the format of a field, actually it is to get the format from the current locale.&lt;/td&gt;
&lt;td&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Number format (when displaying)&lt;/td&gt;
&lt;td style="background-color: rgb(220, 20, 60);"&gt;No&lt;/td&gt;
&lt;td&gt;Django has just a filter (floatformat) to format numbers, where you can specify how many decimals you want. It's very difficult to customize your number format, to the format of the current locale, and even to a fixed format.&lt;/td&gt;
&lt;td&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Number format (on input)&lt;/td&gt;
&lt;td style="background-color: rgb(220, 20, 60);"&gt;No&lt;/td&gt;
&lt;td&gt;Django has no way to specify if you want to enter a decimal number with comma separator (dot is always used). Of course it can't be done according to current locale.&lt;/td&gt;
&lt;td&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;</content><category term="Applications"></category><category term="Django"></category><category term="IT"></category></entry><entry><title>TransDb working on trunk!</title><link href="https://datapythonista.github.io/blog/transdb-working-on-trunk.html" rel="alternate"></link><published>2008-05-19T17:31:00+01:00</published><updated>2008-05-19T17:31:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2008-05-19:/blog/transdb-working-on-trunk.html</id><summary type="html">&lt;p&gt;Some days ago, after the merge of qs-rf to trunk, model field i18n was in trouble, so the principal package for this approach (django-multilingual) stopped working for the latest version of trunk.&lt;br/&gt;&lt;br/&gt;This weekend we had a TransDb sprint, to try to improve our project, and contribute to fix this …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Some days ago, after the merge of qs-rf to trunk, model field i18n was in trouble, so the principal package for this approach (django-multilingual) stopped working for the latest version of trunk.&lt;br/&gt;&lt;br/&gt;This weekend we had a TransDb sprint, to try to improve our project, and contribute to fix this situation in any way.&lt;br/&gt;&lt;br/&gt;The result: We fixed many issues on TransDb, now the project has a more conventional structure, and a setup script, and... &lt;strong&gt;TransDb is now working on trunk!&lt;/strong&gt;&lt;br/&gt;&lt;br/&gt;For achieving  it we created a new branch called oldforms.&lt;br/&gt;&lt;br/&gt;&lt;a href="http://code.google.com/p/transdb"&gt;Try it now&lt;/a&gt;!&lt;/p&gt;</content><category term="Applications"></category><category term="Django"></category><category term="IT"></category></entry><entry><title>StdImageField: Improved image field for Django</title><link href="https://datapythonista.github.io/blog/stdimagefield-improved-image-field-for.html" rel="alternate"></link><published>2008-05-17T03:23:00+01:00</published><updated>2008-05-17T03:23:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2008-05-17:/blog/stdimagefield-improved-image-field-for.html</id><summary type="html">&lt;p&gt;I'm pleased to announce a new project, &lt;a href="http://code.google.com/p/django-stdimage/"&gt;django-stdimage&lt;/a&gt;, that provides a new image field with many improvements respect to Django's core ImageField.&lt;br/&gt;&lt;br/&gt;Features of StdImageField:&lt;br/&gt;- &lt;br/&gt;    &lt;li&gt;Saved files have standardized names (using field name and object id)&lt;/li&gt;&lt;br/&gt;  &lt;li&gt;Images can be removed&lt;/li&gt;&lt;br/&gt; &lt;li&gt;Automatically creates a thumbnail&lt;/li&gt;&lt;br/&gt; &lt;li&gt;Automatically resizes both image and thumbnail …&lt;/li&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;I'm pleased to announce a new project, &lt;a href="http://code.google.com/p/django-stdimage/"&gt;django-stdimage&lt;/a&gt;, that provides a new image field with many improvements respect to Django's core ImageField.&lt;br/&gt;&lt;br/&gt;Features of StdImageField:&lt;br/&gt;- &lt;br/&gt;    &lt;li&gt;Saved files have standardized names (using field name and object id)&lt;/li&gt;&lt;br/&gt;  &lt;li&gt;Images can be removed&lt;/li&gt;&lt;br/&gt; &lt;li&gt;Automatically creates a thumbnail&lt;/li&gt;&lt;br/&gt; &lt;li&gt;Automatically resizes both image and thumbnail (with optional crop to fit exactly specified size)&lt;/li&gt;&lt;br/&gt;
&lt;br/&gt;Here you've an example of usage:&lt;br/&gt;&lt;br/&gt;&lt;code&gt;&lt;br/&gt;from django.db import models&lt;br/&gt;from stdimage import StdImageField&lt;/code&gt;&lt;br/&gt;&lt;code&gt;&lt;br/&gt;class MyClass(models.Model):&lt;br/&gt;&amp;nbsp;&amp;nbsp;my_image = StdImageField(upload_to='path/to/img', blank=True, \&lt;br/&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;size=(640, 480), thumbnail_size=(100, 100, True))&lt;/code&gt;&lt;br/&gt;&lt;br/&gt;If a file called "uploaded_file.png" is uploaded for object id 34, then result will be:&lt;br/&gt;- &lt;br/&gt;  &lt;li&gt; /path/to/img/my_image_34.png (with bigger possible size to fit in a 640x480 area)&lt;/li&gt;&lt;br/&gt;    &lt;li&gt;/path/to/img/my_image_34.thumbnail.png (with a exact size of 100x100, cropping if necessary)&lt;/li&gt;&lt;br/&gt;
&lt;br/&gt;Also it will appear a check-box for deleting when using admin.&lt;/p&gt;</content><category term="Applications"></category><category term="Django"></category><category term="IT"></category></entry><entry><title>Adding your Google Code project to Google Analytics</title><link href="https://datapythonista.github.io/blog/adding-your-google-code-project-to.html" rel="alternate"></link><published>2008-05-11T15:35:00+01:00</published><updated>2008-05-11T15:35:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2008-05-11:/blog/adding-your-google-code-project-to.html</id><summary type="html">&lt;p&gt;I know that the post title looks like a dummy tutorial, but actually it's more a bug report.&lt;br/&gt;&lt;br/&gt;In the past I had no problem setting up the Google Analytics tracker for my Google code projects, but I tried it today and it's more complicate due to what like looks …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I know that the post title looks like a dummy tutorial, but actually it's more a bug report.&lt;br/&gt;&lt;br/&gt;In the past I had no problem setting up the Google Analytics tracker for my Google code projects, but I tried it today and it's more complicate due to what like looks to be a bug.&lt;br/&gt;&lt;br/&gt;The problem is when creating a new profile and specifying something like code.google.com/p/myproject as the URL to be tracked, because now, just  domain names without any path are allowed, and n "Invalid input" error is raised.&lt;br/&gt;&lt;br/&gt;The solution is simple if you know it. You can create your profile just with the domain name (code.google.com), and then edit the profile and update profile name and profile url to the correct values (in this page it's allowed).&lt;br/&gt;&lt;br/&gt;I guess that it will be quickly  solved by the Google team, but until then, here you have the tip.&lt;/p&gt;</content><category term="Google"></category><category term="Internet"></category><category term="IT"></category></entry><entry><title>Searching on Django Snippets</title><link href="https://datapythonista.github.io/blog/searching-on-django-snippets.html" rel="alternate"></link><published>2008-05-11T02:24:00+01:00</published><updated>2008-05-11T02:24:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2008-05-11:/blog/searching-on-django-snippets.html</id><summary type="html">&lt;p&gt;One of the key websites about Django is &lt;a href="http://www.djangosnippets.org"&gt;Django Snippets&lt;/a&gt;, by one of the key Django developers, &lt;a href="http://www.b-list.org/"&gt;James Bennett&lt;/a&gt;.&lt;br/&gt;&lt;br/&gt;I've followed many of the James work, and it's awesome; but I've a complaint on Django Snippets. It's the inefficient way to find anything there. The only ways that I've found …&lt;/p&gt;</summary><content type="html">&lt;p&gt;One of the key websites about Django is &lt;a href="http://www.djangosnippets.org"&gt;Django Snippets&lt;/a&gt;, by one of the key Django developers, &lt;a href="http://www.b-list.org/"&gt;James Bennett&lt;/a&gt;.&lt;br/&gt;&lt;br/&gt;I've followed many of the James work, and it's awesome; but I've a complaint on Django Snippets. It's the inefficient way to find anything there. The only ways that I've found is searching using a paginated list by author, language or tag (sorted alphabetically), where you can spend a huge amount of time if the tag you search starts by Z.&lt;br/&gt;&lt;br/&gt;Of course that I can go to Google an search using site:www.djangosnippets.org, and it would work for all indexed snippets, but I think that at least this search box should be added on the site (until anybody writes the &lt;a href="http://www.djangosnippets.org/about/faq/"&gt;generic search engine&lt;/a&gt; for Django).  It would also help adding result page numbers (with links) at the end of the paginated list.&lt;/p&gt;</content><category term="Applications"></category><category term="Django"></category><category term="IT"></category></entry><entry><title>Changing language on the admin</title><link href="https://datapythonista.github.io/blog/changing-language-on-admin.html" rel="alternate"></link><published>2008-05-11T02:08:00+01:00</published><updated>2008-05-11T02:08:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2008-05-11:/blog/changing-language-on-admin.html</id><summary type="html">&lt;p&gt;When working on multilanguage sites, a feature that many times I missed is a direct way to change the language when you're on the admin,&lt;br/&gt;&lt;br/&gt;With standard Django the only way that exists (as far as I know), is leaving the admin, going to the website, change the language there …&lt;/p&gt;</summary><content type="html">&lt;p&gt;When working on multilanguage sites, a feature that many times I missed is a direct way to change the language when you're on the admin,&lt;br/&gt;&lt;br/&gt;With standard Django the only way that exists (as far as I know), is leaving the admin, going to the website, change the language there, and come back to the admin. Not very fast.&lt;br/&gt;&lt;br/&gt;Today, I've created a &lt;a href="http://www.djangosnippets.org/snippets/751/"&gt;snippet&lt;/a&gt; that creates a drop down menu on the admin bar (just in the main page) to change the language.&lt;br/&gt;&lt;br/&gt;Hope it helps.&lt;/p&gt;</content><category term="Applications"></category><category term="Django"></category><category term="IT"></category></entry><entry><title>DSNP 0.9 released</title><link href="https://datapythonista.github.io/blog/dsnp-09-released.html" rel="alternate"></link><published>2008-05-10T04:39:00+01:00</published><updated>2008-05-10T04:39:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2008-05-10:/blog/dsnp-09-released.html</id><summary type="html">&lt;p&gt;I know that it was just few days ago that I released another version of DSNP, but because of it, I got a lot of feedback on it, I worked hard, and finally DSNP is stable.&lt;br/&gt;&lt;br/&gt;For now, it'll be 0.9 because it works on Django newforms-admin branch, so …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I know that it was just few days ago that I released another version of DSNP, but because of it, I got a lot of feedback on it, I worked hard, and finally DSNP is stable.&lt;br/&gt;&lt;br/&gt;For now, it'll be 0.9 because it works on Django newforms-admin branch, so 1.0 will be reached when newforms-admin will be merged into trunk.&lt;br/&gt;&lt;br/&gt;Changeset for this version is next:&lt;br/&gt;- &lt;br/&gt;  &lt;li&gt;Generated sqlite file has write permissions for all users by default&lt;/li&gt;&lt;br/&gt;  &lt;li&gt;Static files are served by Django http server on development environment (DEBUG==True)&lt;/li&gt;&lt;br/&gt;    &lt;li&gt;File admin.py created to specify admin options&lt;/li&gt;&lt;br/&gt;    &lt;li&gt;Media path has changed (now, all static files are under "media" directory) due to an &lt;a href="http://vaig.be/2008/05/09/unable-to-define-my-urls-exactly-my-way-resignation-statement/"&gt;issue&lt;/a&gt;&lt;/li&gt;&lt;br/&gt;
&lt;br/&gt;I hope you like it.&lt;/p&gt;</content><category term="Applications"></category><category term="Django"></category><category term="IT"></category></entry><entry><title>Unable to define my urls exactly my way (resignation statement)</title><link href="https://datapythonista.github.io/blog/unable-to-define-my-urls-exactly-my-way.html" rel="alternate"></link><published>2008-05-09T19:44:00+01:00</published><updated>2008-05-09T19:44:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2008-05-09:/blog/unable-to-define-my-urls-exactly-my-way.html</id><summary type="html">&lt;p&gt;I've been working with Django for a while, and it helped me to get all my web developments with nice urls. But I also wanted a nice url structure...&lt;br/&gt;&lt;br/&gt;What it is nice for me, opposite to Django default settings, is avoiding the media prefix on my media urls, so …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I've been working with Django for a while, and it helped me to get all my web developments with nice urls. But I also wanted a nice url structure...&lt;br/&gt;&lt;br/&gt;What it is nice for me, opposite to Django default settings, is avoiding the media prefix on my media urls, so&lt;br/&gt;&lt;br/&gt;http://localhost/media/admin/css/login.css would be http://localhost/admin/css/login.cssTrying to emulate old website structures (used widely in php sites).&lt;br/&gt;&lt;br/&gt;That could be nice or not, but for sure it is complicated.&lt;br/&gt;&lt;br/&gt;The first step was to setup apache for it, a little bit more complicated than the usual setup, but possible:&lt;br/&gt;&lt;br/&gt;&lt;LocationMatch "/((css|js|img|swf|pdf)/|favicon.ico)"&gt;&lt;br/&gt;SetHandler None&lt;br/&gt;&lt;/LocationMatch&gt;&lt;br/&gt;&lt;br/&gt;The main problem comes when using Django development http server (started by "python manage.py runserver"), and the admin. Of course you can do that, but what is not possible, is to define the same name for your admin media path, and for the admin itself.&lt;br/&gt;&lt;br/&gt;For example:&lt;br/&gt;&lt;br/&gt;http://localhost/admin and http://localhost/admin/css/login.css&lt;br/&gt;&lt;br/&gt;The reason is the Django web server, processes all requests starting with the ADMIN_MEDIA_PREFIX setting with the AdminMediaHandler, what implies with that structure that all admin requests (even the ones that aren't static files) are processed by this handler, raising an error when the request isn't for a static file. The error is next.&lt;br/&gt;&lt;br/&gt;Permission denied: ${PYTHON_PATH}/django/contrib/admin/media/&lt;br/&gt;&lt;br/&gt;So this is my resignation statement to do what I wanted to do initially. Now, options are:&lt;br/&gt;- &lt;br/&gt;   &lt;li&gt;Don't use the Django http server (use apache even for development)&lt;/li&gt;&lt;br/&gt;    &lt;li&gt;Keep the same structure but change the admin media directory (for example from "admin" to "admin-media"&lt;/li&gt;&lt;br/&gt;   &lt;li&gt;Use the "media" (or any other name) prefix&lt;/li&gt;&lt;br/&gt;
&lt;br/&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; Current version of my project DSNP is affected by this issue. I'll solve it asap.&lt;/p&gt;</content><category term="Applications"></category><category term="Django"></category><category term="IT"></category></entry><entry><title>New DSNP version</title><link href="https://datapythonista.github.io/blog/new-dsnp-version.html" rel="alternate"></link><published>2008-05-07T03:46:00+01:00</published><updated>2008-05-07T03:46:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2008-05-07:/blog/new-dsnp-version.html</id><summary type="html">&lt;p&gt;&lt;a href="http://code.google.com/p/dsnp/"&gt;DSNP&lt;/a&gt; is a simple and customizable Python script, that automatically creates a working Django project.&lt;br/&gt;&lt;br/&gt;Project (and application) creation in Django are very openend and flexible, but sometimes is useful getting all the work done for you, specially:&lt;br/&gt;- &lt;br/&gt;  &lt;li&gt;If you create many Django projects with the same structure.&lt;/li&gt;&lt;br/&gt;   &lt;li&gt;If you're …&lt;/li&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="http://code.google.com/p/dsnp/"&gt;DSNP&lt;/a&gt; is a simple and customizable Python script, that automatically creates a working Django project.&lt;br/&gt;&lt;br/&gt;Project (and application) creation in Django are very openend and flexible, but sometimes is useful getting all the work done for you, specially:&lt;br/&gt;- &lt;br/&gt;  &lt;li&gt;If you create many Django projects with the same structure.&lt;/li&gt;&lt;br/&gt;   &lt;li&gt;If you're new to Python, and want to see a "hello world!"  application working in less than one minute.&lt;/li&gt;&lt;br/&gt;   &lt;li&gt;If you want to check your Django structure with somebody's else (me).&lt;/li&gt;&lt;br/&gt;
&lt;br/&gt;DSNP does exactly that, automates the process of creating projects and applications in Django. The resulting website is a simple project with a single application, ready for start creating models and templates. It's also customizable, to let everyone set their own preferences in the script, and adapt it to your desired structure.&lt;br/&gt;&lt;br/&gt;Want to try it (in five simple steps)?&lt;br/&gt;&lt;br/&gt;&lt;em&gt;svn checkout http://dsnp.googlecode.com/svn/trunk/&lt;/em&gt;&lt;br/&gt;&lt;em&gt;python dsnp.py myproject&lt;/em&gt;&lt;br/&gt;&lt;em&gt;cd myproject&lt;/em&gt;&lt;br/&gt;&lt;em&gt;python manage.py runserver&lt;/em&gt;&lt;br/&gt;&lt;em&gt;Browse &lt;a href="http://localhost:8000/"&gt;http://localhost:8000/ &lt;/a&gt;&lt;/em&gt;&lt;br/&gt;&lt;br/&gt;Easy right?&lt;/p&gt;</content><category term="Applications"></category><category term="Django"></category><category term="IT"></category></entry><entry><title>Django L10n</title><link href="https://datapythonista.github.io/blog/django-l10n.html" rel="alternate"></link><published>2008-04-29T02:22:00+01:00</published><updated>2008-04-29T02:22:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2008-04-29:/blog/django-l10n.html</id><summary type="html">&lt;p&gt;This Sunday, I participated in &lt;a href="http://blog.michaeltrier.com/2008/4/28/this-week-in-django-20-2008-04-27"&gt;This Week in Django&lt;/a&gt;, and tried to give some ideas on Django localization.&lt;br/&gt;&lt;br/&gt;Here I'll post some of the ideas of the interview (and some that I missed), for serving as reference:&lt;br/&gt;&lt;br/&gt;&lt;strong&gt;How to translate your application (quick guide):&lt;/strong&gt;&lt;br/&gt;- &lt;br/&gt;  &lt;li&gt;Mark every text in your application …&lt;/li&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;This Sunday, I participated in &lt;a href="http://blog.michaeltrier.com/2008/4/28/this-week-in-django-20-2008-04-27"&gt;This Week in Django&lt;/a&gt;, and tried to give some ideas on Django localization.&lt;br/&gt;&lt;br/&gt;Here I'll post some of the ideas of the interview (and some that I missed), for serving as reference:&lt;br/&gt;&lt;br/&gt;&lt;strong&gt;How to translate your application (quick guide):&lt;/strong&gt;&lt;br/&gt;- &lt;br/&gt;  &lt;li&gt;Mark every text in your application for translation:&lt;br/&gt;&lt;ul&gt;&lt;br/&gt;  &lt;li&gt;In models.py, views.py... convert  &lt;em&gt;'my text in just one language'&lt;/em&gt; to &lt;em&gt;&lt;em&gt;('my text to translate')&lt;/em&gt;. Don't forget to import &lt;/em&gt;: f&lt;em&gt;rom django.utils.translation import ugettext_lazy as _&lt;/em&gt;&lt;/li&gt;&lt;br/&gt;  &lt;li&gt;In templates, convert &lt;em&gt;&lt;p&gt;Text in english&lt;/p&gt;&lt;/em&gt; to &lt;em&gt;&lt;p&gt;{% trans 'Text in many languages' %}&lt;/p&gt;&lt;/em&gt; (also this can be done with blocktrans tag)&lt;/li&gt;&lt;br/&gt;
&lt;br/&gt;&lt;/li&gt;&lt;br/&gt; &lt;li&gt;Go to your project path and create a directory called locale (also you can do that just for an application)&lt;/li&gt;&lt;br/&gt;   &lt;li&gt;Execute ${PATH_TO_DJANGO}/bin/make-messages -l ${LANGUAGE_CODE} (where language code is en for english, es for spanish...)&lt;/li&gt;&lt;br/&gt;    &lt;li&gt;Edit ${PROJECT_PATH}/locale/${LANGUAGE_CODE}/LC_MESSAGES/django.po and set the &lt;em&gt;msgstr&lt;/em&gt; variables with the translation of every &lt;em&gt;msgid&lt;/em&gt;&lt;/li&gt;&lt;br/&gt; &lt;li&gt;Run msgfmt django.po -o django.mo (I just realized after the interview that exists a django script complie-messages.py that does that for all .po files)&lt;/li&gt;&lt;br/&gt;  &lt;li&gt;And then you have your application translated. There are some settings in settings.py that need to be set for making it work (USE_I18N = True, set LANGUAGES and LANGUAGE_CODE, and specify the django.middleware.locale.LocaleMiddleware middleware)&lt;/li&gt;&lt;br/&gt; &lt;li&gt;Then probably you'll want to have your select input with all available languages (or something like that). For it you'll have to add &lt;em&gt;(r'^i18n/', include('django.conf.urls.i18n'))&lt;/em&gt; to your urls.py, and from your html send a POST request to &lt;em&gt;/i18n/setlang&lt;/em&gt; with the parameter &lt;em&gt;language&lt;/em&gt; set to desired language code&lt;/li&gt;&lt;br/&gt;   &lt;li&gt;For more stuff, and detailed information check: &lt;a href="http://www.djangoproject.com/documentation/i18n/"&gt;http://www.djangoproject.com/documentation/i18n/&lt;/a&gt;&lt;/li&gt;&lt;br/&gt;&lt;/ul&gt;&lt;br/&gt;&lt;strong&gt;Things that IMHO should be improved in Django for a better L10n expirience:&lt;/strong&gt;&lt;br/&gt;- &lt;br/&gt;    &lt;li&gt;Move localflavors outside trunk (to avoid unnecessary translation costs). Every localflavor should come with necessary translations.&lt;/li&gt;&lt;br/&gt;  &lt;li&gt;Create locale settings (besides translations), to set decimal symbol, date and time format, first day of week... and use it automatically for current locale/language.&lt;br/&gt;&lt;ul&gt;&lt;br/&gt;    &lt;li&gt;Check tickets &lt;a href="http://code.djangoproject.com/ticket/1061"&gt;#1061&lt;/a&gt;, &lt;a href="http://code.djangoproject.com/ticket/3940"&gt;#3940&lt;/a&gt; and &lt;a href="http://code.djangoproject.com/ticket/6783"&gt;#6783&lt;/a&gt; that gives different approaches to this problem.&lt;/li&gt;&lt;br/&gt;
&lt;br/&gt;&lt;/li&gt;&lt;br/&gt; &lt;li&gt;Create translatable CharFields and TextFields. For now &lt;a href="http://code.google.com/p/django-multilingual/"&gt;django-multilingual&lt;/a&gt; and &lt;a href="http://code.google.com/p/transdb/"&gt;transdb&lt;/a&gt; can be used for it.&lt;/li&gt;&lt;br/&gt;  &lt;li&gt;Adding something to select the language in admin (when more than one is available).&lt;/li&gt;&lt;br/&gt;   &lt;li&gt;Haven't checked it too much, but it'll be good if urls could be translated as well.&lt;/li&gt;&lt;br/&gt;&lt;/ul&gt;&lt;br/&gt;Finally I want to thank for letting me participate in TWID to &lt;a href="http://blog.michaeltrier.com"&gt;Michael Trier&lt;/a&gt;, who is a father, husband, software architect, entrepreneur, a great journalist, and a better person. And also to &lt;a href="http://www.pointy-stick.com/blog/"&gt;Malcolm Tredinnick&lt;/a&gt;, who recommended me to the show (not sure if I deserved the honour), and for his unpayable help and support on my Django work.&lt;/p&gt;</content><category term="Applications"></category><category term="Django"></category><category term="IT"></category></entry><entry><title>New Accopensys website</title><link href="https://datapythonista.github.io/blog/new-accopensys-website.html" rel="alternate"></link><published>2008-04-25T04:31:00+01:00</published><updated>2008-04-25T04:31:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2008-04-25:/blog/new-accopensys-website.html</id><summary type="html">&lt;p&gt;Today, I'm proud to announce the new version of the &lt;a href="http://www.accopensys.com"&gt;Accopensys website&lt;/a&gt;. There is still many work to do, but finally this latest version has been published.&lt;br/&gt;&lt;br/&gt;Main changes are next:&lt;br/&gt;- &lt;br/&gt;    &lt;li&gt;Website is now running on Django&lt;/li&gt;&lt;br/&gt;  &lt;li&gt;Design has been updated&lt;/li&gt;&lt;br/&gt;   &lt;li&gt;Sections and texts have been rewritten to fit new …&lt;/li&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;Today, I'm proud to announce the new version of the &lt;a href="http://www.accopensys.com"&gt;Accopensys website&lt;/a&gt;. There is still many work to do, but finally this latest version has been published.&lt;br/&gt;&lt;br/&gt;Main changes are next:&lt;br/&gt;- &lt;br/&gt;    &lt;li&gt;Website is now running on Django&lt;/li&gt;&lt;br/&gt;  &lt;li&gt;Design has been updated&lt;/li&gt;&lt;br/&gt;   &lt;li&gt;Sections and texts have been rewritten to fit new business strategies&lt;/li&gt;&lt;br/&gt;&lt;/p&gt;</content><category term="IT"></category></entry><entry><title>Django Catalan usergroup meeting</title><link href="https://datapythonista.github.io/blog/django-catalan-usergroup-meeting.html" rel="alternate"></link><published>2008-04-01T04:43:00+01:00</published><updated>2008-04-01T04:43:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2008-04-01:/blog/django-catalan-usergroup-meeting.html</id><summary type="html">&lt;p&gt;Six months ago, I decided to create the &lt;a href="http://groups.google.com/group/django-cat"&gt;Django Catalan usergroup&lt;/a&gt;, for user in &lt;a href="http://en.wikipedia.org/wiki/Catalonia"&gt;Catalonia&lt;/a&gt;, and for users who speak &lt;a href="http://en.wikipedia.org/wiki/Catalan_language"&gt;catalan&lt;/a&gt;.&lt;br/&gt;&lt;br/&gt;Today I'm happy to announce that we are already 26 members, and we are going to have our first meeting on April 3rd. We've decided to meet together with …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Six months ago, I decided to create the &lt;a href="http://groups.google.com/group/django-cat"&gt;Django Catalan usergroup&lt;/a&gt;, for user in &lt;a href="http://en.wikipedia.org/wiki/Catalonia"&gt;Catalonia&lt;/a&gt;, and for users who speak &lt;a href="http://en.wikipedia.org/wiki/Catalan_language"&gt;catalan&lt;/a&gt;.&lt;br/&gt;&lt;br/&gt;Today I'm happy to announce that we are already 26 members, and we are going to have our first meeting on April 3rd. We've decided to meet together with people from &lt;a href="http://python.meetup.com/185/"&gt;The Barcelona Python Meetup Group&lt;/a&gt;, so both groups have common interests, and many people in common.&lt;br/&gt;&lt;br/&gt;Our planning is having some talks on key subjects such as "Django presentation to non-Django users", "Django status", "Django i18n", "Python 3k"... as well as lightning talks from everybody, to share personal or professional experience with Python/Django. We'll also discuss about organizing a conference in Barcelona, and about the Django-Rails football (aka soccer) match.&lt;br/&gt;&lt;br/&gt;If you are in Barcelona on 3rd, and you want to join us, here you have details (remember that attendance confirmation is required one day before the event):&lt;br/&gt;&lt;br/&gt;&lt;a href="http://python.meetup.com/185/calendar/7640211/"&gt;http://python.meetup.com/185/calendar/7640211/&lt;/a&gt;&lt;br/&gt;&lt;br/&gt;See you there!&lt;/p&gt;</content><category term="Django"></category></entry><entry><title>MySQL and encoding</title><link href="https://datapythonista.github.io/blog/mysql-and-encoding.html" rel="alternate"></link><published>2008-03-27T21:14:00+00:00</published><updated>2008-03-27T21:14:00+00:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2008-03-27:/blog/mysql-and-encoding.html</id><summary type="html">&lt;p&gt;Today I had &lt;strong&gt;another&lt;/strong&gt; encoding problem in my life...&lt;br/&gt;&lt;br/&gt;I had a file with sql inserts, encoded with utf-8. My unix terminal, also encoded with utf-8. I had a database as well, and both database and tables encoded with utf-8.&lt;br/&gt;&lt;br/&gt;My problem: when executing my sql file to my database …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Today I had &lt;strong&gt;another&lt;/strong&gt; encoding problem in my life...&lt;br/&gt;&lt;br/&gt;I had a file with sql inserts, encoded with utf-8. My unix terminal, also encoded with utf-8. I had a database as well, and both database and tables encoded with utf-8.&lt;br/&gt;&lt;br/&gt;My problem: when executing my sql file to my database, the data encoding was corrupted. There were just one missing piece not encoded with utf-8, MySQL terminal.&lt;br/&gt;&lt;br/&gt;To fix it: &lt;strong&gt;mysql -u myuser --default_character_set utf8 mydatabase &amp;lt; myfile&lt;/strong&gt;&lt;/p&gt;</content><category term="IT"></category></entry><entry><title>TransDb: Pretty much easier</title><link href="https://datapythonista.github.io/blog/transdb-pretty-much-easier.html" rel="alternate"></link><published>2008-03-06T19:49:00+00:00</published><updated>2008-03-06T19:49:00+00:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2008-03-06:/blog/transdb-pretty-much-easier.html</id><summary type="html">&lt;p&gt;Today I've released a new version of TransDb, the Django package that allows storing text at database in more than one language (using the same field).&lt;br/&gt;&lt;br/&gt;New version is pretty much easier to use, after fixing many bugs, and avoiding the use of a filter in templates.&lt;br/&gt;&lt;br/&gt;Now, migrating your …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Today I've released a new version of TransDb, the Django package that allows storing text at database in more than one language (using the same field).&lt;br/&gt;&lt;br/&gt;New version is pretty much easier to use, after fixing many bugs, and avoiding the use of a filter in templates.&lt;br/&gt;&lt;br/&gt;Now, migrating your single-language application to a multi-language one is very easy, so almost the only thing you've to do is changing your model fields (no data transformation is required, it is done automatically when you translate texts at admin). A full migration procedure is available at project page.&lt;br/&gt;&lt;br/&gt;You can find everything at &lt;a href="http://code.google.com/p/transdb"&gt;Google's project page&lt;/a&gt;.&lt;/p&gt;</content><category term="Applications"></category><category term="Django"></category><category term="IT"></category></entry><entry><title>Media data without media directory</title><link href="https://datapythonista.github.io/blog/media-data-without-media-directory.html" rel="alternate"></link><published>2008-01-17T16:13:00+00:00</published><updated>2008-01-17T16:13:00+00:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2008-01-17:/blog/media-data-without-media-directory.html</id><summary type="html">&lt;p&gt;It's not a big trouble, but I wanted to remove the /media/ prefix on all my media links, like...&lt;br/&gt;&lt;br/&gt;&lt;code&gt;&lt;br/&gt;&lt;img alt="My Image" src="/media/img/myimage.png"/&gt;&lt;br/&gt;&lt;link rel="stylesheet" href="/media/css/mysheet.css" type="text/css"/&gt;&lt;br/&gt;&lt;/code&gt;&lt;br/&gt;&lt;br/&gt;and so on.&lt;br/&gt;&lt;br/&gt;This can be easily achieved by replacing in apache's configuration file:&lt;br/&gt;&lt;br/&gt;&lt;code&gt;&lt;br/&gt;&lt;Location "/media/"&gt;&lt;br/&gt;SetHandler None&lt;br/&gt;&lt;/LocationMatch&gt;&lt;br/&gt;&lt;/code&gt;&lt;br/&gt;&lt;br/&gt;by&lt;br/&gt;&lt;br/&gt;&lt;code&gt;&lt;br/&gt;&lt;LocationMatch "/((css|js|img|swf|pdf)/|favicon.ico)"&gt;&lt;br/&gt;SetHandler None&lt;br/&gt;&lt;/LocationMatch&gt;&lt;br/&gt;&lt;/code&gt;&lt;br/&gt;&lt;br/&gt;Of course you have to have all you media files in folders …&lt;/p&gt;</summary><content type="html">&lt;p&gt;It's not a big trouble, but I wanted to remove the /media/ prefix on all my media links, like...&lt;br/&gt;&lt;br/&gt;&lt;code&gt;&lt;br/&gt;&lt;img alt="My Image" src="/media/img/myimage.png"/&gt;&lt;br/&gt;&lt;link rel="stylesheet" href="/media/css/mysheet.css" type="text/css"/&gt;&lt;br/&gt;&lt;/code&gt;&lt;br/&gt;&lt;br/&gt;and so on.&lt;br/&gt;&lt;br/&gt;This can be easily achieved by replacing in apache's configuration file:&lt;br/&gt;&lt;br/&gt;&lt;code&gt;&lt;br/&gt;&lt;Location "/media/"&gt;&lt;br/&gt;SetHandler None&lt;br/&gt;&lt;/LocationMatch&gt;&lt;br/&gt;&lt;/code&gt;&lt;br/&gt;&lt;br/&gt;by&lt;br/&gt;&lt;br/&gt;&lt;code&gt;&lt;br/&gt;&lt;LocationMatch "/((css|js|img|swf|pdf)/|favicon.ico)"&gt;&lt;br/&gt;SetHandler None&lt;br/&gt;&lt;/LocationMatch&gt;&lt;br/&gt;&lt;/code&gt;&lt;br/&gt;&lt;br/&gt;Of course you have to have all you media files in folders like css, js, img... or anything that you specify in last regular expression.&lt;br/&gt;&lt;br/&gt;&lt;strong&gt;UPDATE:&lt;/strong&gt; See this &lt;a href="http://vaig.be/2008/05/09/unable-to-define-my-urls-exactly-my-way-resignation-statement/"&gt;post&lt;/a&gt; before using this approach.&lt;/p&gt;</content><category term="Applications"></category><category term="Django"></category><category term="IT"></category></entry><entry><title>Normalize name and size images in Django (and adding thumbnails)</title><link href="https://datapythonista.github.io/blog/normalize-name-and-size-images-in.html" rel="alternate"></link><published>2007-12-10T01:19:00+00:00</published><updated>2007-12-10T01:19:00+00:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2007-12-10:/blog/normalize-name-and-size-images-in.html</id><summary type="html">&lt;p&gt;I wanted to assign an image to every element in a model. I wanted them to have a thumbnail, and to have normalized sizes and names. And of course, I want my application to do everything automatically.&lt;br/&gt;&lt;br/&gt;The best method I've found is next, modifying models.py (note that PIL …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I wanted to assign an image to every element in a model. I wanted them to have a thumbnail, and to have normalized sizes and names. And of course, I want my application to do everything automatically.&lt;br/&gt;&lt;br/&gt;The best method I've found is next, modifying models.py (note that PIL must be installed):&lt;br/&gt;&lt;code style="text-align: left"&gt;&lt;br/&gt;def rename_image(src, field, id):&lt;br/&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;file_ext = os.path.splitext(src)[1].lower().replace('jpg', 'jpeg')&lt;br/&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;dst = 'img/uploaded/work_%s/%s_%s%s' % (field, field, id, file_ext)&lt;br/&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;return dst&lt;br/&gt;&lt;/code&gt;&lt;br/&gt;&lt;br/&gt;&lt;code style="text-align: left"&gt;&lt;br/&gt;def resize_image(src, dst, size):&lt;br/&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;from PIL import Image&lt;br/&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;image = Image.open(src)&lt;br/&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;image.thumbnail(size, Image.ANTIALIAS)&lt;br/&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;image.save('%s%s' % (settings.MEDIA_ROOT, dst))&lt;br/&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;return dst&lt;br/&gt;&lt;/code&gt;&lt;br/&gt;&lt;br/&gt;&lt;code style="text-align: left"&gt;&lt;br/&gt;class MyModel(models.Model):&lt;br/&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;image = models.ImageField(upload_to='img/uploaded/work_image', verbose_name=_('imagen'))&lt;br/&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;thumbnail = models.ImageField(editable=False, upload_to='img/uploaded/work_thumbnail')&lt;br/&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;[...]&lt;br/&gt;&lt;/code&gt;&lt;br/&gt;&lt;br/&gt;&lt;code style="text-align: left"&gt;&lt;br/&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;def save(self):&lt;br/&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;super(MyModel, self).save()&lt;br/&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;if self.image != rename_image(self.image, 'image', self.id):&lt;br/&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;original_filename = self.get_image_filename()&lt;br/&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;self.thumbnail = resize_image(original_filename, rename_image(original_filename, 'thumbnail', self.id), [100, 75])&lt;br/&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;self.image = resize_image(original_filename, rename_image(original_filename, 'image', self.id), [640, 480])&lt;br/&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;if os.path.exists(original_filename):&lt;br/&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;os.remove(original_filename)&lt;br/&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;super(MyModel, self).save()&lt;br/&gt;&lt;/code&gt;&lt;/p&gt;</content><category term="Applications"></category><category term="Django"></category><category term="IT"></category></entry><entry><title>TransDb: Django’s i18n for database</title><link href="https://datapythonista.github.io/blog/transdb-djangos-i18n-for-database.html" rel="alternate"></link><published>2007-12-08T07:15:00+00:00</published><updated>2007-12-08T07:15:00+00:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2007-12-08:/blog/transdb-djangos-i18n-for-database.html</id><summary type="html">&lt;p&gt;Today I've created my own code for having (in Django) fields in more than one language stored in database. There were some other packages, but none of them useful for me (as commented &lt;a href="http://vaig.be/2007/07/11/django-database-texts-translated/"&gt;here&lt;/a&gt;).&lt;br/&gt;&lt;br/&gt;TransDb's main goal is that is simple, for application users, application programmers, and the code itself …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Today I've created my own code for having (in Django) fields in more than one language stored in database. There were some other packages, but none of them useful for me (as commented &lt;a href="http://vaig.be/2007/07/11/django-database-texts-translated/"&gt;here&lt;/a&gt;).&lt;br/&gt;&lt;br/&gt;TransDb's main goal is that is simple, for application users, application programmers, and the code itself. Some work is still missing, but there is a working version at &lt;a href="http://code.google.com/p/transdb/"&gt;TransDb Google Code page&lt;/a&gt;.&lt;br/&gt;&lt;br/&gt;Any comment will be appreciate.&lt;/p&gt;</content><category term="Applications"></category><category term="Django"></category><category term="IT"></category></entry><entry><title>Django is “order sensitive”</title><link href="https://datapythonista.github.io/blog/django-is-order-sensitive.html" rel="alternate"></link><published>2007-11-14T00:21:00+00:00</published><updated>2007-11-14T00:21:00+00:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2007-11-14:/blog/django-is-order-sensitive.html</id><summary type="html">&lt;p&gt;Sometimes I forget that django's settings.py is a Python script, and not a plain configuration file. And forgetting it causes django to behave unexpectedly. A couple of examples that happened to are related to array sorting.&lt;br/&gt;&lt;br/&gt;Some days ago I customized middleware classes, and after that I left on …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Sometimes I forget that django's settings.py is a Python script, and not a plain configuration file. And forgetting it causes django to behave unexpectedly. A couple of examples that happened to are related to array sorting.&lt;br/&gt;&lt;br/&gt;Some days ago I customized middleware classes, and after that I left on my setting.py:&lt;br/&gt;&lt;br/&gt;MIDDLEWARE_CLASSES = (&lt;br/&gt;'django.middleware.locale.LocaleMiddleware',&lt;br/&gt;'django.contrib.sessions.middleware.SessionMiddleware',&lt;br/&gt;'django.contrib.auth.middleware.AuthenticationMiddleware',&lt;br/&gt;'django.middleware.doc.XViewMiddleware',&lt;br/&gt;'django.middleware.common.CommonMiddleware',&lt;br/&gt;)&lt;br/&gt;&lt;br/&gt;With it, LocaleMiddleware doesn't work, because it requires SessionMiddleware that isn't loaded when LocaleMiddleware is executed.&lt;br/&gt;&lt;br/&gt;Today's issue was something similar, but with templates. I customized some admin templates, copying them to a directory loaded with filesystem loader. My settings.py looked like:&lt;br/&gt;&lt;br/&gt;TEMPLATE_LOADERS = (&lt;br/&gt;'django.template.loaders.app_directories.load_template_source',&lt;br/&gt;'django.template.loaders.filesystem.load_template_source',&lt;br/&gt;)&lt;br/&gt;&lt;br/&gt;With it, loaders looked first to application template directories, including the admin ones, so overriding template was never used.&lt;/p&gt;</content><category term="Applications"></category><category term="Django"></category><category term="IT"></category></entry><entry><title>Common web features in Django</title><link href="https://datapythonista.github.io/blog/common-web-features-in-django.html" rel="alternate"></link><published>2007-11-11T02:30:00+00:00</published><updated>2007-11-11T02:30:00+00:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2007-11-11:/blog/common-web-features-in-django.html</id><summary type="html">&lt;p&gt;Here is a brief list of common web features, and the best way I know for achieving it in Django:&lt;br/&gt;- &lt;br/&gt;    &lt;li&gt;&lt;strong&gt;Breadcrumbs:&lt;/strong&gt; use {{ block.super }} for recursive link inheritance [&lt;a href="http://www.martin-geber.com/weblog/2007/10/25/breadcrumbs-django-templates/"&gt;more info&lt;/a&gt;]&lt;/li&gt;&lt;br/&gt; &lt;li&gt;&lt;strong&gt;Back button:&lt;/strong&gt; use {{ request.META.HTTP_REFERER }} for linking to referring URL&lt;em&gt;&lt;/li&gt;&lt;br/&gt;   &lt;li&gt;&lt;strong&gt;Highlight active menu option:&lt;/strong&gt; use {{ request.path }} to know …&lt;/li&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;Here is a brief list of common web features, and the best way I know for achieving it in Django:&lt;br/&gt;- &lt;br/&gt;    &lt;li&gt;&lt;strong&gt;Breadcrumbs:&lt;/strong&gt; use {{ block.super }} for recursive link inheritance [&lt;a href="http://www.martin-geber.com/weblog/2007/10/25/breadcrumbs-django-templates/"&gt;more info&lt;/a&gt;]&lt;/li&gt;&lt;br/&gt; &lt;li&gt;&lt;strong&gt;Back button:&lt;/strong&gt; use {{ request.META.HTTP_REFERER }} for linking to referring URL&lt;em&gt;&lt;/li&gt;&lt;br/&gt;   &lt;li&gt;&lt;strong&gt;Highlight active menu option:&lt;/strong&gt; use {{ request.path }} to know requested URL and compare it with menu options * [&lt;a href="http://gnuvince.wordpress.com/2007/09/14/a-django-template-tag-for-the-current-active-page/"&gt;more info&lt;/a&gt;]&lt;/li&gt;&lt;br/&gt; &lt;li&gt;&lt;strong&gt;Pagination:&lt;/strong&gt; use 'django.views.generic.list_detail.object_list' generic view [&lt;a href="http://www.djangoproject.com/documentation/generic_views/#django-views-generic-list-detail-object-list"&gt;more info&lt;/a&gt;]&lt;/li&gt;&lt;br/&gt;
&lt;br/&gt;&lt;/em&gt; it's needed to add 'request' module to &lt;a href="http://www.djangoproject.com/documentation/settings/#template-context-processors"&gt;TEMPLATE_CONTEXT_PROCESSORS&lt;/a&gt; on settings.py&lt;/p&gt;</content><category term="Applications"></category><category term="Django"></category><category term="IT"></category></entry><entry><title>The Gambia countdown</title><link href="https://datapythonista.github.io/blog/gambia-countdown.html" rel="alternate"></link><published>2007-11-08T04:01:00+00:00</published><updated>2007-11-08T04:01:00+00:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2007-11-08:/blog/gambia-countdown.html</id><summary type="html">&lt;p&gt;In less than two weeks I'll go back to The Gambia, this time with two friends.&lt;br/&gt;&lt;br/&gt;Flight information is next:&lt;br/&gt;&lt;br/&gt;Barcelona -&amp;gt; Banjul (Flight  JK202, departing on Nov 20th at 18:45, arriving at 22:50)&lt;br/&gt;&lt;br/&gt;Banjul -&amp;gt; Barcelona (Flight JK203, departing on Nov 27th at 23:50, arriving at 5:40 …&lt;/p&gt;</summary><content type="html">&lt;p&gt;In less than two weeks I'll go back to The Gambia, this time with two friends.&lt;br/&gt;&lt;br/&gt;Flight information is next:&lt;br/&gt;&lt;br/&gt;Barcelona -&amp;gt; Banjul (Flight  JK202, departing on Nov 20th at 18:45, arriving at 22:50)&lt;br/&gt;&lt;br/&gt;Banjul -&amp;gt; Barcelona (Flight JK203, departing on Nov 27th at 23:50, arriving at 5:40 on  next day)&lt;br/&gt;&lt;br/&gt;There, we'll spend some days in Brikama, and I'll go around in the country.&lt;/p&gt;</content><category term="Personal"></category></entry><entry><title>Learning Chinese (你好 汉语)</title><link href="https://datapythonista.github.io/blog/learning-chinese.html" rel="alternate"></link><published>2007-10-31T02:53:00+00:00</published><updated>2007-10-31T02:53:00+00:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2007-10-31:/blog/learning-chinese.html</id><summary type="html">&lt;p&gt;Some weeks ago I started learning Chinese. Here I want to post some useful resources in the Internet that can help.&lt;br/&gt;- &lt;br/&gt; &lt;li&gt;&lt;a href="http://www.nciku.com/"&gt;Nciku&lt;/a&gt;: dictionary, character drawing recognition, and word listening.&lt;/li&gt;&lt;br/&gt;    &lt;li&gt;&lt;a href="http://www.pinyin.clever-industries.com/"&gt;Pinyin talker&lt;/a&gt;: just that :)&lt;/li&gt;&lt;br/&gt;   &lt;li&gt;&lt;a href="http://www.mandarintools.com/worddict.html"&gt;Mandarin tools&lt;/a&gt;: word translation&lt;/li&gt;&lt;br/&gt;    &lt;li&gt;&lt;a href="http://www.newconceptmandarin.com/support/Intro_Pinyin.asp"&gt;New concept mandarin&lt;/a&gt;: compose and listen words, very interesting...&lt;/li&gt;&lt;br/&gt;
&lt;br/&gt;I hope you like …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Some weeks ago I started learning Chinese. Here I want to post some useful resources in the Internet that can help.&lt;br/&gt;- &lt;br/&gt; &lt;li&gt;&lt;a href="http://www.nciku.com/"&gt;Nciku&lt;/a&gt;: dictionary, character drawing recognition, and word listening.&lt;/li&gt;&lt;br/&gt;    &lt;li&gt;&lt;a href="http://www.pinyin.clever-industries.com/"&gt;Pinyin talker&lt;/a&gt;: just that :)&lt;/li&gt;&lt;br/&gt;   &lt;li&gt;&lt;a href="http://www.mandarintools.com/worddict.html"&gt;Mandarin tools&lt;/a&gt;: word translation&lt;/li&gt;&lt;br/&gt;    &lt;li&gt;&lt;a href="http://www.newconceptmandarin.com/support/Intro_Pinyin.asp"&gt;New concept mandarin&lt;/a&gt;: compose and listen words, very interesting...&lt;/li&gt;&lt;br/&gt;
&lt;br/&gt;I hope you like it! New recommendations will be very welcome...&lt;/p&gt;</content><category term="Offtopic"></category></entry><entry><title>DSNP 0.11 released</title><link href="https://datapythonista.github.io/blog/dsnp-011-released.html" rel="alternate"></link><published>2007-10-26T16:12:00+01:00</published><updated>2007-10-26T16:12:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2007-10-26:/blog/dsnp-011-released.html</id><summary type="html">&lt;p&gt;&lt;a href="http://code.google.com/p/dsnp/"&gt;DSNP&lt;/a&gt; is a shell script that automatically setups a new Django project, with user custom settings.&lt;br/&gt;&lt;br/&gt;It's specially useful for users that create many Django projects following same patterns.&lt;br/&gt;&lt;br/&gt;After a first very simple release, version 0.11 has released, that includes many validations for avoiding user errors, support for …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="http://code.google.com/p/dsnp/"&gt;DSNP&lt;/a&gt; is a shell script that automatically setups a new Django project, with user custom settings.&lt;br/&gt;&lt;br/&gt;It's specially useful for users that create many Django projects following same patterns.&lt;br/&gt;&lt;br/&gt;After a first very simple release, version 0.11 has released, that includes many validations for avoiding user errors, support for PostgresSQL as well as for MySQL, and many more improvements. See &lt;a href="http://dsnp.googlecode.com/svn/trunk/CHANGELOG"&gt;CHANGELOG&lt;/a&gt; for full list.&lt;br/&gt;&lt;br/&gt;Enjoy!&lt;/p&gt;</content><category term="Applications"></category><category term="DSNP"></category><category term="Django"></category><category term="IT"></category></entry><entry><title>Kimmi World Champion</title><link href="https://datapythonista.github.io/blog/kimmi-world-champion.html" rel="alternate"></link><published>2007-10-22T01:24:00+01:00</published><updated>2007-10-22T01:24:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2007-10-22:/blog/kimmi-world-champion.html</id><summary type="html">&lt;p&gt;Kimmi supporters have waited long for it, but this evening (in Europe time), the unluckier Formula 1 pilot had a lucky strike and has won 2007 Formula 1 Worlds Championship.&lt;br/&gt;&lt;br/&gt;I know that no pilot can be compared with Schummi, the best pilot of history, but Kimmi is a brilliant …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Kimmi supporters have waited long for it, but this evening (in Europe time), the unluckier Formula 1 pilot had a lucky strike and has won 2007 Formula 1 Worlds Championship.&lt;br/&gt;&lt;br/&gt;I know that no pilot can be compared with Schummi, the best pilot of history, but Kimmi is a brilliant pilot that deserved this cup it for some years. Luckily, emotion is guaranteed for next yeasr, because another brilliant pilot has been quite close to Kimmi, Hamilton, and it's one of main candidates for next year. It was a sad day for him, but I'm sure that he'll be fighting for World Championship for many years.&lt;br/&gt;&lt;br/&gt;&lt;strong&gt;Congratulations Kimmi!!! &lt;/strong&gt;&lt;/p&gt;</content><category term="Offtopic"></category></entry><entry><title>2.000 Page views</title><link href="https://datapythonista.github.io/blog/2000-page-views.html" rel="alternate"></link><published>2007-10-22T01:03:00+01:00</published><updated>2007-10-22T01:03:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2007-10-22:/blog/2000-page-views.html</id><summary type="html">&lt;p&gt;Today, this blog has reached page view number 2.000. This blog had some testing sample versions, but started in a serious way on February 24th, 2007 (8 months ago).&lt;br/&gt;&lt;br/&gt;In this time, probably nothing very interesting has been published here, you know; but when some months ago I started …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Today, this blog has reached page view number 2.000. This blog had some testing sample versions, but started in a serious way on February 24th, 2007 (8 months ago).&lt;br/&gt;&lt;br/&gt;In this time, probably nothing very interesting has been published here, you know; but when some months ago I started using and hacking Django, I started writing many posts about it, and that created many visits interested in my hacks, tips...&lt;br/&gt;&lt;br/&gt;I don't know what will happen in the future, if visits will increase, or if I'll have more interesting stuff to tell; but all what I can say is that I'm so happy having my voice in the Internet, for those who want to listen to me.&lt;/p&gt;</content><category term="This blog"></category></entry><entry><title>Django spanish localflavor at trunk</title><link href="https://datapythonista.github.io/blog/django-spanish-localflavor-at-trunk.html" rel="alternate"></link><published>2007-10-20T16:40:00+01:00</published><updated>2007-10-20T16:40:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2007-10-20:/blog/django-spanish-localflavor-at-trunk.html</id><summary type="html">&lt;p&gt;Today has been committed to Django trunk version spanish localflavor patch.&lt;br/&gt;&lt;br/&gt;It includes selector fields for provinces and regions, and validation form functions for postal codes, phone numbers, and nif and ccc codes.&lt;br/&gt;&lt;br/&gt;Patch was started by Ricardo J Barrios, contributed by Rob Oggie and finished by myself, who mistakenly …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Today has been committed to Django trunk version spanish localflavor patch.&lt;br/&gt;&lt;br/&gt;It includes selector fields for provinces and regions, and validation form functions for postal codes, phone numbers, and nif and ccc codes.&lt;br/&gt;&lt;br/&gt;Patch was started by Ricardo J Barrios, contributed by Rob Oggie and finished by myself, who mistakenly doesn't appear as an author of it. :)&lt;br/&gt;&lt;br/&gt;I hope you like it, and comments always will be very welcome.&lt;/p&gt;</content><category term="Applications"></category><category term="Django"></category><category term="IT"></category></entry><entry><title>Leopard coming soon</title><link href="https://datapythonista.github.io/blog/leopard-coming-soon.html" rel="alternate"></link><published>2007-10-18T15:12:00+01:00</published><updated>2007-10-18T15:12:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2007-10-18:/blog/leopard-coming-soon.html</id><summary type="html">&lt;p&gt;After some delays, and some lack of official information, today I finally realized that Apple's new operating will be released on Friday October 26th.&lt;br/&gt;&lt;br/&gt;I actually checked it in Apple's headquarters at Cupertino, in my last visit to California, but just for few minutes.&lt;br/&gt;&lt;br/&gt;I haven't changed my Free Software …&lt;/p&gt;</summary><content type="html">&lt;p&gt;After some delays, and some lack of official information, today I finally realized that Apple's new operating will be released on Friday October 26th.&lt;br/&gt;&lt;br/&gt;I actually checked it in Apple's headquarters at Cupertino, in my last visit to California, but just for few minutes.&lt;br/&gt;&lt;br/&gt;I haven't changed my Free Software philosophy, but I want to complement my GNU/vaio development laptop  with a hopefully better one for desktop working.&lt;br/&gt;&lt;br/&gt;I specially don't like working with OpenOffice.org, I hope that working with iMail will fix some problems that I have with Thunderbird, having screenshots is too much complicated in my lightweight system, it'll be great having all major browsers installed on same computer... And after many good references to Steve Jobs work, I'll try to solve all that problems and more without investing time checking new applications and setups.&lt;/p&gt;</content><category term="Systems"></category><category term="IT"></category></entry><entry><title>Cuba wins</title><link href="https://datapythonista.github.io/blog/cuba-wins.html" rel="alternate"></link><published>2007-10-16T16:12:00+01:00</published><updated>2007-10-16T16:12:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2007-10-16:/blog/cuba-wins.html</id><content type="html">&lt;p&gt;Browsing the Internet I've seen an interesting graphic about how many doctors has every country for how many people.&lt;br/&gt;&lt;br/&gt;Result is not surprising, check it here: &lt;a href="http://adsoftheworld.com/media/print/doctors_of_the_world_netherlands_perspective?size=_original"&gt;Doctors of the World &lt;/a&gt;&lt;/p&gt;</content><category term="Offtopic"></category></entry><entry><title>DSNP (Django Start New Project)</title><link href="https://datapythonista.github.io/blog/dsnp-django-start-new-project.html" rel="alternate"></link><published>2007-10-14T22:10:00+01:00</published><updated>2007-10-14T22:10:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2007-10-14:/blog/dsnp-django-start-new-project.html</id><summary type="html">&lt;p&gt;&lt;a href="http://code.google.com/p/dsnp"&gt;DSNP&lt;/a&gt; is a shell script that automatically creates Django's new projects.&lt;br/&gt;&lt;br/&gt;Django is a powerful framework, mostly designed for big applications, but many people uses it for developing little (and many) projects. DSNP eases creation of new projects, automating repetitive steps, and standardizing projects.&lt;br/&gt;&lt;br/&gt;Additionally to creating Django's files and …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="http://code.google.com/p/dsnp"&gt;DSNP&lt;/a&gt; is a shell script that automatically creates Django's new projects.&lt;br/&gt;&lt;br/&gt;Django is a powerful framework, mostly designed for big applications, but many people uses it for developing little (and many) projects. DSNP eases creation of new projects, automating repetitive steps, and standardizing projects.&lt;br/&gt;&lt;br/&gt;Additionally to creating Django's files and directories, DSNP can create a database (and a user) for your project, and can setup apache with necessary changes.&lt;br/&gt;&lt;br/&gt;DSNP skeleton consists on next:&lt;br/&gt;.&lt;br/&gt;./public&lt;br/&gt;./public/js&lt;br/&gt;./public/js/admin&lt;br/&gt;./public/css&lt;br/&gt;./public/img&lt;br/&gt;./public/img/admin&lt;br/&gt;./public/model_data&lt;br/&gt;./private&lt;br/&gt;./private/www&lt;br/&gt;./private/www/templates&lt;br/&gt;&lt;br/&gt;DSNP doesn't need an installation, just edit dsnp.sh, customize parameters with your preferences, and execute.&lt;/p&gt;</content><category term="Applications"></category><category term="DSNP"></category><category term="Django"></category><category term="IT"></category></entry><entry><title>Google Video Lectures</title><link href="https://datapythonista.github.io/blog/google-video-lectures.html" rel="alternate"></link><published>2007-10-09T17:06:00+01:00</published><updated>2007-10-09T17:06:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2007-10-09:/blog/google-video-lectures.html</id><summary type="html">&lt;p&gt;I often check Google Video for conferences about technologies, trends, or anything about IT. I like it more than just read books, articles or posts.&lt;br/&gt;&lt;br/&gt;Today I've realized about &lt;a href="http://code.google.com/edu/videolectures.html"&gt;Google Video Lectures&lt;/a&gt;, a set of videos about many subjects (AJAX, Python, Clustering...), focused to IT educators, but very interesting for …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I often check Google Video for conferences about technologies, trends, or anything about IT. I like it more than just read books, articles or posts.&lt;br/&gt;&lt;br/&gt;Today I've realized about &lt;a href="http://code.google.com/edu/videolectures.html"&gt;Google Video Lectures&lt;/a&gt;, a set of videos about many subjects (AJAX, Python, Clustering...), focused to IT educators, but very interesting for any IT geek.&lt;/p&gt;</content><category term="Google"></category><category term="Internet"></category><category term="IT"></category></entry><entry><title>Django catalan group created</title><link href="https://datapythonista.github.io/blog/django-catalan-group-created_30.html" rel="alternate"></link><published>2007-09-30T22:57:00+01:00</published><updated>2007-09-30T22:57:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2007-09-30:/blog/django-catalan-group-created_30.html</id><summary type="html">&lt;p&gt;A new Django community has been created for Django users/developers that speak Catalan, or live in Catalonia.&lt;/p&gt;
&lt;p&gt;Main reasons for its creation are:
&lt;ul&gt;
&lt;li&gt;Provide a resource where Catalan users can ask django questions in their own language.&lt;/li&gt;
&lt;li&gt;Coordinate Django Catalan specific jobs, mostly Catalan translation (that now is up …&lt;/li&gt;&lt;/ul&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;A new Django community has been created for Django users/developers that speak Catalan, or live in Catalonia.&lt;/p&gt;
&lt;p&gt;Main reasons for its creation are:
&lt;ul&gt;
&lt;li&gt;Provide a resource where Catalan users can ask django questions in their own language.&lt;/li&gt;
&lt;li&gt;Coordinate Django Catalan specific jobs, mostly Catalan translation (that now is up to date).&lt;/li&gt;
&lt;li&gt;Be in touch with other Django community members in our little country (for business, beers...).&lt;/li&gt;
&lt;/ul&gt;
Want to join us? &lt;a href="http://groups.google.com/group/django-cat"&gt;http://groups.google.com/group/django-cat&lt;/a&gt;&lt;/p&gt;</content><category term="Applications"></category><category term="Django"></category><category term="IT"></category></entry><entry><title>Google Presentations</title><link href="https://datapythonista.github.io/blog/google-presentations.html" rel="alternate"></link><published>2007-09-18T17:24:00+01:00</published><updated>2007-09-18T17:24:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2007-09-18:/blog/google-presentations.html</id><summary type="html">&lt;p&gt;Some months ago Google announced that they were working to add presentations to its Google Applications suite. And today finally they finished their work, some hours ago Google announced it in &lt;a href="http://googleblog.blogspot.com/2007/09/our-feature-presentation.html"&gt;Official Google Blog&lt;/a&gt;.&lt;br/&gt;&lt;br/&gt;You can check how it works &lt;a href="http://docs.google.com/"&gt;here&lt;/a&gt;.&lt;br/&gt;&lt;br/&gt;My first impressions: I miss the feature for importing …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Some months ago Google announced that they were working to add presentations to its Google Applications suite. And today finally they finished their work, some hours ago Google announced it in &lt;a href="http://googleblog.blogspot.com/2007/09/our-feature-presentation.html"&gt;Official Google Blog&lt;/a&gt;.&lt;br/&gt;&lt;br/&gt;You can check how it works &lt;a href="http://docs.google.com/"&gt;here&lt;/a&gt;.&lt;br/&gt;&lt;br/&gt;My first impressions: I miss the feature for importing Openoffice.org documents, and it looks that it's not possible to create your own theme. I hope that they add those features (and more) in new releases.&lt;/p&gt;</content><category term="Google"></category><category term="Internet"></category><category term="IT"></category></entry><entry><title>Django spanish localflavor</title><link href="https://datapythonista.github.io/blog/django-spanish-localflavor.html" rel="alternate"></link><published>2007-09-16T04:17:00+01:00</published><updated>2007-09-16T04:17:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2007-09-16:/blog/django-spanish-localflavor.html</id><summary type="html">&lt;p&gt;Django sprint has finished, but not Django work. Today I've written some lines of code for adding some new features on Django. In this case, I've programmed a validation function for spanish NIF identification number. I've also created a couple of files with useful spanish data (regions and provinces in …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Django sprint has finished, but not Django work. Today I've written some lines of code for adding some new features on Django. In this case, I've programmed a validation function for spanish NIF identification number. I've also created a couple of files with useful spanish data (regions and provinces in Spain).&lt;br/&gt;&lt;br/&gt;The spanish localflavor package was created some months ago, but not yet submitted to subversion. I hope with this contribution (and more that I'm going to do) we can finish it soon.&lt;br/&gt;&lt;br/&gt;You can check a detailed status on this &lt;a href="http://code.djangoproject.com/ticket/4036"&gt;ticket&lt;/a&gt;.&lt;/p&gt;</content><category term="Applications"></category><category term="Django"></category><category term="IT"></category></entry><entry><title>New design</title><link href="https://datapythonista.github.io/blog/new-design.html" rel="alternate"></link><published>2007-09-16T03:57:00+01:00</published><updated>2007-09-16T03:57:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2007-09-16:/blog/new-design.html</id><summary type="html">&lt;p&gt;It will be obvious for returning visitors, but I've changed this blog design. Selected theme has been &lt;a href="http://aydin.net/blog/2006/03/23/three-column-k2-theme-for-wordpress-3k2/"&gt;3K2&lt;/a&gt;.&lt;br/&gt;&lt;br/&gt;As well as a design change, it supposes a more important role on publicity, and the addition of a working search engine.&lt;br/&gt;&lt;br/&gt;I hope you like it,  and comments will be welcome …&lt;/p&gt;</summary><content type="html">&lt;p&gt;It will be obvious for returning visitors, but I've changed this blog design. Selected theme has been &lt;a href="http://aydin.net/blog/2006/03/23/three-column-k2-theme-for-wordpress-3k2/"&gt;3K2&lt;/a&gt;.&lt;br/&gt;&lt;br/&gt;As well as a design change, it supposes a more important role on publicity, and the addition of a working search engine.&lt;br/&gt;&lt;br/&gt;I hope you like it,  and comments will be welcome. Enjoy!&lt;/p&gt;</content><category term="This blog"></category></entry><entry><title>Django Sprint</title><link href="https://datapythonista.github.io/blog/django-sprint.html" rel="alternate"></link><published>2007-09-06T17:31:00+01:00</published><updated>2007-09-06T17:31:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2007-09-06:/blog/django-sprint.html</id><content type="html">&lt;p&gt;On September 14th it is scheduled a Django Sprint, for reducing tickets, and try to get a new release soon. It will be based on Chicago and Mountain View, and over the Internet.&lt;br/&gt;&lt;br/&gt;More information at &lt;a href="http://groups.google.com/group/django-developers/browse_thread/thread/9ed7681e2f567472"&gt;list thread&lt;/a&gt; and &lt;a href="http://code.djangoproject.com/wiki/Sprint14Sep"&gt;wiki page&lt;/a&gt;.&lt;br/&gt;&lt;br/&gt;See you there!&lt;/p&gt;</content><category term="Applications"></category><category term="Django"></category><category term="IT"></category></entry><entry><title>Truth age</title><link href="https://datapythonista.github.io/blog/truth-age.html" rel="alternate"></link><published>2007-08-23T16:02:00+01:00</published><updated>2007-08-23T16:02:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2007-08-23:/blog/truth-age.html</id><summary type="html">&lt;p&gt;Most people already realized that nowadays our society is governed by information most than by economy itself, and that means an evolution from industrial age to information age.&lt;br/&gt;&lt;br/&gt;Today I was wondering about a new age. In my opinion it becomes from another revolution, what is called Web 2.0 …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Most people already realized that nowadays our society is governed by information most than by economy itself, and that means an evolution from industrial age to information age.&lt;br/&gt;&lt;br/&gt;Today I was wondering about a new age. In my opinion it becomes from another revolution, what is called Web 2.0. This revolution implies that through the internet, everyone can contribute and express their ideas or their opinions to anybody else. It can be done in many different media such as a blog, a video, a presentation... And what it means is that now information isn't controlled exclusively by big corporations and its conventional media channels.&lt;br/&gt;&lt;br/&gt;An example is that &lt;a href="http://video.google.com/videoplay?docid=-5296803036286377485"&gt;video&lt;/a&gt;, where an alternative version of what happened in NY on 9/11, that no conventional media has shown. Today most people still gets most information by those channels, but hopefully in some time we can get some kind of &lt;strong&gt;Truth age&lt;/strong&gt;, where our information isn't what "they" want us to know; our information is what we want to know; where we can choose, and where everybody that has something to say, can express it.&lt;/p&gt;</content><category term="Offtopic"></category></entry><entry><title>BCNEmprende</title><link href="https://datapythonista.github.io/blog/bcnemprende.html" rel="alternate"></link><published>2007-08-20T02:01:00+01:00</published><updated>2007-08-20T02:01:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2007-08-20:/blog/bcnemprende.html</id><summary type="html">&lt;p&gt;Browsing the internet I've found an interesting initiative, some kind of enterpreneurs event for people in Barcelona area. I can imagine that it'll be focused on IT, but just guessing, so there is just few information right now.&lt;br/&gt;&lt;br/&gt;It'll be on September 12th at 19:30, place TBD in Barcelona …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Browsing the internet I've found an interesting initiative, some kind of enterpreneurs event for people in Barcelona area. I can imagine that it'll be focused on IT, but just guessing, so there is just few information right now.&lt;br/&gt;&lt;br/&gt;It'll be on September 12th at 19:30, place TBD in Barcelona.&lt;br/&gt;&lt;br/&gt;You can check and join the event at its &lt;a href="http://www.sachafuentes.com/"&gt;blog&lt;/a&gt; and its &lt;a href="http://www.sachafuentes.com/wiki"&gt;wiki&lt;/a&gt;.&lt;/p&gt;</content><category term="Offtopic"></category><category term="IT"></category></entry><entry><title>Django issue with PHP mhash</title><link href="https://datapythonista.github.io/blog/django-issue-with-php-mhash.html" rel="alternate"></link><published>2007-08-03T13:17:00+01:00</published><updated>2007-08-03T13:17:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2007-08-03:/blog/django-issue-with-php-mhash.html</id><summary type="html">&lt;p&gt;After installing django, and running with apache, next error could appear:&lt;br/&gt;&lt;br/&gt;&lt;strong&gt;Looks like your browser isn't configured to accept cookies. Please enable cookies, reload this page, and try again.&lt;/strong&gt;&lt;br/&gt;&lt;br/&gt;It is possible that actually you browser isn't configured to accept cookies, but it is also possible that your apache server …&lt;/p&gt;</summary><content type="html">&lt;p&gt;After installing django, and running with apache, next error could appear:&lt;br/&gt;&lt;br/&gt;&lt;strong&gt;Looks like your browser isn't configured to accept cookies. Please enable cookies, reload this page, and try again.&lt;/strong&gt;&lt;br/&gt;&lt;br/&gt;It is possible that actually you browser isn't configured to accept cookies, but it is also possible that your apache server is running with PHP support with mhash module enabled; then it is an unsolved and known issue.&lt;br/&gt;&lt;br/&gt;This issue causes python md5 module to get unexpected results, when executed in same apache server than mhash PHP module. &lt;a href="http://mail-archives.apache.org/mod_mbox/httpd-python-dev/200706.mbox/%3C27092147.1183094044465.JavaMail.jira@brutus%3E"&gt;Here&lt;/a&gt; it is a more detailed description.&lt;br/&gt;&lt;br/&gt;It seems to be no solution for that (just uninstall mhash module, or whole php support if possible).&lt;/p&gt;</content><category term="Applications"></category><category term="Django"></category><category term="IT"></category></entry><entry><title>Spanish censorship</title><link href="https://datapythonista.github.io/blog/spanish-censorship.html" rel="alternate"></link><published>2007-07-21T23:11:00+01:00</published><updated>2007-07-21T23:11:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2007-07-21:/blog/spanish-censorship.html</id><summary type="html">&lt;p class="blog_text3"&gt;There are always incredible things on news about spanish “justice”, government… Last one is that a famous humor magazine has been banned.&lt;/p&gt;

&lt;p&gt;&lt;br/&gt;&lt;p class="blog_text3"&gt;&lt;a href="http://www.theage.com.au/ffximage/2007/07/21/wrg_jueves_wideweb__470x293,0.jpg"&gt;Here&lt;/a&gt; is why.&lt;/p&gt;&lt;br/&gt;&lt;p class="blog_text3"&gt;&amp;nbsp;&lt;/p&gt;&lt;br/&gt;&lt;p class="blog_text3"&gt;Translation:&lt;/p&gt;&lt;br/&gt;&lt;p class="blog_text3"&gt;    Felipe (spanish prince): “Just imagine if you end up pregnant, this will be the closest thing to work I’ve ever done in my …&lt;/p&gt;&lt;/p&gt;</summary><content type="html">&lt;p class="blog_text3"&gt;There are always incredible things on news about spanish “justice”, government… Last one is that a famous humor magazine has been banned.&lt;/p&gt;

&lt;p&gt;&lt;br/&gt;&lt;p class="blog_text3"&gt;&lt;a href="http://www.theage.com.au/ffximage/2007/07/21/wrg_jueves_wideweb__470x293,0.jpg"&gt;Here&lt;/a&gt; is why.&lt;/p&gt;&lt;br/&gt;&lt;p class="blog_text3"&gt;&amp;nbsp;&lt;/p&gt;&lt;br/&gt;&lt;p class="blog_text3"&gt;Translation:&lt;/p&gt;&lt;br/&gt;&lt;p class="blog_text3"&gt;    Felipe (spanish prince): “Just imagine if you end up pregnant, this will be the closest thing to work I’ve ever done in my life.”  In reference to a new law on what people will get 2.500 euros for every son or daughter.&lt;/p&gt;&lt;br/&gt;&lt;p class="blog_text3"&gt;&amp;nbsp;&lt;/p&gt;&lt;br/&gt;&lt;p class="blog_text3"&gt;&lt;strong&gt;I want to give my support to “El jueves” in my still uncensored blog.&lt;/strong&gt;&lt;/p&gt;&lt;/p&gt;</content><category term="Offtopic"></category></entry><entry><title>Django database texts translated</title><link href="https://datapythonista.github.io/blog/django-database-texts-translated.html" rel="alternate"></link><published>2007-07-12T01:36:00+01:00</published><updated>2007-07-12T01:36:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2007-07-12:/blog/django-database-texts-translated.html</id><content type="html">&lt;p&gt;Django i18n is really good, but an important feature is missing... a very simple way (for users) for translating database stored labels.&lt;br/&gt;&lt;br/&gt;I've checked 
&lt;img alt="" src="http://vaig.be/wp-content/uploads/django_mlang_small.png"&gt;&lt;/p&gt;</content><category term="Applications"></category><category term="Django"></category><category term="IT"></category></entry><entry><title>Django TODO (my point of view)</title><link href="https://datapythonista.github.io/blog/django-todo-my-point-of-view.html" rel="alternate"></link><published>2007-07-08T13:38:00+01:00</published><updated>2007-07-08T13:38:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2007-07-08:/blog/django-todo-my-point-of-view.html</id><summary type="html">&lt;p&gt;&lt;a href="http://www.djangoproject.com/"&gt;Django&lt;/a&gt; is a very powerful and very well done Web framework, but some things are missing - in my opinion -.&lt;br/&gt;&lt;ol&gt;&lt;br/&gt;   &lt;li&gt;Specific way to allow saving multilingual texts on database.&lt;/li&gt;&lt;br/&gt;  &lt;li&gt;Reporting system.&lt;/li&gt;&lt;br/&gt; &lt;li&gt;Another edit_inline mode, with a delete button, and an edit button that links to the item page.&lt;/li&gt;&lt;br/&gt;   &lt;li&gt;Improve database synchronization …&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="http://www.djangoproject.com/"&gt;Django&lt;/a&gt; is a very powerful and very well done Web framework, but some things are missing - in my opinion -.&lt;br/&gt;&lt;ol&gt;&lt;br/&gt;   &lt;li&gt;Specific way to allow saving multilingual texts on database.&lt;/li&gt;&lt;br/&gt;  &lt;li&gt;Reporting system.&lt;/li&gt;&lt;br/&gt; &lt;li&gt;Another edit_inline mode, with a delete button, and an edit button that links to the item page.&lt;/li&gt;&lt;br/&gt;   &lt;li&gt;Improve database synchronization and make it create fields in existing tables.&lt;/li&gt;&lt;br/&gt;    &lt;li&gt;Allow storing files in database&lt;/li&gt;&lt;br/&gt;&lt;/ol&gt;&lt;br/&gt;I hope having enough time for contributing to it. Thanks to Django team for that great work!&lt;/p&gt;</content><category term="Applications"></category><category term="Django"></category><category term="IT"></category></entry><entry><title>Convert a GNU/Linux PC in a router</title><link href="https://datapythonista.github.io/blog/convert-gnulinux-pc-in-router.html" rel="alternate"></link><published>2007-07-08T13:28:00+01:00</published><updated>2007-07-08T13:28:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2007-07-08:/blog/convert-gnulinux-pc-in-router.html</id><content type="html">&lt;p&gt;For converting a simple computer with two interfaces (or more) in a router, it's necessary just to type two sentences in a console:&lt;br/&gt;&lt;br/&gt;&lt;em&gt;echo 1 &amp;gt; /proc/sys/net/ipv4/ip-forward&lt;/em&gt;&lt;br/&gt;&lt;br/&gt;&lt;em&gt;iptables -t nat -A POSTROUTING -o &lt;interface&gt; -j MASQUERADE&lt;/em&gt;&lt;/p&gt;</content><category term="Systems"></category><category term="IT"></category></entry><entry><title>Wordpress spam comments</title><link href="https://datapythonista.github.io/blog/wordpress-spam-comments.html" rel="alternate"></link><published>2007-06-29T14:16:00+01:00</published><updated>2007-06-29T14:16:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2007-06-29:/blog/wordpress-spam-comments.html</id><content type="html">&lt;p&gt;Today I've installed a new &lt;a href="http://wordpress.org"&gt;WordPress&lt;/a&gt; plugin, to avoid robots write comments on this page. It's very common that spammers use blog comments to link their pages, as publicity, and for increasing their pagerank.&lt;br/&gt;&lt;br/&gt;It can be solved in WordPress using &lt;a href="http://wordpress.org/extend/plugins/jsspamblock/"&gt;JSSpamBlock&lt;/a&gt; plugin from &lt;a href="http://www.paulbutler.org/"&gt;Paul Butler&lt;/a&gt;. Thanks man!&lt;/p&gt;</content><category term="Applications"></category><category term="This blog"></category><category term="IT"></category></entry><entry><title>SourceForge.net and Subversion</title><link href="https://datapythonista.github.io/blog/sourceforgenet-and-subversion.html" rel="alternate"></link><published>2007-06-29T13:47:00+01:00</published><updated>2007-06-29T13:47:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2007-06-29:/blog/sourceforgenet-and-subversion.html</id><content type="html">&lt;p&gt;Today I've discovered that &lt;a href="http://www.sourceforge.net"&gt;SourceForge.net&lt;/a&gt; is offering Subverion control system. Last time I've seen that I just realized on CVS.&lt;br/&gt;&lt;br/&gt;If you already have your project, you have to change it manually; from your control panel, Admin &amp;gt; Subversion, and enable it.&lt;/p&gt;</content><category term="IT"></category></entry><entry><title>File encodings</title><link href="https://datapythonista.github.io/blog/file-encodings.html" rel="alternate"></link><published>2007-06-07T15:52:00+01:00</published><updated>2007-06-07T15:52:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2007-06-07:/blog/file-encodings.html</id><summary type="html">&lt;p&gt;Many times, specially when writing web pages, you have to deal with texts with different encodes (if web site isn't in us-ascii, of course).  Here are some useful tips for not spending too much time with this:&lt;br/&gt;&lt;br/&gt;&lt;em&gt;bash# &lt;/em&gt;&lt;em&gt;file -i &lt;filename&gt;&lt;/em&gt; (for knowing the encoding for a specific file)&lt;br/&gt;&lt;br/&gt;&lt;em&gt;vim# &lt;/em&gt;&lt;em&gt;:set …&lt;/em&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;Many times, specially when writing web pages, you have to deal with texts with different encodes (if web site isn't in us-ascii, of course).  Here are some useful tips for not spending too much time with this:&lt;br/&gt;&lt;br/&gt;&lt;em&gt;bash# &lt;/em&gt;&lt;em&gt;file -i &lt;filename&gt;&lt;/em&gt; (for knowing the encoding for a specific file)&lt;br/&gt;&lt;br/&gt;&lt;em&gt;vim# &lt;/em&gt;&lt;em&gt;:set fileencoding=utf-8&lt;/em&gt; (for changing encoding of current file, converting characters from one charset to the new one in a human understandable way)&lt;br/&gt;&lt;br/&gt;&lt;em&gt;vim# :set encoding=utf-8&lt;/em&gt; (for setting encode of new files; default is system locale)&lt;br/&gt;&lt;br/&gt;Remember that those thinks just apply to plain files, that are saved without any header or any information about encoding (editors try to figure out encodes).&lt;br/&gt;&lt;br/&gt;A little bit offtopic, but an interesting vim command is also:&lt;br/&gt;&lt;br/&gt;&lt;em&gt;vim# :set ff=unix&lt;/em&gt; (for changing eol from dos/mac to unix)&lt;br/&gt;&lt;br/&gt;&lt;strong&gt;UPDATE:&lt;/strong&gt; If you have many files to convert, or don't know how to use vim... :) you can use GNU &lt;em&gt;iconv&lt;/em&gt; program.&lt;/p&gt;</content><category term="Development"></category><category term="Systems"></category><category term="IT"></category></entry><entry><title>Vaig bé host changed</title><link href="https://datapythonista.github.io/blog/vaig-b-host-changed.html" rel="alternate"></link><published>2007-05-23T15:53:00+01:00</published><updated>2007-05-23T15:53:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2007-05-23:/blog/vaig-b-host-changed.html</id><content type="html">&lt;p&gt;Due to many problems with blogger, finally I've changed this host placeholder.&lt;br/&gt;&lt;br/&gt;I've done it using &lt;a href="http://www.wordpress.org&amp;quot; target=&amp;quot;_blank"&gt;WordPress&lt;/a&gt; software and a private hosting. Some work is still missing, but all my problems disappeared. :)&lt;/p&gt;</content><category term="This blog"></category></entry><entry><title>chmod and umask</title><link href="https://datapythonista.github.io/blog/chmod-and-umask.html" rel="alternate"></link><published>2007-05-12T01:00:00+01:00</published><updated>2007-05-12T01:00:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2007-05-12:/blog/chmod-and-umask.html</id><summary type="html">&lt;p&gt;Both UNIX commands are used to set permissions, &lt;span class="blsp-spelling-error" id="SPELLING_ERROR_0"&gt;chmod&lt;/span&gt; is for changing permissions of a specific file, and &lt;span class="blsp-spelling-error" id="SPELLING_ERROR_1"&gt;umask&lt;/span&gt; is for setting default creation permissions for a user.&lt;br/&gt;&lt;br/&gt;&lt;span style="font-weight: bold"&gt;Basics&lt;/span&gt;&lt;br/&gt;Simple UNIX permissions are:&lt;br/&gt;r (read)&lt;br/&gt;w (write)&lt;br/&gt;x (execute)&lt;br/&gt;and them can be assigned to users:&lt;br/&gt;u (user/owner)&lt;br/&gt;g …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Both UNIX commands are used to set permissions, &lt;span class="blsp-spelling-error" id="SPELLING_ERROR_0"&gt;chmod&lt;/span&gt; is for changing permissions of a specific file, and &lt;span class="blsp-spelling-error" id="SPELLING_ERROR_1"&gt;umask&lt;/span&gt; is for setting default creation permissions for a user.&lt;br/&gt;&lt;br/&gt;&lt;span style="font-weight: bold"&gt;Basics&lt;/span&gt;&lt;br/&gt;Simple UNIX permissions are:&lt;br/&gt;r (read)&lt;br/&gt;w (write)&lt;br/&gt;x (execute)&lt;br/&gt;and them can be assigned to users:&lt;br/&gt;u (user/owner)&lt;br/&gt;g (group)&lt;br/&gt;o (others)&lt;br/&gt;a (all/last 3)&lt;br/&gt;&lt;br/&gt;&lt;span style="font-weight: bold"&gt;Easy &lt;span class="blsp-spelling-error" id="SPELLING_ERROR_2"&gt;chmod&lt;/span&gt;&lt;/span&gt;:&lt;br/&gt;&lt;span class="blsp-spelling-error" id="SPELLING_ERROR_3"&gt;chmod&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;permission&gt;+&lt;users&gt; &lt;filename&gt; (add &lt;span class="blsp-spelling-corrected" id="SPELLING_ERROR_4"&gt;permissions&lt;/span&gt;)&lt;br/&gt;&lt;span class="blsp-spelling-error" id="SPELLING_ERROR_5"&gt;chmod&lt;/span&gt;&lt;/filename&gt;&lt;/users&gt;&lt;/permission&gt;&lt;br/&gt;&lt;permission&gt;-&lt;users&gt; &lt;filename&gt; (remove &lt;span class="blsp-spelling-corrected" id="SPELLING_ERROR_6"&gt;permissions&lt;/span&gt;)&lt;/filename&gt;&lt;/users&gt;&lt;/permission&gt;Examples:&lt;br/&gt;&lt;span style="font-style: italic"&gt;&lt;span class="blsp-spelling-error" id="SPELLING_ERROR_7"&gt;chmod&lt;/span&gt; a+r &lt;span class="blsp-spelling-error" id="SPELLING_ERROR_8"&gt;myfile&lt;/span&gt;&lt;/span&gt; (everybody can read)&lt;br/&gt;&lt;span style="font-style: italic"&gt;&lt;span class="blsp-spelling-error" id="SPELLING_ERROR_9"&gt;chmod&lt;/span&gt; o-w &lt;span class="blsp-spelling-error" id="SPELLING_ERROR_10"&gt;myfile&lt;/span&gt;&lt;/span&gt; (only owner and users in group can write)&lt;br/&gt;&lt;br/&gt;&lt;span style="font-weight: bold"&gt;"Difficult" &lt;span class="blsp-spelling-error" id="SPELLING_ERROR_11"&gt;chmod&lt;/span&gt;&lt;/span&gt;:&lt;br/&gt;Use numbers for setting permissions. 3 digits, first for owner, second for group and third for others.&lt;br/&gt;To calculate a number you have to sum next values: 4 for read, 2 for write, 1 for execute.&lt;br/&gt;&lt;br/&gt;Example:&lt;br/&gt;Want to add read and write for owner, just read for group, and nothing for others...&lt;br/&gt;1st: 4 (read) + 2 (write) = 6&lt;br/&gt;2&lt;span class="blsp-spelling-error" id="SPELLING_ERROR_12"&gt;nd&lt;/span&gt;: 4 (read) = 4&lt;br/&gt;3rd: 0&lt;br/&gt;&lt;span style="font-style: italic"&gt;&lt;span class="blsp-spelling-error" id="SPELLING_ERROR_13"&gt;chmod&lt;/span&gt; 640 &lt;span class="blsp-spelling-error" id="SPELLING_ERROR_14"&gt;myfile&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;span style="font-weight: bold"&gt;&lt;span class="blsp-spelling-error" id="SPELLING_ERROR_15"&gt;umask&lt;/span&gt;&lt;span style="font-weight: bold"&gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;span class="blsp-spelling-error" id="SPELLING_ERROR_16"&gt;umask&lt;/span&gt; value is calculated in next way; maximum permissions less &lt;span class="blsp-spelling-error" id="SPELLING_ERROR_18"&gt;chmod&lt;/span&gt; desired value.&lt;br/&gt;If we want 750 permissions (&lt;span class="blsp-spelling-error" id="SPELLING_ERROR_19"&gt;rwxr&lt;/span&gt;-x---):&lt;br/&gt;0777&lt;br/&gt;-0750&lt;br/&gt;------&lt;br/&gt;0027&lt;br/&gt;&lt;br/&gt;so add...&lt;br/&gt;&lt;span style="font-style: italic"&gt;&lt;span class="blsp-spelling-error" id="SPELLING_ERROR_20"&gt;umask&lt;/span&gt; 0025&lt;/span&gt;&lt;span style="font-weight: bold"&gt;&lt;span style="font-weight: bold"&gt;&lt;/span&gt;&lt;br/&gt;&lt;/span&gt;to&lt;br/&gt;~/.&lt;span class="blsp-spelling-error" id="SPELLING_ERROR_21"&gt;bashrc&lt;/span&gt;&lt;/p&gt;</content><category term="Systems"></category><category term="IT"></category></entry><entry><title>Download full web sites</title><link href="https://datapythonista.github.io/blog/download-full-web-sites.html" rel="alternate"></link><published>2007-05-05T20:37:00+01:00</published><updated>2007-05-05T20:37:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2007-05-05:/blog/download-full-web-sites.html</id><summary type="html">&lt;p&gt;I've spent too much time searching for an application that allows me downloading all files (all pages, images...) from a web site.&lt;br/&gt;&lt;br/&gt;It has been a hard search, but finally I've found one installed on my computer...&lt;br/&gt;&lt;br/&gt;Yeah, of course wget can do that! Just use it with few parameters …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I've spent too much time searching for an application that allows me downloading all files (all pages, images...) from a web site.&lt;br/&gt;&lt;br/&gt;It has been a hard search, but finally I've found one installed on my computer...&lt;br/&gt;&lt;br/&gt;Yeah, of course wget can do that! Just use it with few parameters...&lt;br/&gt;&lt;br/&gt;&lt;span style="font-weight: bold"&gt;wget -r -l0 -p&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;And that's all.&lt;br/&gt;&lt;br/&gt;&lt;strong&gt;UPDATE:&lt;/strong&gt; Also very interesting for downloading many files from an ftp server &lt;strong&gt;wget -r --no-passive-ftp ftp://user:password@host/directory&lt;/strong&gt; and very interesting &lt;strong&gt;wput&lt;/strong&gt; for uploading the files.&lt;/p&gt;</content><category term="Applications"></category><category term="IT"></category></entry><entry><title>Blog Impact</title><link href="https://datapythonista.github.io/blog/blog-impact.html" rel="alternate"></link><published>2007-04-30T13:46:00+01:00</published><updated>2007-04-30T13:46:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2007-04-30:/blog/blog-impact.html</id><summary type="html">&lt;p&gt;Probably this post would never be in any top 10, or appearing in any IT magazine, but after few weeks we already have a PageRank #2, and we are appearing in &lt;a href="http://technorati.com/"&gt;&lt;span class="blsp-spelling-error" id="SPELLING_ERROR_0"&gt;&lt;span class="blsp-spelling-error" id="SPELLING_ERROR_0"&gt;Technorati&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;.&lt;br/&gt;&lt;br/&gt;Those are good news, so we still have some handicaps, specially due to blogger issues, that make this …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Probably this post would never be in any top 10, or appearing in any IT magazine, but after few weeks we already have a PageRank #2, and we are appearing in &lt;a href="http://technorati.com/"&gt;&lt;span class="blsp-spelling-error" id="SPELLING_ERROR_0"&gt;&lt;span class="blsp-spelling-error" id="SPELLING_ERROR_0"&gt;Technorati&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;.&lt;br/&gt;&lt;br/&gt;Those are good news, so we still have some handicaps, specially due to blogger issues, that make this blog appear with different names...&lt;br/&gt;&lt;a href="http://vaigbe.blogspot.com/"&gt;    http://vaigbe.blogspot.com/&lt;/a&gt;&lt;br/&gt;&lt;a href="http://vaig.be"&gt;    http://vaig.be&lt;/a&gt; - &lt;a href="http://www.vaig.be"&gt;http://www.vaig.be&lt;/a&gt;&lt;br/&gt;dividing our PageRank, and creating future &lt;span class="blsp-spelling-error" id="SPELLING_ERROR_1"&gt;dead&lt;/span&gt; links.&lt;/p&gt;</content><category term="This blog"></category></entry><entry><title>Firefox Extensions</title><link href="https://datapythonista.github.io/blog/firefox-extensions.html" rel="alternate"></link><published>2007-04-25T15:24:00+01:00</published><updated>2007-04-25T15:24:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2007-04-25:/blog/firefox-extensions.html</id><summary type="html">&lt;p&gt;When developing web pages is essential having a good set of &lt;span class="blsp-spelling-error" id="SPELLING_ERROR_0"&gt;firefox&lt;/span&gt; extensions. It  gives you powerful tools for checking &lt;span class="blsp-spelling-corrected" id="SPELLING_ERROR_1"&gt;accessibility&lt;/span&gt;, and for getting more information on your website, and are also good fot getting information about all websites...&lt;br/&gt;&lt;br/&gt;Those are my favourites:&lt;br/&gt;&lt;a href="https://addons.mozilla.org/en-US/firefox/addon/249"&gt;Html &lt;span class="blsp-spelling-error" id="SPELLING_ERROR_2"&gt;Validator&lt;/span&gt;&lt;/a&gt;: Quick view if you are …&lt;/p&gt;</summary><content type="html">&lt;p&gt;When developing web pages is essential having a good set of &lt;span class="blsp-spelling-error" id="SPELLING_ERROR_0"&gt;firefox&lt;/span&gt; extensions. It  gives you powerful tools for checking &lt;span class="blsp-spelling-corrected" id="SPELLING_ERROR_1"&gt;accessibility&lt;/span&gt;, and for getting more information on your website, and are also good fot getting information about all websites...&lt;br/&gt;&lt;br/&gt;Those are my favourites:&lt;br/&gt;&lt;a href="https://addons.mozilla.org/en-US/firefox/addon/249"&gt;Html &lt;span class="blsp-spelling-error" id="SPELLING_ERROR_2"&gt;Validator&lt;/span&gt;&lt;/a&gt;: Quick view if you are following standards.&lt;br/&gt;&lt;a href="https://addons.mozilla.org/en-US/firefox/addon/2007"&gt;Live PageRank&lt;/a&gt;: Quick view on site's PageRank.&lt;br/&gt;&lt;a href="https://addons.mozilla.org/en-US/firefox/addon/60"&gt;Web Developer&lt;/a&gt;: Many tools, specially for disabling &lt;span class="blsp-spelling-error" id="SPELLING_ERROR_3"&gt;css&lt;/span&gt; or javascript, and for resizing screen.&lt;/p&gt;</content><category term="Applications"></category><category term="Development"></category><category term="IT"></category></entry><entry><title>The Simpsons quotes</title><link href="https://datapythonista.github.io/blog/simpsons-quotes.html" rel="alternate"></link><published>2007-04-19T18:13:00+01:00</published><updated>2007-04-19T18:13:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2007-04-19:/blog/simpsons-quotes.html</id><summary type="html">&lt;p&gt;Today I've found something very funny; I just want to share with you...&lt;br/&gt;&lt;br/&gt;&lt;span style="font-style: italic"&gt;Marge: Homer, the plant called. They said if you don't show up tomorrow don't bother showing up on Monday. &lt;/span&gt;&lt;br/&gt;&lt;span style="font-style: italic"&gt; Homer: Woo-hoo. Four-day weekend.&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;Grandpa: My Homer is not a communist.  He may be a liar, a pig …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Today I've found something very funny; I just want to share with you...&lt;br/&gt;&lt;br/&gt;&lt;span style="font-style: italic"&gt;Marge: Homer, the plant called. They said if you don't show up tomorrow don't bother showing up on Monday. &lt;/span&gt;&lt;br/&gt;&lt;span style="font-style: italic"&gt; Homer: Woo-hoo. Four-day weekend.&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;Grandpa: My Homer is not a communist.  He may be a liar, a pig, an idiot, a communist, but he is not a porn star.&lt;br/&gt;&lt;br/&gt;Good stuff, right?&lt;br/&gt;&lt;br/&gt;Search more at &lt;a href="http://www.thesimpsonsquotes.com/"&gt;Simpsons Quotes&lt;/a&gt;&lt;/p&gt;</content><category term="Offtopic"></category></entry><entry><title>Allow user to execute root files</title><link href="https://datapythonista.github.io/blog/allow-user-to-execute-root-files.html" rel="alternate"></link><published>2007-04-17T15:39:00+01:00</published><updated>2007-04-17T15:39:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2007-04-17:/blog/allow-user-to-execute-root-files.html</id><summary type="html">&lt;p&gt;Sometimes it's useful allowing users to execute programs reserved for root. For example if we have a desktop system, we can allow users to halt or reboot computer.&lt;br/&gt;&lt;br/&gt;There are several ways to &lt;span class="blsp-spelling-corrected" id="SPELLING_ERROR_0"&gt;achieve&lt;/span&gt; it, the proposed here is the simplest one (probably not the securest one).&lt;br/&gt;&lt;br/&gt;Just add +s …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Sometimes it's useful allowing users to execute programs reserved for root. For example if we have a desktop system, we can allow users to halt or reboot computer.&lt;br/&gt;&lt;br/&gt;There are several ways to &lt;span class="blsp-spelling-corrected" id="SPELLING_ERROR_0"&gt;achieve&lt;/span&gt; it, the proposed here is the simplest one (probably not the securest one).&lt;br/&gt;&lt;br/&gt;Just add +s to file permissions; for example:&lt;br/&gt;&lt;span style="font-weight: bold"&gt;&lt;span class="blsp-spelling-error" id="SPELLING_ERROR_1"&gt;chmod&lt;/span&gt; +s /&lt;span class="blsp-spelling-error" id="SPELLING_ERROR_2"&gt;sbin&lt;/span&gt;/halt&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;I don't recommend doing it without reading some documentation, and comparing this method with "&lt;span class="blsp-spelling-error" id="SPELLING_ERROR_3"&gt;sudo&lt;/span&gt;"...&lt;/p&gt;</content><category term="Systems"></category><category term="IT"></category></entry><entry><title>GPG Error updating Debian Etch</title><link href="https://datapythonista.github.io/blog/gpg-error-updating-debian-etch.html" rel="alternate"></link><published>2007-04-17T14:08:00+01:00</published><updated>2007-04-17T14:08:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2007-04-17:/blog/gpg-error-updating-debian-etch.html</id><summary type="html">&lt;p&gt;Probably not happening anymore with Debian Etch as stable, but that error happened sometimes when apt-get update:&lt;br/&gt;&lt;br/&gt;W: &lt;span class="blsp-spelling-error" id="SPELLING_ERROR_0"&gt;GPG&lt;/span&gt; error: http://security.debian.org etch/updates Release: The following signatures couldn't be verified because the public key is not available: NO_&lt;span class="blsp-spelling-error" id="SPELLING_ERROR_1"&gt;PUBKEY&lt;/span&gt; A70&lt;span class="blsp-spelling-error" id="SPELLING_ERROR_2"&gt;DAF&lt;/span&gt;536070D3A1&lt;br/&gt;W: &lt;span class="blsp-spelling-error" id="SPELLING_ERROR_3"&gt;GPG&lt;/span&gt; error: ftp://ftp …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Probably not happening anymore with Debian Etch as stable, but that error happened sometimes when apt-get update:&lt;br/&gt;&lt;br/&gt;W: &lt;span class="blsp-spelling-error" id="SPELLING_ERROR_0"&gt;GPG&lt;/span&gt; error: http://security.debian.org etch/updates Release: The following signatures couldn't be verified because the public key is not available: NO_&lt;span class="blsp-spelling-error" id="SPELLING_ERROR_1"&gt;PUBKEY&lt;/span&gt; A70&lt;span class="blsp-spelling-error" id="SPELLING_ERROR_2"&gt;DAF&lt;/span&gt;536070D3A1&lt;br/&gt;W: &lt;span class="blsp-spelling-error" id="SPELLING_ERROR_3"&gt;GPG&lt;/span&gt; error: ftp://ftp.hr.debian.org testing Release: The following signatures couldn't be verified because the public key is not available: NO_&lt;span class="blsp-spelling-error" id="SPELLING_ERROR_4"&gt;PUBKEY&lt;/span&gt; A70&lt;span class="blsp-spelling-error" id="SPELLING_ERROR_5"&gt;DAF&lt;/span&gt;536070D3A1&lt;br/&gt;W: You may want to run apt-get update to correct these problems&lt;br/&gt;&lt;br/&gt;I've solved it just with:&lt;br/&gt;&lt;span style="font-style: italic"&gt;apt-get install &lt;span class="blsp-spelling-error" id="SPELLING_ERROR_6"&gt;debian&lt;/span&gt;-archive-keyring&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;Source: &lt;a href="http://www.linuxquestions.org/questions/showthread.php?t=533672&amp;amp;highlight=apt-get+public+key+gpg+error"&gt;&lt;span class="blsp-spelling-error" id="SPELLING_ERROR_7"&gt;LinuxQuestions&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;</content><category term="Systems"></category><category term="IT"></category></entry><entry><title>Adding your blogger page to Google sitemap</title><link href="https://datapythonista.github.io/blog/adding-your-blogger-page-to-google.html" rel="alternate"></link><published>2007-04-08T21:32:00+01:00</published><updated>2007-04-08T21:32:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2007-04-08:/blog/adding-your-blogger-page-to-google.html</id><summary type="html">&lt;p&gt;Google sitemap is a service that allows you to get many information about what Google think about your page (pageranks, best position searches, errors...). It's easy to use sitemap whan you have your page in a server under your control, but there are some things to take in consideration when …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Google sitemap is a service that allows you to get many information about what Google think about your page (pageranks, best position searches, errors...). It's easy to use sitemap whan you have your page in a server under your control, but there are some things to take in consideration when using blogger.&lt;br/&gt;&lt;br/&gt;Here you have a brief howto:&lt;br/&gt;&lt;br/&gt;Sign up Google sitemap&lt;br/&gt;&amp;gt; Add site (your URL)&lt;br/&gt;&amp;gt; Verify your site&lt;br/&gt;&amp;gt; Add a META tag&lt;br/&gt;&amp;gt; Copy META tag&lt;br/&gt;&amp;gt; Sign up blogger&lt;br/&gt;&amp;gt; Template&lt;br/&gt;&amp;gt; Edit HTML&lt;br/&gt;&amp;gt; Paste META tag after &lt;head&gt; tag&lt;br/&gt;&amp;gt; SAVE TEMPLATE&lt;br/&gt;&amp;gt; Go back to Google sitemap page&lt;br/&gt;&amp;gt; Verify&lt;br/&gt;&amp;gt; Add a sitemap&lt;br/&gt;&amp;gt; Add General Web Sitemap&lt;br/&gt;&amp;gt; Your sitemap URL is {your_blogger_page}/atom.xml&lt;br/&gt;&lt;br/&gt;If you need a more detailed howto, you have it &lt;a href="http://blogs.cyberciti.biz/hm/index.php/2006/04/28/adding-google-sitemap-to-bloggercom-blog-account/"&gt;here&lt;/a&gt;.&lt;/p&gt;</content><category term="Google"></category><category term="Internet"></category><category term="IT"></category></entry><entry><title>DNS update at vaig.be</title><link href="https://datapythonista.github.io/blog/dns-update-at-vaigbe.html" rel="alternate"></link><published>2007-04-08T20:50:00+01:00</published><updated>2007-04-08T20:50:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2007-04-08:/blog/dns-update-at-vaigbe.html</id><summary type="html">&lt;p&gt;I've changed the &lt;span class="blsp-spelling-error" id="SPELLING_ERROR_0"&gt;dns&lt;/span&gt; settings for this blog, because a blogger issue (I suppose) that didn't redirect requests to &lt;a href="http://vaig.be"&gt;http://vaig.be&lt;/a&gt; to this blog (just from &lt;a href="http://www.vaig.be"&gt;http://www.vaig.be&lt;/a&gt;).&lt;br/&gt;&lt;br/&gt;Blogger manages external domains for blogs, but with &lt;span class="blsp-spelling-corrected" id="SPELLING_ERROR_1"&gt;previous&lt;/span&gt; commented issue, so I'm not going to use this feature …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I've changed the &lt;span class="blsp-spelling-error" id="SPELLING_ERROR_0"&gt;dns&lt;/span&gt; settings for this blog, because a blogger issue (I suppose) that didn't redirect requests to &lt;a href="http://vaig.be"&gt;http://vaig.be&lt;/a&gt; to this blog (just from &lt;a href="http://www.vaig.be"&gt;http://www.vaig.be&lt;/a&gt;).&lt;br/&gt;&lt;br/&gt;Blogger manages external domains for blogs, but with &lt;span class="blsp-spelling-corrected" id="SPELLING_ERROR_1"&gt;previous&lt;/span&gt; commented issue, so I'm not going to use this feature anymore, and I'll use &lt;a href="http://vaigbe.blogspot.com"&gt;http://vaigbe.blogspot.com&lt;/a&gt; and change &lt;span class="blsp-spelling-error" id="SPELLING_ERROR_2"&gt;dns&lt;/span&gt; settings for my domain &lt;span class="blsp-spelling-error" id="SPELLING_ERROR_3"&gt;vaig&lt;/span&gt;.be.&lt;br/&gt;&lt;br/&gt;This means that this page won't be available throw &lt;a href="http://www.vaig.be"&gt;http://www.vaig.be&lt;/a&gt; for some time during &lt;span class="blsp-spelling-error" id="SPELLING_ERROR_4"&gt;dns&lt;/span&gt; update, and &lt;span class="blsp-spelling-error" id="SPELLING_ERROR_5"&gt;dns&lt;/span&gt; mirrors update. I apologize for it. But after &lt;span class="blsp-spelling-error" id="SPELLING_ERROR_6"&gt;dns&lt;/span&gt; updates it will be also available at &lt;a href="http://vaig.be"&gt;http://vaig.be&lt;/a&gt; and &lt;a href="http://vaigbe.blogspot.com/"&gt;http://vaigbe.blogspot.com&lt;/a&gt;.&lt;/p&gt;</content><category term="This blog"></category></entry><entry><title>Debian GNU/Linux 4.0 released</title><link href="https://datapythonista.github.io/blog/debian-gnulinux-40-released.html" rel="alternate"></link><published>2007-04-08T20:14:00+01:00</published><updated>2007-04-08T20:14:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2007-04-08:/blog/debian-gnulinux-40-released.html</id><summary type="html">&lt;p&gt;Finally, after 21 months of constant development, last version of Debian distribution has been released. Oppositely to previous versions of Debian, Etch has a "up-to-date flavour", including last version packages such as Linux kernel 2.6, MySQL 5, &lt;span class="blsp-spelling-error" id="SPELLING_ERROR_0"&gt;PHP&lt;/span&gt; 5, Python 2.5, &lt;span class="blsp-spelling-error" id="SPELLING_ERROR_1"&gt;OpenOffice&lt;/span&gt; 2.0, &lt;span class="blsp-spelling-error" id="SPELLING_ERROR_2"&gt;Iceweasel&lt;/span&gt; (&lt;span class="blsp-spelling-error" id="SPELLING_ERROR_3"&gt;Firefox&lt;/span&gt;) 2.0 …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Finally, after 21 months of constant development, last version of Debian distribution has been released. Oppositely to previous versions of Debian, Etch has a "up-to-date flavour", including last version packages such as Linux kernel 2.6, MySQL 5, &lt;span class="blsp-spelling-error" id="SPELLING_ERROR_0"&gt;PHP&lt;/span&gt; 5, Python 2.5, &lt;span class="blsp-spelling-error" id="SPELLING_ERROR_1"&gt;OpenOffice&lt;/span&gt; 2.0, &lt;span class="blsp-spelling-error" id="SPELLING_ERROR_2"&gt;Iceweasel&lt;/span&gt; (&lt;span class="blsp-spelling-error" id="SPELLING_ERROR_3"&gt;Firefox&lt;/span&gt;) 2.0...&lt;br/&gt;&lt;br/&gt;I'm using Etch for some months in different beta and release candidates versions, with very good results. For me &lt;span class="blsp-spelling-corrected" id="SPELLING_ERROR_4"&gt;Debian&lt;/span&gt; has been probably the best system for many time, but with a big handicap, versions. Now I think that there is no good competitor for this distribution, for a medium/advanced GNU user.&lt;br/&gt;&lt;br/&gt;You can find more information in announcements at &lt;a href="http://www.debian.org/News/2007/20070408"&gt;Debian page&lt;/a&gt; and &lt;a href="http://lists.debian.org/debian-announce/debian-announce-2007/msg00002.html"&gt;distribution list&lt;/a&gt;.&lt;br/&gt;&lt;br/&gt;Convinced? Just download &lt;a href="http://cdimage.debian.org/debian-cd/4.0_r0/i386/iso-cd/debian-40r0-i386-netinst.iso"&gt;here&lt;/a&gt; and enjoy!&lt;/p&gt;</content><category term="Systems"></category><category term="IT"></category></entry><entry><title>bug in IE</title><link href="https://datapythonista.github.io/blog/bug-in-ie.html" rel="alternate"></link><published>2007-04-07T19:39:00+01:00</published><updated>2007-04-07T19:39:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2007-04-07:/blog/bug-in-ie.html</id><summary type="html">&lt;p&gt;It's known that Microsoft Internet Explorer usually shows pages in a different way than good web programmers expect. Luckily those differences diminish when using XHTML Strict and CSS, but sometimes we are surprised for some huge bugs.&lt;br/&gt;&lt;br/&gt;This is the case when trying to create an empty layer, something like …&lt;/p&gt;</summary><content type="html">&lt;p&gt;It's known that Microsoft Internet Explorer usually shows pages in a different way than good web programmers expect. Luckily those differences diminish when using XHTML Strict and CSS, but sometimes we are surprised for some huge bugs.&lt;br/&gt;&lt;br/&gt;This is the case when trying to create an empty layer, something like that:&lt;br/&gt;&lt;span style="color: #999999"&gt;our_style {&lt;/span&gt;&lt;br/&gt;&lt;span style="color: #999999"&gt;    height: 1px;&lt;/span&gt;&lt;br/&gt;&lt;span style="color: #999999"&gt;    width: 100px;&lt;/span&gt;&lt;br/&gt;&lt;span style="color: #999999"&gt;    background-color: black;&lt;/span&gt;&lt;br/&gt;&lt;span style="color: #999999"&gt;}&lt;/span&gt;&lt;br/&gt;[...]&lt;br/&gt;&lt;span style="color: #999999"&gt;&lt;div class="our_style"&gt;&lt;/div&gt;&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;Obviously we expect something like a horizontal line, but IE increases our layer height to 10px 18px or whatever...&lt;br/&gt;&lt;br/&gt;This time there is a easy solution for solving the bug, that is just adding a zero font size for the layer:&lt;br/&gt;&lt;br/&gt;&lt;span style="color: #999999"&gt;our_style {&lt;/span&gt;&lt;br/&gt;&lt;span style="color: #999999"&gt;    &lt;span style="font-weight: bold; color: #000000"&gt;font-size: 0px&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;span style="color: #999999"&gt;     height: 1px;&lt;/span&gt;&lt;br/&gt;&lt;span style="color: #999999"&gt;     width: 100px;&lt;/span&gt;&lt;br/&gt;&lt;span style="color: #999999"&gt;     background-color: black;&lt;/span&gt;&lt;br/&gt;&lt;span style="color: #999999"&gt; }&lt;/span&gt;&lt;/p&gt;</content><category term="Development"></category><category term="IT"></category></entry><entry><title>Google Products</title><link href="https://datapythonista.github.io/blog/google-products.html" rel="alternate"></link><published>2007-04-01T03:41:00+01:00</published><updated>2007-04-01T03:41:00+01:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2007-04-01:/blog/google-products.html</id><summary type="html">&lt;p&gt;It's not a secret that I like Google products, I use &lt;a href="http://www.gmail.com/"&gt;Gmail&lt;/a&gt; for mail, &lt;a href="http://www.google.com/"&gt;Google&lt;/a&gt; for searching sites, &lt;a href="http://www.google.com/calendar/"&gt;Google calendar&lt;/a&gt;, &lt;a href="http://docs.google.com/"&gt;Google docs&lt;/a&gt;, this blog is developed under &lt;a href="http://www.blogger.com/"&gt;blogger&lt;/a&gt;, &lt;a href="http://picasaweb.google.com/"&gt;&lt;span class="blsp-spelling-error" id="SPELLING_ERROR_0"&gt;picassa&lt;/span&gt;&lt;/a&gt; and &lt;a href="http://www.youtube.com/"&gt;&lt;span class="blsp-spelling-error" id="SPELLING_ERROR_1"&gt;youtube&lt;/span&gt;&lt;/a&gt;...&lt;br/&gt;&lt;br/&gt;But last Google product is really incredible... I think that I won't live without it! The best &lt;span class="blsp-spelling-error" id="SPELLING_ERROR_2"&gt;internet&lt;/span&gt; connection …&lt;/p&gt;</summary><content type="html">&lt;p&gt;It's not a secret that I like Google products, I use &lt;a href="http://www.gmail.com/"&gt;Gmail&lt;/a&gt; for mail, &lt;a href="http://www.google.com/"&gt;Google&lt;/a&gt; for searching sites, &lt;a href="http://www.google.com/calendar/"&gt;Google calendar&lt;/a&gt;, &lt;a href="http://docs.google.com/"&gt;Google docs&lt;/a&gt;, this blog is developed under &lt;a href="http://www.blogger.com/"&gt;blogger&lt;/a&gt;, &lt;a href="http://picasaweb.google.com/"&gt;&lt;span class="blsp-spelling-error" id="SPELLING_ERROR_0"&gt;picassa&lt;/span&gt;&lt;/a&gt; and &lt;a href="http://www.youtube.com/"&gt;&lt;span class="blsp-spelling-error" id="SPELLING_ERROR_1"&gt;youtube&lt;/span&gt;&lt;/a&gt;...&lt;br/&gt;&lt;br/&gt;But last Google product is really incredible... I think that I won't live without it! The best &lt;span class="blsp-spelling-error" id="SPELLING_ERROR_2"&gt;internet&lt;/span&gt; connection that you can imagine: &lt;a href="http://www.google.com/tisp/"&gt;Google &lt;span class="blsp-spelling-error" id="SPELLING_ERROR_3"&gt;TiSP&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;br/&gt;Some other good products:&lt;br/&gt;&lt;a href="http://www.google.com/romance/"&gt;Google Romance&lt;/a&gt;&lt;br/&gt;&lt;a href="http://www.google.com/jobs/lunar_job.html"&gt;Google Job Opportunities&lt;/a&gt;&lt;br/&gt;&lt;a href="http://www.google.com/technology/pigeonrank.html"&gt;Google Technology&lt;/a&gt;&lt;br/&gt;&lt;a href="http://www.google.com/mentalplex/"&gt;Google MentalPlex&lt;/a&gt;&lt;br/&gt;&lt;br/&gt;Happy &lt;a href="http://en.wikipedia.org/wiki/April_fool"&gt;April Fool's Day&lt;/a&gt;!&lt;/p&gt;</content><category term="Google"></category><category term="Internet"></category><category term="IT"></category></entry><entry><title>Subversion</title><link href="https://datapythonista.github.io/blog/subversion.html" rel="alternate"></link><published>2007-03-14T15:08:00+00:00</published><updated>2007-03-14T15:08:00+00:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2007-03-14:/blog/subversion.html</id><summary type="html">&lt;p&gt;Today I've learnt a new &lt;a href="http://subversion.tigris.org/"&gt;Subversion&lt;/a&gt; command, but I want to review all subversion usage (in the simplest way...). Here you have the shortest Subversion manual:&lt;br/&gt;&lt;br/&gt;&lt;span style="font-style: italic"&gt;svn checkout http://&lt;repository_url style="font-style: italic"&gt;&lt;/repository_url&gt;&lt;/span&gt;&lt;span style="font-style: italic"&gt;repository_url&lt;/span&gt; &amp;lt;- Get a new repository in current directory&lt;br/&gt;&lt;span style="font-style: italic"&gt;svn import http://&lt;/span&gt;&lt;span style="font-style: italic"&gt;repository_url&lt;/span&gt; &amp;lt;- Uploads a new repository from current directory tree&lt;span style="font-style: italic"&gt;&lt;br/&gt;&lt;/span&gt;&lt;span style="font-style: italic"&gt;svn …&lt;/span&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;Today I've learnt a new &lt;a href="http://subversion.tigris.org/"&gt;Subversion&lt;/a&gt; command, but I want to review all subversion usage (in the simplest way...). Here you have the shortest Subversion manual:&lt;br/&gt;&lt;br/&gt;&lt;span style="font-style: italic"&gt;svn checkout http://&lt;repository_url style="font-style: italic"&gt;&lt;/repository_url&gt;&lt;/span&gt;&lt;span style="font-style: italic"&gt;repository_url&lt;/span&gt; &amp;lt;- Get a new repository in current directory&lt;br/&gt;&lt;span style="font-style: italic"&gt;svn import http://&lt;/span&gt;&lt;span style="font-style: italic"&gt;repository_url&lt;/span&gt; &amp;lt;- Uploads a new repository from current directory tree&lt;span style="font-style: italic"&gt;&lt;br/&gt;&lt;/span&gt;&lt;span style="font-style: italic"&gt;svn update&lt;/span&gt; &amp;lt;- Update your repository copy with server changes&lt;span style="font-style: italic"&gt;&lt;br/&gt;&lt;/span&gt;&lt;span style="font-style: italic"&gt;svn stat&lt;/span&gt; &amp;lt;- Check files with changes done by you&lt;span style="font-style: italic"&gt;&lt;br/&gt;&lt;/span&gt;&lt;span style="font-style: italic"&gt;svn diff &lt;filename&gt;&lt;/filename&gt;&lt;/span&gt;&lt;span style="font-style: italic"&gt; filename &lt;/span&gt;&amp;lt;- Check changes done by you in a specific file&lt;span style="font-style: italic"&gt;&lt;br/&gt;&lt;/span&gt;&lt;span style="font-style: italic"&gt;svn commit&lt;/span&gt; &amp;lt;- Update your changes to the server&lt;br/&gt;&lt;span style="font-style: italic"&gt;svn revert&lt;/span&gt;&lt;span style="font-style: italic"&gt; filename&lt;/span&gt; &amp;lt;- Drop your local changes and update with server version&lt;br/&gt;&lt;br/&gt;&lt;a href="http://svnbook.red-bean.com/nightly/en/index.html"&gt;Here&lt;/a&gt; you have the whole reference for the application.&lt;br/&gt;&lt;br/&gt;And today's command is:&lt;br/&gt;&lt;span style="font-weight: bold; font-style: italic"&gt;svn diff -rRelease1&lt;version1&gt;:Release2 filename&lt;version2&gt; &lt;filename&gt;&lt;/filename&gt;&lt;/version2&gt;&lt;/version1&gt;&lt;/span&gt;&lt;br/&gt;for checking changes in a file between two releases.&lt;br/&gt;&lt;br/&gt;Thanks for it &lt;a href="http://www.murrayc.com/blog/permalink/2007/01/25/subversion-diff-between-branches/"&gt;Murray&lt;/a&gt;&lt;br/&gt;&lt;br/&gt;&lt;strong&gt;UPDATE:&lt;/strong&gt; For creating a new repository on the server it's necessary to do &lt;em&gt;svnadmin create &lt;repo path&gt; --fs-type fsfs&lt;/em&gt;&lt;/p&gt;</content><category term="Applications"></category><category term="IT"></category></entry><entry><title>Web 2.0</title><link href="https://datapythonista.github.io/blog/web-20.html" rel="alternate"></link><published>2007-03-07T15:15:00+00:00</published><updated>2007-03-07T15:15:00+00:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2007-03-07:/blog/web-20.html</id><summary type="html">&lt;p&gt;Those days everybody is using Web 2.0 and AJAX, but everyone understand a different meaning of those technologies. Here I'll explain my interpretation.&lt;br/&gt;&lt;br/&gt;In short I'll use this formula:&lt;br/&gt;&lt;span style="font-weight: bold"&gt;Web 2.0 = &lt;span class="blsp-spelling-error" id="SPELLING_ERROR_0"&gt;XHTML&lt;/span&gt; Strict + &lt;span class="blsp-spelling-error" id="SPELLING_ERROR_1"&gt;CSS&lt;/span&gt;2 + AJAX&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;It means the end of using html tables for positioning objects in …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Those days everybody is using Web 2.0 and AJAX, but everyone understand a different meaning of those technologies. Here I'll explain my interpretation.&lt;br/&gt;&lt;br/&gt;In short I'll use this formula:&lt;br/&gt;&lt;span style="font-weight: bold"&gt;Web 2.0 = &lt;span class="blsp-spelling-error" id="SPELLING_ERROR_0"&gt;XHTML&lt;/span&gt; Strict + &lt;span class="blsp-spelling-error" id="SPELLING_ERROR_1"&gt;CSS&lt;/span&gt;2 + AJAX&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;It means the end of using html tables for positioning objects in the page (HTML 4.0 or &lt;span class="blsp-spelling-error" id="SPELLING_ERROR_2"&gt;XHTML&lt;/span&gt; Transactional). Web 2.0 uses &lt;span class="blsp-spelling-error" id="SPELLING_ERROR_3"&gt;CSS&lt;/span&gt;2 properties to do it. In this formula AJAX is the &lt;span class="blsp-spelling-error" id="SPELLING_ERROR_4"&gt;XMLHttpRequest&lt;/span&gt; JavaScript object, that allows to get HTTP data using JavaScript code (and prevents reloading the whole page).&lt;br/&gt;&lt;br/&gt;A good reference for more of those technologies is &lt;a href="http://www.w3schools.com/"&gt;W3Schools&lt;/a&gt;. In addition there is a very good presentation for best practices (and &lt;span class="blsp-spelling-corrected" id="SPELLING_ERROR_5"&gt;accessibility&lt;/span&gt;) called &lt;a href="http://www.thefutureoftheweb.com/talks/2006-10-ajax-experience/slides/"&gt;&lt;span class="blsp-spelling-error" id="SPELLING_ERROR_6"&gt;Unobstructive&lt;/span&gt; AJAX&lt;/a&gt;.&lt;/p&gt;</content><category term="Development"></category><category term="IT"></category></entry><entry><title>Firefox &amp; Google browser sync</title><link href="https://datapythonista.github.io/blog/firefox-google-browser-sync.html" rel="alternate"></link><published>2007-03-03T01:58:00+00:00</published><updated>2007-03-03T01:58:00+00:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2007-03-03:/blog/firefox-google-browser-sync.html</id><summary type="html">&lt;p&gt;Nowadays, almost everybody already know how good is &lt;a href="http://www.mozilla.com/"&gt;&lt;span class="blsp-spelling-error" id="SPELLING_ERROR_0"&gt;firefox&lt;/span&gt;&lt;/a&gt;. Not so many know about a very good extension for it, &lt;a href="http://www.google.com/tools/firefox/browsersync/"&gt;Google browser sync&lt;/a&gt;. It keeps all your browser's personal information into your Google account, and &lt;span class="blsp-spelling-corrected" id="SPELLING_ERROR_1"&gt;synchronizes&lt;/span&gt; it in any computer. Very useful when using more than one computer (home and …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Nowadays, almost everybody already know how good is &lt;a href="http://www.mozilla.com/"&gt;&lt;span class="blsp-spelling-error" id="SPELLING_ERROR_0"&gt;firefox&lt;/span&gt;&lt;/a&gt;. Not so many know about a very good extension for it, &lt;a href="http://www.google.com/tools/firefox/browsersync/"&gt;Google browser sync&lt;/a&gt;. It keeps all your browser's personal information into your Google account, and &lt;span class="blsp-spelling-corrected" id="SPELLING_ERROR_1"&gt;synchronizes&lt;/span&gt; it in any computer. Very useful when using more than one computer (home and work...), or when reinstalling your system.&lt;br/&gt;&lt;br/&gt;Debian doesn't include &lt;span class="blsp-spelling-error" id="SPELLING_ERROR_2"&gt;firefox&lt;/span&gt; itself, it's available a &lt;span class="blsp-spelling-error" id="SPELLING_ERROR_3"&gt;rebranding&lt;/span&gt; branch called &lt;a href="http://www.gnu.org/software/gnuzilla/"&gt;&lt;span class="blsp-spelling-error" id="SPELLING_ERROR_4"&gt;Iceweasel&lt;/span&gt;&lt;/a&gt;. When trying to install the extension in this application, the page doesn't detect that &lt;span class="blsp-spelling-error" id="SPELLING_ERROR_5"&gt;Iceweasel&lt;/span&gt; is a &lt;span class="blsp-spelling-error" id="SPELLING_ERROR_6"&gt;firefox&lt;/span&gt; 2.0 compatible application, and raises and error. Solution, just click &lt;a href="http://dl.google.com/firefox/google-browsersync.xpi"&gt;here&lt;/a&gt;.&lt;br/&gt;&lt;br/&gt;&lt;span style="font-weight: bold"&gt;UPDATE:&lt;/span&gt; Some other application doesn't detect your browser (for example when changing your profile's picture in &lt;a href="http://groups.google.com/"&gt;Google Groups&lt;/a&gt;. To fix all those problems just type &lt;a href="about:config"&gt;about:config&lt;/a&gt;, search &lt;span style="font-style: italic"&gt;general.useragent.extra.firefox&lt;/span&gt; and change it's value from &lt;span style="font-style: italic"&gt;Iceweasel/2.0.0.1&lt;/span&gt; (or your version) to &lt;span style="font-style: italic"&gt;Firefox/2.0.0.1&lt;/span&gt;.&lt;/p&gt;</content><category term="Applications"></category><category term="Google"></category><category term="Internet"></category><category term="IT"></category></entry><entry><title>Sony Vaio support</title><link href="https://datapythonista.github.io/blog/sony-vaio-support.html" rel="alternate"></link><published>2007-02-27T22:48:00+00:00</published><updated>2007-02-27T22:48:00+00:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2007-02-27:/blog/sony-vaio-support.html</id><summary type="html">&lt;p&gt;Some days ago, my laptop's screen crashed. It's a Sony Vaio, and my experience hasn't been good at all.&lt;br/&gt;My first problems were when contacting vaio support spain, I had to do many calls to know the whole procedure, register my laptop in the support center, and finally register the …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Some days ago, my laptop's screen crashed. It's a Sony Vaio, and my experience hasn't been good at all.&lt;br/&gt;My first problems were when contacting vaio support spain, I had to do many calls to know the whole procedure, register my laptop in the support center, and finally register the issue. More problems about data in my disk, so they were no responsible for any data on my disk -even when it was a screen problem-, and then because they asked me to install the original operating system (w32), for being able to do testing on it.&lt;br/&gt;The worse part of the story was not directly with sony, it has been with dhl, the company that picked up the laptop at my home, and the give it back to me. The tracking service of this company is pretty good, but in both visits they don't come when they were supposed to come. The courier notified that I wasn't at home, but I was there, and the visit notes are still missing.&lt;br/&gt;The good part of the history has been the quick reparation at Sony, with a good delivery system I would had my computer back in less than one week.&lt;br/&gt;So my rating of both companies:&lt;br/&gt;&lt;a href="http://www.vaio-link.com"&gt;Sony VAIO support&lt;/a&gt;: 7&lt;br/&gt;&lt;a href="http://www.dhl.com&amp;quot; rel=&amp;quot;nofollow"&gt;DHL&lt;/a&gt;: 4&lt;/p&gt;</content><category term="Systems"></category><category term="IT"></category><category term="Personal"></category></entry><entry><title>New blog</title><link href="https://datapythonista.github.io/blog/new-blog.html" rel="alternate"></link><published>2007-02-24T13:25:00+00:00</published><updated>2007-02-24T13:25:00+00:00</updated><author><name>Marc</name></author><id>tag:datapythonista.github.io,2007-02-24:/blog/new-blog.html</id><content type="html">&lt;p&gt;This is the new placeholder for my blog. It's hosted by Google's &lt;a href="http://www.blogger.com"&gt;blogger&lt;/a&gt; service.&lt;br/&gt;Main purpose of this blog is sharing computer related experiences. Despite of this, I've added some photo galleries about my personal live (specially traveling).&lt;/p&gt;</content><category term="This blog"></category></entry></feed>